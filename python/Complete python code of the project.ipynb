{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e638e321-8c7f-42bc-ad9c-aa324a2cadaa",
   "metadata": {},
   "source": [
    "Libraries and Imports\n",
    "requests: This library is used to send HTTP requests. In this script, it is used to fetch the content of a webpage.\n",
    "pprint: This module is for \"pretty-printing\" data structures, though it’s not used in the code you’ve shared.\n",
    "BeautifulSoup from bs4: This library helps parse HTML and XML documents. It is used here to parse and extract data from the HTML content of a webpage.\n",
    "datetime: This module is for manipulating dates and times, though it’s also not used in the code you’ve shared.\n",
    "Cookies\n",
    "The cookies dictionary contains cookies that are sent with the HTTP request. Cookies can store information about the user’s session and preferences, which can be important for maintaining state or for accessing certain resources.\n",
    "\n",
    "Headers\n",
    "The headers dictionary contains HTTP headers that are sent with the request. These headers provide information about the request, such as the accepted content types and user-agent. In this case:\n",
    "\n",
    "Accept: Specifies the types of content the client can accept.\n",
    "Accept-Language: Indicates the preferred languages for the response.\n",
    "Connection: Indicates if the connection should be kept alive or closed after the request.\n",
    "User-Agent: Provides information about the client’s browser and operating system.\n",
    "Referer: Specifies the URL of the page that linked to the resource being requested.\n",
    "Request\n",
    "The requests.get function sends a GET request to the specified URL (https://dcbjuniorlge.play-cricket.com/home) with the provided cookies and headers. The server’s response is stored in the response variable.\n",
    "\n",
    "Parsing HTML\n",
    "BeautifulSoup(response.content, 'html.parser'): The HTML content of the response is parsed using BeautifulSoup. The html.parser argument specifies that the built-in HTML parser should be used.\n",
    "Summary\n",
    "The script sends an HTTP GET request to a cricket website using specified cookies and headers, then parses the HTML content of the response using BeautifulSoup. This setup is often used for web scraping to retrieve and analyze data from web pages.\n",
    "\n",
    "If you want to extract specific information from the page, you would use BeautifulSoup’s methods to navigate and search the HTML structure, such as find(), find_all(), or CSS selectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db23fc4-9743-4bc2-a2a3-c63df858814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "cookies = {\n",
    "    'fdp-fingerprint': '1889803a551ecbaea1a74b3111b91ec8',\n",
    "    'OptanonAlertBoxClosed': '2024-04-30T13:30:53.182Z',\n",
    "    'ai_user': 'CU74D3KILVFnI2v4blNfQP|2024-06-03T19:59:44.280Z',\n",
    "    '_gid': 'GA1.2.972306044.1717694055',\n",
    "    '_play_cricket_session': 'IKqmU7wVY5OKGzKIUjS1WEZ0KyUUgl3h%2FePq67zQyx9aXbD3SUe85zj4a9MprzB7lOinQzJUCm7xlGHuMnYnC4QW9D6PgDKtC9ItW4HW2x6Uti8TZT1uxEPzuApob8fGSvOQTkKVDNE5dwhEXaDlP1XDBVR0gIpEV8T7U5xBN28JutWjt3O7LT1bjk8s%2FkgTCVHotMI%2F7mzEkm6nSOUjJbVcnjx5OiAEROrzjtOwJy9iQJTP5IHBUvWttfd0ypJf9HsAseu2YdXjVRoaLr0vUCxvQLS%2B136KPsoAFWMj3w%2FKGB4aSuwou3RXIHn9UxP%2FpaOL%2F3uafHHg1%2F%2B6Xn%2BexxY2srq5OKNhs3FWIdd07wdR76xFW2SGa86sQqn6vFYzeg%3D%3D--md3L0ZgpqH4CmuTu--C9cpDGB9yOBsoNl4z3ivIQ%3D%3D',\n",
    "    'TSd091cc5a027': '08ac97c60eab2000ffbe1b9cf025675bb1526cd069f3d6c33c069bf3b00b6a0cc94c962a8ec9ff64084342fb361130002eaafe37980af451e70b0b4d170ac4da0ab37739a3781d7fbf668fbc5bf9c0edbc248ede0a4510fe2310b0695f8fdacc',\n",
    "    'OptanonConsent': 'isGpcEnabled=0&datestamp=Thu+Jun+06+2024+20%3A09%3A21+GMT%2B0100+(British+Summer+Time)&version=202401.2.0&browserGpcFlag=0&isIABGlobal=false&hosts=&consentId=d771d464-7a78-4757-91b3-39bade7bccaa&interactionCount=1&landingPath=NotLandingPage&groups=C0001%3A1%2CC0002%3A1%2CC0004%3A1&geolocation=GB%3BENG&AwaitingReconsent=false',\n",
    "    '_ga_ZP882GSBL8': 'GS1.2.1717700942.6.1.1717700961.0.0.0',\n",
    "    '_ga_HHWFVJSD1E': 'GS1.1.1717700944.9.1.1717700962.0.0.0',\n",
    "    '_ga': 'GA1.1.1376912539.1714483850',\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "    'Accept-Language': 'en-GB,en-US;q=0.9,en;q=0.8',\n",
    "    'Cache-Control': 'max-age=0',\n",
    "    'Connection': 'keep-alive',\n",
    "    # 'Cookie': 'fdp-fingerprint=1889803a551ecbaea1a74b3111b91ec8; OptanonAlertBoxClosed=2024-04-30T13:30:53.182Z; ai_user=CU74D3KILVFnI2v4blNfQP|2024-06-03T19:59:44.280Z; _gid=GA1.2.972306044.1717694055; _play_cricket_session=IKqmU7wVY5OKGzKIUjS1WEZ0KyUUgl3h%2FePq67zQyx9aXbD3SUe85zj4a9MprzB7lOinQzJUCm7xlGHuMnYnC4QW9D6PgDKtC9ItW4HW2x6Uti8TZT1uxEPzuApob8fGSvOQTkKVDNE5dwhEXaDlP1XDBVR0gIpEV8T7U5xBN28JutWjt3O7LT1bjk8s%2FkgTCVHotMI%2F7mzEkm6nSOUjJbVcnjx5OiAEROrzjtOwJy9iQJTP5IHBUvWttfd0ypJf9HsAseu2YdXjVRoaLr0vUCxvQLS%2B136KPsoAFWMj3w%2FKGB4aSuwou3RXIHn9UxP%2FpaOL%2F3uafHHg1%2F%2B6Xn%2BexxY2srq5OKNhs3FWIdd07wdR76xFW2SGa86sQqn6vFYzeg%3D%3D--md3L0ZgpqH4CmuTu--C9cpDGB9yOBsoNl4z3ivIQ%3D%3D; TSd091cc5a027=08ac97c60eab2000ffbe1b9cf025675bb1526cd069f3d6c33c069bf3b00b6a0cc94c962a8ec9ff64084342fb361130002eaafe37980af451e70b0b4d170ac4da0ab37739a3781d7fbf668fbc5bf9c0edbc248ede0a4510fe2310b0695f8fdacc; OptanonConsent=isGpcEnabled=0&datestamp=Thu+Jun+06+2024+20%3A09%3A21+GMT%2B0100+(British+Summer+Time)&version=202401.2.0&browserGpcFlag=0&isIABGlobal=false&hosts=&consentId=d771d464-7a78-4757-91b3-39bade7bccaa&interactionCount=1&landingPath=NotLandingPage&groups=C0001%3A1%2CC0002%3A1%2CC0004%3A1&geolocation=GB%3BENG&AwaitingReconsent=false; _ga_ZP882GSBL8=GS1.2.1717700942.6.1.1717700961.0.0.0; _ga_HHWFVJSD1E=GS1.1.1717700944.9.1.1717700962.0.0.0; _ga=GA1.1.1376912539.1714483850',\n",
    "    'DNT': '1',\n",
    "    'If-None-Match': 'W/\"e73977832b057e5923fc0354614ca18d\"',\n",
    "    'Referer': 'https://durhamcity.play-cricket.com/home',\n",
    "    'Sec-Fetch-Dest': 'document',\n",
    "    'Sec-Fetch-Mode': 'navigate',\n",
    "    'Sec-Fetch-Site': 'same-origin',\n",
    "    'Sec-Fetch-User': '?1',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36',\n",
    "    'sec-ch-ua': '\"Google Chrome\";v=\"125\", \"Chromium\";v=\"125\", \"Not.A/Brand\";v=\"24\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform': '\"Windows\"',\n",
    "}\n",
    "\n",
    "response = requests.get('https://dcbjuniorlge.play-cricket.com/home', cookies=cookies, headers=headers)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533b09b1-c7ba-46e5-972f-bdd2b878d492",
   "metadata": {},
   "source": [
    "This Python script uses Selenium to automate interactions with a webpage and then parses the resulting HTML using BeautifulSoup. It performs the following steps:\n",
    "\n",
    "Setup:\n",
    "\n",
    "Imports necessary libraries: Selenium for browser automation and BeautifulSoup for HTML parsing.\n",
    "Sets up the WebDriver to control the Chrome browser.\n",
    "Initialize WebDriver:\n",
    "\n",
    "Specifies the path to the ChromeDriver executable.\n",
    "Initializes the Chrome WebDriver with specified options.\n",
    "Handle Cookies:\n",
    "\n",
    "Defines a list of cookies to simulate a logged-in session or maintain state.\n",
    "Opens the target webpage.\n",
    "Adds the defined cookies to the browser session.\n",
    "Refreshes the page to apply the cookies.\n",
    "Interact with Web Elements:\n",
    "\n",
    "Waits for a dropdown menu with a specific ID ('season') to be present on the page.\n",
    "Selects an option from the dropdown based on its value ('257').\n",
    "Pauses execution for a few seconds to allow the page to update after interacting with the dropdown.\n",
    "Extract and Parse HTML:\n",
    "\n",
    "Retrieves the updated HTML content of the page.\n",
    "Parses the HTML using BeautifulSoup for further processing.\n",
    "Prints the prettified (formatted) HTML to the console.\n",
    "Cleanup:\n",
    "\n",
    "Closes the WebDriver to end the browser session and free up resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6139cd10-48a9-4d38-848d-2ebeb0413a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import Select, WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Initialize the WebDriver with ChromeDriverManager\n",
    "driver_path = r'C:\\Users\\dheer\\chromedriver.exe'\n",
    "\n",
    "service = Service(driver_path)\n",
    "options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "\n",
    "\n",
    "# Define the cookies\n",
    "cookies1 = [\n",
    "    {'name': 'fdp-fingerprint', 'value': '1889803a551ecbaea1a74b3111b91ec8'},\n",
    "    {'name': 'OptanonAlertBoxClosed', 'value': '2024-04-30T13:30:53.182Z'},\n",
    "    {'name': 'ai_user', 'value': 'CU74D3KILVFnI2v4blNfQP|2024-06-03T19:59:44.280Z'},\n",
    "    {'name': '_gid', 'value': 'GA1.2.972306044.1717694055'},\n",
    "    {'name': '_play_cricket_session', 'value': 'IKqmU7wVY5OKGzKIUjS1WEZ0KyUUgl3h%2FePq67zQyx9aXbD3SUe85zj4a9MprzB7lOinQzJUCm7xlGHuMnYnC4QW9D6PgDKtC9ItW4HW2x6Uti8TZT1uxEPzuApob8fGSvOQTkKVDNE5dwhEXaDlP1XDBVR0gIpEV8T7U5xBN28JutWjt3O7LT1bjk8s%2FkgTCVHotMI%2F7mzEkm6nSOUjJbVcnjx5OiAEROrzjtOwJy9iQJTP5IHBUvWttfd0ypJf9HsAseu2YdXjVRoaLr0vUCxvQLS%2B136KPsoAFWMj3w%2FKGB4aSuwou3RXIHn9UxP%2FpaOL%2F3uafHHg1%2F%2B6Xn%2BexxY2srq5OKNhs3FWIdd07wdR76xFW2SGa86sQqn6vFYzeg%3D%3D--md3L0ZgpqH4CmuTu--C9cpDGB9yOBsoNl4z3ivIQ%3D%3D'},\n",
    "    {'name': 'TSd091cc5a027', 'value': '08ac97c60eab2000ffbe1b9cf025675bb1526cd069f3d6c33c069bf3b00b6a0cc94c962a8ec9ff64084342fb361130002eaafe37980af451e70b0b4d170ac4da0ab37739a3781d7fbf668fbc5bf9c0edbc248ede0a4510fe2310b0695f8fdacc'},\n",
    "    {'name': 'OptanonConsent', 'value': 'isGpcEnabled=0&datestamp=Thu+Jun+06+2024+20%3A09%3A21+GMT%2B0100+(British+Summer+Time)&version=202401.2.0&browserGpcFlag=0&isIABGlobal=false&hosts=&consentId=d771d464-7a78-4757-91b3-39bade7bccaa&interactionCount=1&landingPath=NotLandingPage&groups=C0001%3A1%2CC0002%3A1%2CC0004%3A1&geolocation=GB%3BENG&AwaitingReconsent=false'},\n",
    "    {'name': '_ga_ZP882GSBL8', 'value': 'GS1.2.1717700942.6.1.1717700961.0.0.0'},\n",
    "    {'name': '_ga_HHWFVJSD1E', 'value': 'GS1.1.1717700944.9.1.1717700962.0.0.0'},\n",
    "    {'name': '_ga', 'value': 'GA1.1.1376912539.1714483850'}\n",
    "]\n",
    "\n",
    "try:\n",
    "    # Open the web page\n",
    "    driver.get('https://dcbjuniorlge.play-cricket.com/home')\n",
    "\n",
    "    # Add cookies to the session\n",
    "    for cookie in cookies1:\n",
    "        driver.add_cookie(cookie)\n",
    "\n",
    "    # Refresh the page to apply the cookies\n",
    "    driver.refresh()\n",
    "\n",
    "    # Wait for the dropdown to be present and select the option with value '256'\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    dropdown = wait.until(EC.presence_of_element_located((By.ID, 'season')))\n",
    "    select = Select(dropdown)\n",
    "    select.select_by_value('257')\n",
    "\n",
    "    # Wait for the page to update after selecting the dropdown value\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Get the updated HTML content of the page\n",
    "    html_content = driver.page_source\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Print the parsed HTML content\n",
    "    print(soup.prettify())\n",
    "finally:\n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ad4db7-7052-4e67-a2c0-06412dec2471",
   "metadata": {},
   "source": [
    "The code snippet provided extracts and filters hyperlinks from a webpage using BeautifulSoup, a library for parsing HTML.\n",
    "\n",
    "First, the code locates a specific div element on the webpage with the class name \"panel-body\". This is done using soup.find('div', class_=\"panel-body\"), which retrieves the first div matching this class and stores it in the variable div.\n",
    "\n",
    "Next, within this div, the code identifies all anchor a tags using div.find_all('a'). This method returns a list of all the links present within the div, and this list is stored in the variable links.\n",
    "\n",
    "The script then proceeds to create a dictionary named initial_dict. It iterates over each link in the links list, extracting the href attribute, which contains the URL of the link, and the text inside the anchor tag. The text is cleaned of any leading or trailing whitespace using strip=True. Each pair of link text and URL is added to initial_dict, with the link text as the key and the URL as the value.\n",
    "\n",
    "After building initial_dict, the code filters this dictionary to produce filtered_dict. The filtering criteria include only those dictionary entries where the key (link text) contains the substring '13' and does not contain the substring 'Girls'. This is achieved using a dictionary comprehension that checks these conditions for each key-value pair in initial_dict.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb7c375-438e-4db3-8abb-21623d048d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "div = soup.find('div',class_=\"panel-body\")\n",
    "links = div.find_all('a')\n",
    "initial_dict={}\n",
    "for link in links:\n",
    "    href = link.get('href')\n",
    "    text = link.get_text(strip=True)\n",
    "    initial_dict[text]=href\n",
    "filtered_dict = {key: value for key, value in initial_dict.items() if '13' in key and 'Girls' not in key}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c0405f-a718-46e6-b1d6-68ef2f4fb8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_link=[]\n",
    "for i in filtered_dict:\n",
    "    final_link.append(\"https://dcbjuniorlge.play-cricket.com/\"+filtered_dict[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9916ea3-b56a-4263-a2ef-8dc969f07354",
   "metadata": {},
   "source": [
    "The provided script is designed to extract team names and their associated links from multiple webpages and compile these links into a list for further use. Here’s a detailed explanation of how it works:\n",
    "\n",
    "The script begins by initializing an empty list, all_link, which will be used to store the extracted links. It then iterates through a list of URLs, final_link, which contains the addresses of the webpages to be processed.\n",
    "\n",
    "For each URL in this list, the script sends an HTTP GET request using the requests.get() method. This request is made with specific cookies and headers to simulate a browser session or maintain certain states. The HTML content of the response is then parsed using BeautifulSoup, which enables the script to navigate and extract data from the webpage.\n",
    "\n",
    "The script focuses on finding specific table rows within the parsed HTML. Each row that has the class league_row is identified as containing relevant information. Within each of these rows, the script looks for anchor (<a>) tags that contain links. For each anchor tag found, the script extracts the visible text, which represents the team name, and the URL from the href attribute.\n",
    "\n",
    "These extracted team names and URLs are stored in a dictionary called teams_dict, where the team names are the keys and the URLs are the values. After populating this dictionary with all the links from the current webpage, the script prints each team name and its corresponding link. This printout serves as a verification step to ensure that the data has been extracted correctly.\n",
    "\n",
    "Finally, the script appends each URL from teams_dict to the all_link list. This process is repeated for all URLs in the final_link list. By the end of the script, all_link contains a comprehensive list of links extracted from all the processed webpages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d917a44c-4597-4d11-abbf-2bc760d0fd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_link=[]\n",
    "for i in final_link:\n",
    "    response1 = requests.get(i, cookies=cookies, headers=headers)\n",
    "    soup = BeautifulSoup(response1.content, 'html.parser')\n",
    "    rows = soup.find_all('tr', class_='league_row')\n",
    "\n",
    "    # Create a dictionary to store the team names and their links\n",
    "    teams_dict = {}\n",
    "\n",
    "    for row in rows:\n",
    "        link = row.find('a')\n",
    "        if link:\n",
    "            team_name = link.get_text(strip=True)\n",
    "            href = link.get('href')\n",
    "            teams_dict[team_name] = href\n",
    "\n",
    "    # Print the dictionary to verify the contents\n",
    "    for team, link in teams_dict.items():\n",
    "        print(f\"'{team}': '{link}'\")\n",
    "        all_link.append(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615807b0-94a4-412f-ab9d-ff6949a8ac0c",
   "metadata": {},
   "source": [
    "The script is designed to extract specific match links related to the year \"2024\" from a list of webpages. It initializes an empty list, l2023, to store these links. For each URL in the all_link list, it sends a GET request to fetch the webpage content, which is then parsed with BeautifulSoup. The script locates table rows containing match data and extracts the relevant table cells. Each cell is examined to find links, specifically looking for those that mention \"2024\". It constructs a base URL by trimming the original URL to a higher directory level. If it finds a link related to \"2024\", it combines this link with the trimmed base URL to form a complete URL, which is then added to the l2023 list. In essence, the script collects and compiles URLs of matches from the given webpages that are associated with the year \"2024\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2c737b-eaf2-49bb-ba10-177485160e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "l2023=[]\n",
    "for i in all_link:\n",
    "    match=[]\n",
    "    response1 = requests.get(i, cookies=cookies, headers=headers)\n",
    "    soup = BeautifulSoup(response1.content, 'html.parser')\n",
    "    div=soup.find('div',class_=\"tab-content brnone\")\n",
    "    tbody=div.find('tbody')\n",
    "    tr=tbody.find_all('tr')\n",
    "    for j in tr:\n",
    "        td=j.find('td', class_=\"tfont3\")\n",
    "        if td:  # Check if td is not None\n",
    "                match.append(td)\n",
    "\n",
    "    # Provided URL\n",
    "    url = i\n",
    "\n",
    "    # Parse the URL\n",
    "    parsed_url = urlparse(url)\n",
    "\n",
    "    # Split the path component by slashes\n",
    "    path_parts = parsed_url.path.split('/')\n",
    "\n",
    "    # Join the path components except for the last part\n",
    "    trimmed_path = '/'.join(path_parts[:-2])\n",
    "\n",
    "    # Reconstruct the URL up to the last second slash\n",
    "    trimmed_url = f\"{parsed_url.scheme}://{parsed_url.netloc}{trimmed_path}\"\n",
    "\n",
    "    # Print the result\n",
    "\n",
    "\n",
    "    matchs = [ str(k) for k in match]\n",
    "    # Initialize the link variable\n",
    "    link_2023 = None\n",
    "\n",
    "    # Iterate over the match list to find the one with the 2023 link\n",
    "    for html_str in matchs:\n",
    "        # Ensure the item is a string\n",
    "        if html_str:\n",
    "            # Parse the HTML string\n",
    "            td = BeautifulSoup(html_str, 'html.parser').td\n",
    "            # Find the 'a' tag within the td\n",
    "            a_tag = td.find('a')\n",
    "            # Check if the text of the 'a' tag is '2023'\n",
    "            if a_tag and a_tag.text == '2024':\n",
    "                link_2023 = a_tag['href']\n",
    "                break\n",
    "\n",
    "    if trimmed_url != None and link_2023 != None:\n",
    "        # Print the link for 2023\n",
    "        l2023.append(trimmed_url+link_2023)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08872cf4-85f0-46a9-8646-60bdd196a4cb",
   "metadata": {},
   "source": [
    "The script is designed to extract and compile specific match-related links from a list of URLs, l2023. It iterates over each URL in this list, sending a GET request to retrieve the webpage content, which is then parsed using BeautifulSoup. Within the parsed HTML, the script identifies and processes div elements with the class col-sm-1 col-md-1 d-none d-md-block, which likely contain scorecard links. For each of these div elements, it looks for an anchor tag a with the class link-scorecard d-none d-md-inline-block rounded-circle, indicating a link to detailed match information. The script then constructs a base URL by removing any specific path or query parameters from the original URL, ensuring that only the scheme and domain are retained. It appends this base URL to the href attribute of each identified link to form a complete URL. All such filtered and reconstructed URLs are collected into a list, ball_link, which groups links corresponding to each URL from l2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee900b51-97b4-4ded-8595-22eea1030fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse, urlunparse\n",
    "\n",
    "# Assuming l2023, cookies, and headers are already defined\n",
    "ball_link = []\n",
    "\n",
    "for i in l2023:\n",
    "    response1 = requests.get(i, cookies=cookies, headers=headers)\n",
    "    soup = BeautifulSoup(response1.content, 'html.parser')\n",
    "    divs = soup.find_all('div', class_='col-sm-1 col-md-1 d-none d-md-block')\n",
    "\n",
    "    # Filter links that have <i class=\"material-icons\">assignment</i>\n",
    "    filtered_links = []\n",
    "\n",
    "    for div in divs:\n",
    "        link = div.find('a', class_='link-scorecard d-none d-md-inline-block rounded-circle')\n",
    "        if link:\n",
    "            parsed_url = urlparse(i)\n",
    "            # Reconstruct the URL without the specific path and query\n",
    "            trimmed_url = urlunparse((parsed_url.scheme, parsed_url.netloc, '', '', '', ''))\n",
    "            filtered_links.append(trimmed_url + link.get('href'))        \n",
    "\n",
    "    ball_link.append(filtered_links)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f56e44-44d0-43f1-96b4-4d454d4eec5c",
   "metadata": {},
   "source": [
    "The script is designed to gather specific match scoreball links from a list of URLs stored in ball_link. It starts by initializing an empty list, scoreball, to store the links of interest. For each URL in ball_link, the script sends a GET request to fetch the webpage content and parses it using BeautifulSoup. Within the parsed HTML, it searches for a li element with the class li-iasBallbyballtab, which indicates the presence of scoreball details. If such a li element is found, the script extracts the href attribute from the nested a tag within it and appends the current URL (j) to the scoreball list. The script also maintains a counter z to track the number of processed URLs and prints this count after processing each set of links from ball_link. Essentially, the script systematically retrieves and stores URLs that contain detailed scoreball information for matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3472736e-8d23-42c3-af67-5cc8adb61893",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreball = []\n",
    "z=0\n",
    "for i in ball_link:\n",
    "    for j in i:\n",
    "        response1 = requests.get(j, cookies=cookies, headers=headers)\n",
    "        soup = BeautifulSoup(response1.content, 'html.parser')\n",
    "        li = soup.find('li', class_=\"li-iasBallbyballtab\")\n",
    "\n",
    "        # Check if 'li' is found\n",
    "        if li:\n",
    "\n",
    "            a = li.find('a')\n",
    "            href = a.get('href')\n",
    "            scoreball.append(j)\n",
    "        z=z+1 \n",
    "    print(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e285e35-d037-4d3c-8a7f-c9e7737cd1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_to_remove = [\n",
    "    \"https://seaham.play-cricket.com/website/results/6415368\",\n",
    "    \"https://dawdonwelfare.play-cricket.com/website/results/6415368\"\n",
    "]\n",
    "\n",
    "# Remove the URLs\n",
    "scoreball = [url for url in scoreball if url not in urls_to_remove]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06339ab7-7fe6-47d8-beb9-c189ac20e792",
   "metadata": {},
   "source": [
    "The script is designed to extract detailed cricket match data, focusing on ball-by-ball statistics for each over. It starts by setting up a DataFrame with predefined columns to store the collected data. The process begins by iterating over a list of scoreball URLs, where each URL corresponds to a specific match's scoreball data.\n",
    "\n",
    "For each URL, the script initializes a Selenium WebDriver instance with the Chrome browser. It uses predefined cookies to simulate a logged-in session and refreshes the page to apply these cookies. The script then navigates to the 'Ball by Ball' tab, waits for the data to load, and extracts the HTML content of the relevant sections for each over. If the data appears incomplete or the page fails to load, it skips to the next URL.\n",
    "\n",
    "After gathering the ball-by-ball data, the script makes a separate HTTP request to the same URL to retrieve additional match details such as team names, scores, toss information, and match results. This information is parsed to determine which team batted or fielded first based on the toss result.\n",
    "\n",
    "Next, the script processes the collected HTML data for each over, extracting information like over number, ball details, events, commentary, and player statistics. It checks if specific player information is available and includes it in the data if present. The script then compiles this data into a DataFrame, adjusting innings information based on the toss result.\n",
    "\n",
    "Finally, the script combines the newly gathered data with the main DataFrame and prints a completion message. This approach ensures a comprehensive dataset capturing detailed ball-by-ball statistics across multiple overs for each match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1f519e-889f-41ff-81ed-d56809bce79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data for each over\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "z=0\n",
    "columns = ['Over', 'Ball', 'Event', 'Commentary', 'innings', 'teamname','teamscore', 'teamtossinfo','full_match_result', 'Player', 'Dismissal', 'R', 'B', '4s', '6s', 'SR']\n",
    "\n",
    "    # Create an empty DataFrame with specified columns\n",
    "df_data = pd.DataFrame(columns=columns)\n",
    "for i in scoreball:\n",
    "    print(i)\n",
    "    z=z+1\n",
    "    print(z)\n",
    "    # Initialize Chrome options\n",
    "    \n",
    "    # Initialize the WebDriver with ChromeDriverManager\n",
    "    driver_path = r'C:\\Users\\dheer\\chromedriver.exe'\n",
    "    \n",
    "    service = Service(driver_path)\n",
    "    options = webdriver.ChromeOptions()\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    # Define your cookies\n",
    "    cookies = [\n",
    "        {'name': 'fdp-fingerprint', 'value': '1889803a551ecbaea1a74b3111b91ec8'},\n",
    "        {'name': 'OptanonAlertBoxClosed', 'value': '2024-04-30T13:30:53.182Z'},\n",
    "        {'name': 'ai_user', 'value': 'CU74D3KILVFnI2v4blNfQP|2024-06-03T19:59:44.280Z'},\n",
    "        {'name': '_gid', 'value': 'GA1.2.972306044.1717694055'},\n",
    "        {'name': '_play_cricket_session', 'value': 'IKqmU7wVY5OKGzKIUjS1WEZ0KyUUgl3h%2FePq67zQyx9aXbD3SUe85zj4a9MprzB7lOinQzJUCm7xlGHuMnYnC4QW9D6PgDKtC9ItW4HW2x6Uti8TZT1uxEPzuApob8fGSvOQTkKVDNE5dwhEXaDlP1XDBVR0gIpEV8T7U5xBN28JutWjt3O7LT1bjk8s%2FkgTCVHotMI%2F7mzEkm6nSOUjJbVcnjx5OiAEROrzjtOwJy9iQJTP5IHBUvWttfd0ypJf9HsAseu2YdXjVRoaLr0vUCxvQLS%2B136KPsoAFWMj3w%2FKGB4aSuwou3RXIHn9UxP%2FpaOL%2F3uafHHg1%2F%2B6Xn%2BexxY2srq5OKNhs3FWIdd07wdR76xFW2SGa86sQqn6vFYzeg%3D%3D--md3L0ZgpqH4CmuTu--C9cpDGB9yOBsoNl4z3ivIQ%3D%3D'},\n",
    "        {'name': 'TSd091cc5a027', 'value': '08ac97c60eab2000ffbe1b9cf025675bb1526cd069f3d6c33c069bf3b00b6a0cc94c962a8ec9ff64084342fb361130002eaafe37980af451e70b0b4d170ac4da0ab37739a3781d7fbf668fbc5bf9c0edbc248ede0a4510fe2310b0695f8fdacc'},\n",
    "        {'name': 'OptanonConsent', 'value': 'isGpcEnabled=0&datestamp=Thu+Jun+06+2024+20%3A09%3A21+GMT%2B0100+(British+Summer+Time)&version=202401.2.0&browserGpcFlag=0&isIABGlobal=false&hosts=&consentId=d771d464-7a78-4757-91b3-39bade7bccaa&interactionCount=1&landingPath=NotLandingPage&groups=C0001%3A1%2CC0002%3A1%2CC0004%3A1&geolocation=GB%3BENG&AwaitingReconsent=false'},\n",
    "        {'name': '_ga_ZP882GSBL8', 'value': 'GS1.2.1717700942.6.1.1717700961.0.0.0'},\n",
    "        {'name': '_ga_HHWFVJSD1E', 'value': 'GS1.1.1717700944.9.1.1717700962.0.0.0'},\n",
    "        {'name': '_ga', 'value': 'GA1.1.1376912539.1714483850'}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        # Open the web page\n",
    "        driver.get(i)\n",
    "\n",
    "        # Add cookies to the session\n",
    "        for cookie in cookies:\n",
    "            driver.add_cookie(cookie)\n",
    "\n",
    "        # Refresh the page to apply the cookies\n",
    "        driver.refresh()\n",
    "\n",
    "        # Wait for the 'Ball by Ball' tab to be clickable and click it\n",
    "        wait = WebDriverWait(driver, 7)\n",
    "       \n",
    "        ball_by_ball_tab = wait.until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"iasBallbyballtab-tab\"]')))\n",
    "        ball_by_ball_tab.click()\n",
    "\n",
    "        # Wait for the data to load (you may need to adjust the wait time or the condition)\n",
    "        time.sleep(3)  # Adjust this sleep time if necessary\n",
    "\n",
    "        # Scrape the data you need\n",
    "        \n",
    "        data_elements = driver.find_elements(By.XPATH, '//*[@id=\"iasBallbyball\"]/div/div[2]/div[2]/div')\n",
    "        if data_elements == []:\n",
    "            continue\n",
    "        for element in data_elements:\n",
    "            element_html1 = element.get_attribute('outerHTML')\n",
    "        if (len(element_html1))< 1000:\n",
    "            continue\n",
    "        try:\n",
    "            ball_by_ball_tab = wait.until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"iasBallbyball\"]/div/div[1]/ul/li[2]')))\n",
    "\n",
    "            ball_by_ball_tab.click()\n",
    "\n",
    "            time.sleep(3)  # Adjust this sleep time if necessary\n",
    "\n",
    "            # Scrape the data you need\n",
    "            data_elements = driver.find_elements(By.XPATH, '//*[@id=\"iasBallbyball\"]/div/div[2]/div[2]/div')\n",
    "            for element in data_elements:\n",
    "                element_html2 = element.get_attribute('outerHTML')\n",
    "        except TimeoutException:\n",
    "            driver.quit()\n",
    "    finally:\n",
    "        # Close the WebDriver\n",
    "        driver.quit()\n",
    "\n",
    "    response1 = requests.get(i)\n",
    "    soup = BeautifulSoup(response1.content, 'html.parser')\n",
    "    td=soup.find_all('td',class_=\"col-md-4 text-center v-top\")\n",
    "    tdc=soup.find('td',class_=\"col-md-4 text-center bluebg-top\")\n",
    "    team1_name = team1_score = team1_toss_info = ''\n",
    "    team2_name = team2_score = team2_toss_info = ''\n",
    "\n",
    "    # Extract team data\n",
    "    team_data = []\n",
    "\n",
    "    for i, team in enumerate(td):\n",
    "        score1 = tdc\n",
    "        team_name = team.find('p', class_='team-name').text.strip()\n",
    "        team_info_2 = team.find('p', class_='team-info-2')\n",
    "        score = team.find('p', class_='team-info-2').get_text(separator=' ', strip=True)\n",
    "        score = ' '.join(score)\n",
    "        toss_info = team.find('p', class_='team-info-3 adma')\n",
    "        team_namex = ''\n",
    "        try:\n",
    "            team_namex = score1.find('p', class_='match-ttl win-cb-name').text.strip()\n",
    "        except AttributeError:\n",
    "            pass  # Handle the case where the element is not found, or do nothing\n",
    "        # Extract the match result\n",
    "        \n",
    "        if team_namex:\n",
    "            match_result_div = score1.find('div', class_='info mdont')\n",
    "            match_result = match_result_div.text.strip()\n",
    "            span_text = match_result_div.find('span').text.strip()\n",
    "        else:\n",
    "            match_result=\" \"\n",
    "            span_text=\" \"\n",
    "        # Combine the match result with the text inside the span tag\n",
    "        full_match_result = f\"{team_namex} {match_result} {span_text}\"\n",
    "        if not toss_info:\n",
    "            toss_info = team.find('p', class_='team-info-3')\n",
    "        toss_info = toss_info.text.strip() if toss_info else 'None'\n",
    "        if i == 0:\n",
    "            team1_name = team_name\n",
    "            team1_score = score\n",
    "            team1_toss_info = toss_info\n",
    "        elif i == 1:\n",
    "            team2_name = team_name\n",
    "            team2_score = score\n",
    "            team2_toss_info = toss_info\n",
    "\n",
    "    # Print the extracted data\n",
    "    team_data_dict = {\n",
    "        'team1name': team1_name,\n",
    "        'team1score': team1_score,\n",
    "        'team1tossinfo': team1_toss_info,\n",
    "        'team2name': team2_name,\n",
    "        'team2score': team2_score,\n",
    "        'team2tossinfo': team2_toss_info,\n",
    "        'full_match_result':full_match_result\n",
    "    }\n",
    "\n",
    "    innings=1\n",
    "    if team_data_dict['team1tossinfo']== 'Won the toss and elected to bat':\n",
    "        n=\"1\"\n",
    "    elif team_data_dict['team1tossinfo']== 'Won the toss and elected to field':\n",
    "        n=\"2\"\n",
    "    elif team_data_dict['team2tossinfo']== 'Won the toss and elected to bat':\n",
    "        n=\"2\"\n",
    "    elif team_data_dict['team2tossinfo']== 'Won the toss and elected to field':\n",
    "        n=\"1\"\n",
    "    \n",
    "    \n",
    "    columns = ['Over', 'Ball', 'Event', 'Commentary', 'innings', 'teamname',\n",
    "               'teamscore', 'teamtossinfo', 'full_match_result', 'Player', 'Dismissal', 'R', 'B', '4s', '6s', 'SR']\n",
    "\n",
    "    # Create an empty DataFrame with specified columns\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    for i in [element_html1,element_html2]:\n",
    "        soup = BeautifulSoup(i, 'html.parser')\n",
    "        over_containers = soup.find_all('div', class_='BallByBallStyle__OverContainer-sc-1u6d087-4')\n",
    "\n",
    "        # List to hold all ball data\n",
    "        all_ball_data = []\n",
    "\n",
    "        # Loop through each over container and extract ball data\n",
    "        for over_container in over_containers:\n",
    "            over_number = over_container.find('span', class_='BallByBallStyle__OverHeading-sc-1u6d087-5').text.strip()\n",
    "            ball_containers = over_container.find_all('div', class_='BallDetailViewStyle__BallContainerInner-sc-19vwj2-2')\n",
    "            teamname=\"team\"+n+\"name\"\n",
    "            teamscore=\"team\"+n+\"score\"\n",
    "            teamtossinfo=\"team\"+n+\"tossinfo\"\n",
    "            \n",
    "            for ball_container in ball_containers:\n",
    "                ball_data = {}\n",
    "                ball_data['Over'] = over_number\n",
    "                ball_data['Ball'] = ball_container.find('div', class_='BallDetailViewStyle__StandardContainer-sc-19vwj2-3').text.strip()\n",
    "                ball_data['Event'] = ball_container.find('div', class_='BallDetailViewStyle__CenterStandardContainer-sc-19vwj2-4').text.strip()\n",
    "                ball_data['Commentary'] = ball_container.find('div', class_='BallDetailViewStyle__CommentaryContainer-sc-19vwj2-5').text.strip()\n",
    "                ball_data['innings'] = innings\n",
    "                ball_data['teamname'] = team_data_dict[teamname]\n",
    "                ball_data['teamscore'] = team_data_dict[teamscore]\n",
    "                ball_data['teamtossinfo'] = team_data_dict[teamtossinfo]\n",
    "                ball_data['full_match_result']=team_data_dict[\"full_match_result\"]\n",
    "                # Additional player data if available\n",
    "                player_container = ball_container.find('div', class_='BallDetailViewStyle__WicketInformationContainer-sc-19vwj2-6')\n",
    "                if player_container:\n",
    "                    ball_data['Player'] = player_container.find('div', class_='BallDetailViewStyle__PersonName-sc-19vwj2-9').text.strip()\n",
    "                    ball_data['Dismissal'] = player_container.find('div', class_='BallDetailViewStyle__PersonDismissal-sc-19vwj2-10').text.strip()\n",
    "                    stats_containers = player_container.find_all('div', class_='BallDetailViewStyle__StatItem-sc-19vwj2-12')\n",
    "                    for stat_container in stats_containers:\n",
    "                        stat_heading = stat_container.find('div', class_='BallDetailViewStyle__StatHeading-sc-19vwj2-13').text.strip()\n",
    "                        stat_value = stat_container.find('div', class_='BallDetailViewStyle__StatValue-sc-19vwj2-14').text.strip()\n",
    "                        ball_data[stat_heading] = stat_value\n",
    "\n",
    "                all_ball_data.append(ball_data)\n",
    "        if team_data_dict['team1tossinfo']== 'Won the toss and elected to bat':\n",
    "            n=\"2\"\n",
    "        elif team_data_dict['team1tossinfo']== 'Won the toss and elected to field':\n",
    "            n=\"1\"\n",
    "        elif team_data_dict['team2tossinfo']== 'Won the toss and elected to bat':\n",
    "            n=\"1\"\n",
    "        elif team_data_dict['team2tossinfo']== 'Won the toss and elected to field':\n",
    "            n=\"2\"\n",
    "        # Create DataFrame\n",
    "        df1 = pd.DataFrame(all_ball_data)\n",
    "        df = pd.concat([df, df1], ignore_index=True)\n",
    "        innings=innings+1\n",
    "    df_data = pd.concat([df_data, df], ignore_index=True)\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a580bd64-6a6c-4ef2-8919-f4c6f2e9e737",
   "metadata": {},
   "source": [
    "The script processes a DataFrame df_data to assign the bowling team for each row based on the innings information. It begins by creating a new column, 'batting team', which copies the values from the existing 'teamname' column. Additionally, it initializes another column, 'bowling team', with None to store the name of the opposing team.\n",
    "\n",
    "To populate the 'bowling team' column, the script iterates through each row of the DataFrame. For rows where the innings is 1, the script searches subsequent rows to find the first occurrence of innings 2. It assigns the team name from this innings 2 row as the bowling team for the current innings 1 row.\n",
    "\n",
    "Conversely, for rows where the innings is 2, the script looks backward through previous rows to locate the most recent occurrence of innings 1. The team name from this innings 1 row is then assigned as the bowling team for the current innings 2 row.\n",
    "\n",
    "This approach effectively pairs each batting team with the corresponding bowling team based on the sequence of innings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caae4491-4f54-4cc8-a8e4-1dc983a4f466",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['batting team'] = df_data['teamname']\n",
    "\n",
    "# Initialize the bowling team column with None\n",
    "df_data['bowling team'] = None\n",
    "\n",
    "# Iterate over the DataFrame to set the bowling team\n",
    "for i in range(len(df_data)):\n",
    "    if df_data.at[i, 'innings'] == 1:\n",
    "        # For innings 1, find the next row with innings 2\n",
    "        for j in range(i + 1, len(df_data)):\n",
    "            if df_data.at[j, 'innings'] == 2:\n",
    "                df_data.at[i, 'bowling team'] = df_data.at[j, 'teamname']\n",
    "                break\n",
    "    elif df_data.at[i, 'innings'] == 2:\n",
    "        # For innings 2, find the previous row with innings 1\n",
    "        for j in range(i - 1, -1, -1):\n",
    "            if df_data.at[j, 'innings'] == 1:\n",
    "                df_data.at[i, 'bowling team'] = df_data.at[j, 'teamname']\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2042ad74-8c03-4f80-b9b3-91f235862161",
   "metadata": {},
   "source": [
    "The provided script defines a function, extract_details, designed to parse and extract specific details from a cricket match commentary. This function takes a string of commentary text and attempts to split it into three components: the bowler's name, the batsman's name, and the number of runs scored.\n",
    "\n",
    "The function begins by splitting the commentary into two parts using the phrase \"to \" as the delimiter. This division separates the text into the bowler's part and the remainder, which contains the batsman's name and runs. Next, the function further splits the remainder by the colon \":\" to isolate the batsman's name from the runs scored. It then trims any extra whitespace from these components.\n",
    "\n",
    "In cases where the commentary does not match the expected format, the function handles potential errors by assigning None to all three variables: bowler, batsman, and runs.\n",
    "\n",
    "The script then applies this function to the 'Commentary' column of the DataFrame df_data. It uses the apply method with a lambda function to transform each commentary string into a pandas Series containing the extracted details. These details are then assigned to new columns in the DataFrame: 'bowler', 'batsman', and 'runs'.\n",
    "\n",
    "Finally, the updated DataFrame, now enriched with the extracted details, is ready for further analysis or reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3934e8dc-9673-41b3-bae9-48e67dcf3c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract bowler, batsman, and runs\n",
    "def extract_details(commentary):\n",
    "    # Split the commentary into parts\n",
    "    try:\n",
    "        bowler_part, batsman_part = commentary.split(\"to \")\n",
    "        batsman, runs = batsman_part.split(\":\")\n",
    "        bowler = bowler_part.strip()\n",
    "        batsman = batsman.strip() if batsman else None\n",
    "        runs = runs.strip()\n",
    "    except ValueError:\n",
    "        # In case of unexpected format\n",
    "        bowler, batsman, runs = None, None, None\n",
    "    \n",
    "    return bowler, batsman, runs\n",
    "\n",
    "# Apply the function to the Commentary column\n",
    "df_data[['bowler', 'batsman', 'runs']] = df_data['Commentary'].apply(lambda x: pd.Series(extract_details(x)))\n",
    "\n",
    "# Print the updated DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5c4b19-e969-4568-887a-2ef72a0dc6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_rows = df_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e6fb04-5b38-4294-af09-1f4829b95372",
   "metadata": {},
   "source": [
    "The script concludes by saving the processed data into an Excel file for convenience and efficiency. The variable excel_path specifies the path where the Excel file will be stored, named 'finaldesertation.xlsx'. The DataFrame unique_rows is written to this file using the to_excel method, with the index=False parameter to exclude the DataFrame's index from the output.\n",
    "\n",
    "This step is crucial because rerunning the data extraction and processing code is time-consuming, often taking between four to six hours to complete. By saving the final processed data into an Excel file, users can avoid the need for repeated lengthy computations. Instead, they can load the stored file for subsequent analysis or use, significantly reducing the overall time and effort required for data handling. This approach ensures that the results are preserved and readily accessible without the need to repeatedly execute the complex and time-intensive code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb191ee-a8c8-4061-8cb0-5756cfea7cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_path = 'finaldesertation.xlsx'\n",
    "unique_rows.to_excel(excel_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509532d7-aff0-4e07-afa1-d19051d8b1c2",
   "metadata": {},
   "source": [
    "Part 2(The next set of program uses the excel data genetated in the above code) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d0e016-0e91-4694-ba5c-dd246e547c77",
   "metadata": {},
   "source": [
    "The code snippet starts by reading data from an Excel file into a pandas DataFrame using pd.read_excel(\"finaldesertation.xlsx\"). It then removes duplicate rows with df.drop_duplicates(), ensuring that each record is unique and eliminating potential redundancies. To address any irregularity in the DataFrame’s indexing after duplicate removal, df.reset_index(drop=True, inplace=True) is used, which resets the index to a sequential integer format. Finally, the rows are reversed with df.iloc[::-1] to rearrange the data, often to prioritize recent entries or match a required format. The index is reset again with reset_index(drop=True) to maintain a clean, sequential index. These steps collectively prepare the DataFrame by cleaning, reindexing, and reordering the data, ensuring it is in a well-organized state for further analysis or processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f134b2-e904-4c33-8d25-171ae0539a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_excel(\"finaldesertation.xlsx\")\n",
    "df = df.drop_duplicates()\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df = df.iloc[::-1].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05db18f1-762d-4a42-832f-a00b4855e3a4",
   "metadata": {},
   "source": [
    "The provided code defines a function calculate_metrics designed to process cricket match data and compute various performance metrics for batsmen and bowlers. The function begins by initializing dictionaries to store metrics for each player and setting up dictionaries for scoring, dismissals, and extras.\n",
    "\n",
    "The function iterates over each row of the DataFrame, extracting details such as the event, bowler, batsman, and bowling team. It then checks and updates the metrics for both batsmen and bowlers based on the event type. For instance, runs are updated in the batsman_metrics dictionary, and any dismissals or extras are recorded. The function also handles the transition between innings by saving scores for batsmen when a new bowling team is detected.\n",
    "\n",
    "Additional calculations are performed to determine averages, strike rates, and economy rates for both batsmen and bowlers. For batsmen, metrics such as runs scored, balls faced, and boundaries are recorded, along with calculating batting averages and strike rates. For bowlers, runs conceded, wickets taken, and economy rates are calculated.\n",
    "\n",
    "The function ultimately returns the dictionaries containing detailed metrics for both batsmen and bowlers, which are then printed for review. This comprehensive approach allows for an in-depth analysis of player performances throughout the match.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773d5e10-c3c8-42d4-b482-68deab3447f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from decimal import Decimal\n",
    "\n",
    "# Function to process events and calculate metrics for batsmen and bowlers\n",
    "def calculate_metrics(df):\n",
    "    # Initialize dictionaries to hold metrics\n",
    "    batsman_metrics = {}\n",
    "    bowler_metrics = {}\n",
    "\n",
    "    # Define scoring rules\n",
    "    runs_scored = {\n",
    "        '0 runs': 0, '1 run': 1, '2 runs': 2, '3 runs': 3, '4 runs': 4, '6 runs': 6,\n",
    "        '1 run \\n 1 no ball': 1, '2 runs \\n 1 no ball': 2, '3 runs \\n 1 no ball': 3, \n",
    "        '4 runs \\n 1 no ball': 4, '6 runs \\n 1 no ball': 6, '5 runs': 5,\n",
    "        '1 run \\n 2 no balls': 1, '4 runs \\n 2 no balls': 4,\n",
    "    }\n",
    "    \n",
    "    dismissals = [\n",
    "        'Wicket!', 'Wicket! \\n 2 wides', 'Wicket! \\n 1 run \\n 1 no ball', \n",
    "        'Wicket! \\n 1 run', 'Wicket! \\n 2 runs', 'Wicket! \\n 1 bye', \n",
    "        'Wicket! \\n 1 no ball', 'Wicket! \\n 1 wide', 'Wicket! \\n 1 leg bye'\n",
    "    ]\n",
    "\n",
    "    extras = {\n",
    "        '1 wide': 1, '2 wides': 2, '3 wides': 3, '4 wides': 4, '5 wides': 5, '6 wides': 6,\n",
    "        '1 no ball': 1, '2 no balls': 2, '1 bye': 1, '2 byes': 2, '3 byes': 3, \n",
    "        '4 byes': 4, '5 byes': 5, '1 leg bye': 1, '2 leg byes': 2, '3 leg byes': 3, \n",
    "        '4 leg byes': 4, '2 1nb + byes': 2, '3 1nb + byes': 3, '6 1nb + byes': 6, \n",
    "        '5 1nb + byes': 5, '4 1nb + byes': 4, '2 1nb + leg byes': 2\n",
    "    }\n",
    "\n",
    "    previous_bowling_team = None\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        event = row['Event']\n",
    "        bowler = row['bowler']\n",
    "        batsman = row['batsman']\n",
    "        bowling_team = row['bowling team']\n",
    "        over = int(row['Over'][5:])\n",
    "\n",
    "        # Initialize batsman and bowler if not already in the dictionary\n",
    "        if batsman not in batsman_metrics:\n",
    "            batsman_metrics[batsman] = {'runs': 0, 'boundaries': 0, 'dismissal': 0, 'balls_faced': 0, 'innings': 0, 'scores': []}\n",
    "        if bowler not in bowler_metrics:\n",
    "            bowler_metrics[bowler] = {'runs_conceded': 0, 'wickets': 0, 'extras': 0, 'balls_bowled': 0, 'innings': 0}\n",
    "\n",
    "        # Handle change in batting team (new match or new innings)\n",
    "        if previous_bowling_team is not None and previous_bowling_team != bowling_team:\n",
    "            # Save the scores for all batsmen\n",
    "            for b in batsman_metrics:\n",
    "                if batsman_metrics[b]['runs'] > 0:\n",
    "                    batsman_metrics[b]['scores'].append(batsman_metrics[b]['runs'])\n",
    "                    batsman_metrics[b]['runs'] = 0\n",
    "\n",
    "        # Calculate metrics for batsmen\n",
    "        if event in runs_scored:\n",
    "            runs = runs_scored[event]\n",
    "            batsman_metrics[batsman]['runs'] += runs\n",
    "            batsman_metrics[batsman]['balls_faced'] += 1\n",
    "            if runs >= 4:\n",
    "                batsman_metrics[batsman]['boundaries'] += 1\n",
    "\n",
    "        if event in dismissals:\n",
    "            batsman_metrics[batsman]['balls_faced'] += 1\n",
    "            batsman_metrics[batsman]['dismissal'] += 1\n",
    "            batsman_metrics[batsman]['scores'].append(batsman_metrics[batsman]['runs'])\n",
    "            batsman_metrics[batsman]['runs'] = 0  # Reset runs for the next innings\n",
    "\n",
    "        # Calculate metrics for bowlers\n",
    "        if event in runs_scored:\n",
    "            bowler_metrics[bowler]['runs_conceded'] += runs_scored[event]\n",
    "            bowler_metrics[bowler]['balls_bowled'] += 1\n",
    "\n",
    "        if event in dismissals:\n",
    "            bowler_metrics[bowler]['wickets'] += 1\n",
    "\n",
    "        if event in extras:\n",
    "            bowler_metrics[bowler]['extras'] += extras[event]\n",
    "            bowler_metrics[bowler]['runs_conceded'] += extras[event]\n",
    "\n",
    "        previous_bowling_team = bowling_team\n",
    "\n",
    "    # Ensure last innings runs are recorded\n",
    "    for batsman in batsman_metrics:\n",
    "        if batsman_metrics[batsman]['runs'] > 0:\n",
    "            batsman_metrics[batsman]['scores'].append(batsman_metrics[batsman]['runs'])\n",
    "\n",
    "    # Calculate additional metrics for batsmen\n",
    "    for batsman in batsman_metrics:\n",
    "        runs = sum(batsman_metrics[batsman]['scores'])\n",
    "        dismissal = batsman_metrics[batsman]['dismissal']\n",
    "        balls_faced = batsman_metrics[batsman]['balls_faced']\n",
    "\n",
    "        average = runs / dismissal if dismissal > 0 else runs\n",
    "        strike_rate = (runs / balls_faced * 100) if balls_faced > 0 else Decimal('0')\n",
    "        highest_score = max(batsman_metrics[batsman]['scores']) if batsman_metrics[batsman]['scores'] else runs\n",
    "\n",
    "        batsman_metrics[batsman]['average'] = average\n",
    "        batsman_metrics[batsman]['strike_rate'] = strike_rate\n",
    "        batsman_metrics[batsman]['highest_score'] = highest_score\n",
    "        batsman_metrics[batsman]['runs'] = runs\n",
    "        batsman_metrics[batsman]['innings'] = len(batsman_metrics[batsman]['scores'])\n",
    "\n",
    "    # Calculate additional metrics for bowlers\n",
    "    for bowler in bowler_metrics:\n",
    "        runs_conceded = bowler_metrics[bowler]['runs_conceded']\n",
    "        wickets = bowler_metrics[bowler]['wickets']\n",
    "        balls_bowled = bowler_metrics[bowler]['balls_bowled']\n",
    "\n",
    "        bowler_metrics[bowler]['average'] = runs_conceded / wickets if wickets > 0 else runs_conceded\n",
    "        bowler_metrics[bowler]['strike_rate'] = balls_bowled / wickets if wickets > 0 else balls_bowled\n",
    "        bowler_metrics[bowler]['economy_rate'] = (runs_conceded / (balls_bowled / 6)) if balls_bowled > 0 else 0\n",
    "\n",
    "    return batsman_metrics, bowler_metrics\n",
    "\n",
    "\n",
    "\n",
    "# Calculate metrics\n",
    "batsman_metrics, bowler_metrics = calculate_metrics(df)\n",
    "\n",
    "# Print results\n",
    "print(\"Batsman Metrics:\", batsman_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fd2736-8d7f-4bc1-b0dd-01bd7a9d0572",
   "metadata": {},
   "source": [
    "The line filters the batsman_metrics dictionary to exclude any entries where the key is NaN, ensuring that only valid batsman entries are retained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6564b5-6597-4c06-8798-fd4a307bf378",
   "metadata": {},
   "outputs": [],
   "source": [
    "batsman_metrics = {k: v for k, v in batsman_metrics.items() if pd.notna(k)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96b12ef-3577-4d38-9c33-876c47ba35fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, metrics in batsman_metrics.items():\n",
    "    if metrics['dismissal'] != 0:  # Avoid division by zero\n",
    "        metrics['dismissal'] = 1 / metrics['dismissal']\n",
    "\n",
    "# Display the updated dictionary\n",
    "print(batsman_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84be9eeb-be65-4fc7-a232-f1f22ec88afb",
   "metadata": {},
   "source": [
    "The provided code snippet is designed to process cricket match data from an Excel file and update the innings count for bowlers based on the parsed data. Here's a detailed explanation of how the code achieves this:\n",
    "\n",
    "Loading Data: The code begins by loading data from an Excel file named finaldesertation.xlsx into a DataFrame using pandas. This DataFrame contains records of cricket match events, such as overs, innings, and player actions.\n",
    "\n",
    "Initialize Variables: Two variables are initialized: matches_dataframes to hold DataFrames for each match and current_match to accumulate data for the current inning. The current_inning variable tracks the inning currently being processed.\n",
    "\n",
    "Iterate Over Rows: The code iterates over each row in the DataFrame. If it's the first row or a row from the same inning as the previous row, it continues to add the row to current_match. When a new inning is encountered, the accumulated data for the previous inning is converted into a DataFrame and stored in matches_dataframes. Then, the process starts over for the new inning.\n",
    "\n",
    "Handle Last Match: After the loop, any remaining data in current_match (representing the last inning) is converted into a DataFrame and appended to matches_dataframes.\n",
    "\n",
    "Update Bowler Metrics: For each DataFrame in matches_dataframes, the code updates the innings count for each player in bowler_metrics. It checks if the player from the DataFrame exists in bowler_metrics, and if so, increments the innings count.\n",
    "\n",
    "Output Updated Metrics: Finally, the updated bowler_metrics dictionary, which now includes the updated innings count for each bowler, is printed.\n",
    "\n",
    "This approach ensures that all match data is properly segmented and analyzed, allowing for accurate tracking of player performance across multiple innings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2a9d64-4d14-4427-b3d2-ca251fa7bb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming the data is in a CSV file named 'cricket_data.csv'\n",
    "data = pd.read_excel(\"finaldesertation.xlsx\")\n",
    "\n",
    "# Initialize the list to store data frames\n",
    "matches_dataframes = []\n",
    "\n",
    "# Initialize variables to track the current match\n",
    "current_match = []\n",
    "current_inning = None\n",
    "\n",
    "# Iterate over the rows of the DataFrame\n",
    "for index, row in data.iterrows():\n",
    "    inning = row['innings']\n",
    "    \n",
    "    if current_inning is None:\n",
    "        # First row of the first match\n",
    "        current_inning = inning\n",
    "    \n",
    "    if inning == current_inning:\n",
    "        # Continue collecting data for the current inning\n",
    "        current_match.append(row)\n",
    "    else:\n",
    "        # Switch to the next inning\n",
    "        # Create a DataFrame for the completed match innings and store it\n",
    "        if current_match:\n",
    "            match_df = pd.DataFrame(current_match)\n",
    "            matches_dataframes.append(match_df)\n",
    "        \n",
    "        # Start a new match collection with the current row\n",
    "        current_match = [row]\n",
    "        current_inning = inning\n",
    "    \n",
    "# Add the last match data frame if there's any leftover data\n",
    "if current_match:\n",
    "    match_df = pd.DataFrame(current_match)\n",
    "    matches_dataframes.append(match_df)\n",
    "\n",
    "# Now matches_dataframes is a list of DataFrames, each containing data for one match\n",
    "\n",
    "\n",
    "# Updating innings count for each player in batsman_metrics\n",
    "for df in matches_dataframes:\n",
    "    for player in df['batsman'].unique():\n",
    "        if player in bowler_metrics:\n",
    "            bowler_metrics[player]['innings'] += 1\n",
    "\n",
    "# Output the updated batsman_metrics dictionary\n",
    "print(bowler_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57c0a09-08c8-4df9-b8f9-c49f4d16332a",
   "metadata": {},
   "source": [
    "The provided code snippet outlines a methodical approach to cleaning a DataFrame loaded from an Excel file, enhancing data quality for subsequent analysis. The process begins with loading the dataset from an Excel file named nope.xlsx using the pandas library, which transforms the raw data into a structured DataFrame. This initial step ensures that the data is ready for processing.\n",
    "\n",
    "The first data cleaning task focuses on the teamscore column. This column's entries are subjected to the str.strip() method, which effectively removes any leading or trailing whitespace. Such extra spaces can often occur during data entry or import processes and can cause inconsistencies in data analysis. By stripping these spaces, the data in the teamscore column is standardized, ensuring that all entries are clean and free from unwanted spaces.\n",
    "\n",
    "Next, the code addresses the issue of missing values. It specifies a subset of columns—'R' (Runs), 'B' (Balls Faced), '4s' (Fours), '6s' (Sixes), and 'SR' (Strike Rate)—that are crucial for analysis. The dropna() function is employed to remove any rows from the DataFrame that contain null values in these specified columns. This step is vital as it eliminates incomplete data entries, which could skew results or lead to inaccuracies in statistical analysis. By focusing on these key columns, the code ensures that the dataset maintains its integrity and usability for further processing.\n",
    "\n",
    "Finally, the cleaned DataFrame, now referred to as df_non_null, is displayed using the print() function. This action provides a quick view of the data after the cleaning process, allowing users to verify that the data is now complete and consistent. The output shows a DataFrame devoid of null values in the critical columns, ready for reliable analysis.\n",
    "\n",
    "In summary, the code efficiently cleans the dataset by removing extraneous spaces and filtering out incomplete rows, thereby improving the quality and reliability of the data for future analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d44f3b3-7314-4dbf-a739-8acb7d35c665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_excel(\"nope.xlsx\")\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming the DataFrame is already loaded into df\n",
    "# Replace 'your_dataframe.csv' with the path to your actual data if needed\n",
    "# df = pd.read_csv('your_dataframe.csv')\n",
    "\n",
    "# Removing leading and trailing spaces from the 'teamscore' column\n",
    "df['teamscore'] = df['teamscore'].str.strip()\n",
    "\n",
    "# Creating a new DataFrame without null values in the specified columns\n",
    "columns_to_check = ['R', 'B', '4s', '6s', 'SR']\n",
    "df_non_null = df.dropna(subset=columns_to_check)\n",
    "\n",
    "# Displaying the new DataFrame\n",
    "print(df_non_null)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ff5ffc-d5e0-4203-96c7-543dea1e76a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_non_null['batsman'].unique()))\n",
    "print(len(df_non_null['bowler'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa09e84d-dcc9-470c-8816-321a797623f2",
   "metadata": {},
   "source": [
    "The code calculates the average runs, balls faced, boundaries, and strike rate for each batsman from the df_non_null DataFrame. It then updates the batsman_metrics dictionary with these averages for each player. Finally, it prints the updated batsman_metrics dictionary, reflecting these new statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0fbef5-9655-4159-9e8a-13a2dfc58d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = df_non_null.groupby('batsman').agg({\n",
    "    'R': 'mean',\n",
    "    'B': 'mean',\n",
    "    '4s': 'mean',\n",
    "    '6s': 'mean',\n",
    "    'SR': 'mean'\n",
    "}).reset_index()\n",
    "for index, row in averages.iterrows():\n",
    "    player_name = row['batsman']\n",
    "    if player_name in batsman_metrics:\n",
    "        batsman_metrics[player_name]['average_runs'] = row['R']  # Set runs average\n",
    "        batsman_metrics[player_name]['average_balls_faced'] = row['B']  # Set balls faced average\n",
    "        batsman_metrics[player_name]['average_boundaries'] = row['4s'] + row['6s']  # Set total boundaries\n",
    "        batsman_metrics[player_name]['average_strike_rate'] = row['SR']  # Set strike rate\n",
    "\n",
    "# Print the updated dictionary\n",
    "print(batsman_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b4ee51-c59f-48f9-8ae4-cf3ab94a29a8",
   "metadata": {},
   "source": [
    "Data Preparation: It starts by creating a DataFrame from batsman_metrics, filling missing values with zero, and selecting relevant features for clustering.\n",
    "\n",
    "Standardization and PCA: The features are standardized to ensure uniform scaling. PCA is then applied to reduce the data to four principal components, which are visualized through explained variance and feature contribution heatmaps.\n",
    "\n",
    "Elbow Method: The Elbow method is used to determine the optimal number of clusters by plotting inertia (within-cluster sum of squares) against the number of clusters. This helps identify the point where adding more clusters yields diminishing returns.\n",
    "\n",
    "Silhouette Analysis: The Silhouette score is calculated for different cluster counts to evaluate clustering quality. This score measures how similar an object is to its own cluster compared to other clusters.\n",
    "\n",
    "Clustering and Visualization: Based on the Silhouette score, the optimal number of clusters is selected, and K-Means clustering is performed. The clustered data is visualized using a 3D scatter plot, with clusters color-coded and labeled.\n",
    "\n",
    "Cluster Evaluation: The average Silhouette score for the chosen clusters is printed, and a silhouette plot is created to show the distribution of silhouette scores within each cluster.\n",
    "\n",
    "Cluster Distribution: Finally, a pie chart displays the proportion of players in each cluster, providing a clear distribution overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ff8f0d-1efa-4965-8a9e-9ac517dadb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Sample Data (assuming batsman_metrics is a dictionary and defined)\n",
    "data = batsman_metrics\n",
    "df_bat1 = pd.DataFrame.from_dict(data, orient='index')\n",
    "df_bat1 = df_bat1.fillna(0)\n",
    "\n",
    "# Features to use for clustering\n",
    "features = ['runs', 'boundaries', 'dismissal', 'average', 'strike_rate', 'highest_score',\n",
    "            'balls_faced', 'innings', 'average_strike_rate', 'average_runs', \n",
    "            'average_balls_faced', 'average_boundaries']\n",
    "\n",
    "# Extract features\n",
    "X = df_bat1[features]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=4)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Plot the explained variance ratio as a bar graph\n",
    "plt.figure(figsize=(8, 5))\n",
    "num_components = len(pca.explained_variance_ratio_)\n",
    "plt.bar(range(1, num_components + 1), pca.explained_variance_ratio_, alpha=0.7, align='center')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('Explained Variance Ratio by Principal Component')\n",
    "plt.xticks(range(1, num_components + 1))\n",
    "plt.savefig('explained_variance_ratio.png')  # Save the image\n",
    "plt.show()\n",
    "\n",
    "# Plot the contribution of each feature to each principal component\n",
    "plt.figure(figsize=(10, 7))\n",
    "num_components = pca.components_.shape[0]  # Number of principal components\n",
    "num_features = pca.components_.shape[1]    # Number of features\n",
    "\n",
    "# Ensure the number of row indices matches the number of principal components\n",
    "pc_labels = [f'PC{i+1}' for i in range(num_components)]\n",
    "\n",
    "# Create DataFrame for heatmap\n",
    "heatmap_df = pd.DataFrame(pca.components_, columns=features, index=pc_labels)\n",
    "\n",
    "# Plot heatmap\n",
    "sns.heatmap(heatmap_df, annot=True, cmap='coolwarm')\n",
    "plt.title('Feature Contribution to Principal Components')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Principal Component')\n",
    "plt.savefig('feature_contribution_heatmap.png')  # Save the image\n",
    "plt.show()\n",
    "\n",
    "# Step 1: Determine the optimal number of clusters using the Elbow method\n",
    "inertia = []\n",
    "K_range = range(1, 11)  # Trying 1 to 10 clusters\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans.fit(X_pca)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the Elbow method result\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(K_range, inertia, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.xticks(K_range)\n",
    "plt.grid(True)\n",
    "plt.savefig('elbow_method.png')  # Save the image\n",
    "plt.show()\n",
    "\n",
    "# Step 2: Compute Silhouette Scores for a range of cluster numbers\n",
    "silhouette_scores = []\n",
    "K_range = range(2, 11)  # Silhouette score requires at least 2 clusters\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    clusters = kmeans.fit_predict(X_pca)\n",
    "    silhouette_avg = silhouette_score(X_pca, clusters)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "\n",
    "# Plot the Silhouette Scores\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(K_range, silhouette_scores, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Score for Different Numbers of Clusters')\n",
    "plt.xticks(K_range)\n",
    "plt.grid(True)\n",
    "plt.savefig('silhouette_scores.png')  # Save the image\n",
    "plt.show()\n",
    "\n",
    "# Choose the optimal number of clusters based on silhouette score\n",
    "optimal_k = 2  # Replace this with the optimal number of clusters from the Silhouette Score plot\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=0)\n",
    "clusters = kmeans.fit_predict(X_pca)\n",
    "\n",
    "# Add the cluster number to the DataFrame\n",
    "df_bat1['Cluster'] = clusters\n",
    "\n",
    "# Display the DataFrame with the cluster column\n",
    "print(df_bat1.head())\n",
    "\n",
    "# 3D Scatter Plot with Renamed Clusters\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Define colors for the clusters\n",
    "colors = plt.cm.get_cmap('tab10', optimal_k)\n",
    "\n",
    "# Renaming the clusters\n",
    "cluster_labels = {0: 'Top Cluster Players', 1: 'Average Cluster Players'}\n",
    "\n",
    "for i in range(optimal_k):\n",
    "    ax.scatter(X_pca[clusters == i, 0], X_pca[clusters == i, 1], X_pca[clusters == i, 2],\n",
    "               color=colors(i), label=cluster_labels[i], alpha=0.6)\n",
    "\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "ax.set_title('Initial Clustering of Players')\n",
    "ax.legend()\n",
    "plt.savefig('initial_clustering_players.png')  # Save the image\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Plot Silhouette Scores for Each Cluster\n",
    "silhouette_avg = silhouette_score(X_pca, clusters)\n",
    "print(f'Silhouette Score for {optimal_k} clusters: {silhouette_avg:.2f}')\n",
    "\n",
    "# Compute silhouette scores for each sample\n",
    "sample_silhouette_values = silhouette_samples(X_pca, clusters)\n",
    "\n",
    "# Create a silhouette plot\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "y_lower = 10\n",
    "for i in range(optimal_k):\n",
    "    # Aggregate the silhouette scores for samples belonging to cluster i\n",
    "    cluster_silhouette_values = sample_silhouette_values[clusters == i]\n",
    "    cluster_silhouette_values.sort()\n",
    "    \n",
    "    # Compute the size of the cluster\n",
    "    size_cluster_i = cluster_silhouette_values.shape[0]\n",
    "    \n",
    "    # Plot the silhouette scores for cluster i\n",
    "    ax.fill_betweenx(np.arange(y_lower, y_lower + size_cluster_i),\n",
    "                     0, cluster_silhouette_values,\n",
    "                     facecolor=colors(i), alpha=0.7)\n",
    "    \n",
    "    # Add the cluster label\n",
    "    ax.text(-0.05, y_lower + 0.5 * size_cluster_i, cluster_labels[i],\n",
    "            color='black', va='center', ha='right', fontsize=12)\n",
    "    \n",
    "    # Update y_lower for the next cluster\n",
    "    y_lower += size_cluster_i\n",
    "\n",
    "ax.set_xlabel('Silhouette coefficient values')\n",
    "ax.set_ylabel('Cluster')\n",
    "ax.set_title('Silhouette Plot for the Clusters')\n",
    "plt.savefig('silhouette_plot.png')  # Save the image\n",
    "plt.show()\n",
    "\n",
    "# Pie Chart of Total Number of Points in Each Cluster with Custom Labels\n",
    "cluster_counts = df_bat1['Cluster'].value_counts()\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Custom labels for the pie chart\n",
    "pie_labels = [cluster_labels[i] for i in cluster_counts.index]\n",
    "\n",
    "plt.pie(cluster_counts, labels=pie_labels, autopct='%1.1f%%', colors=plt.cm.tab10(range(optimal_k)))\n",
    "plt.title('Distribution of Players in Initial Clustering')\n",
    "plt.savefig('cluster_distribution_pie_chart.png')  # Save the pie chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e148c948-b0e3-46d6-a46f-ba03d2b26cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'scores' column from the DataFrame\n",
    "df_bat1 = df_bat1.drop(columns=['scores'])\n",
    "\n",
    "# Ensure all columns are numeric\n",
    "df_bat1 = df_bat1.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Compute the mean of each feature by cluster\n",
    "cluster_means1 = df_bat1.groupby('Cluster').mean()\n",
    "\n",
    "# Display the cluster means\n",
    "print(cluster_means1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71badd63-bc78-4207-86f4-bf8789a625c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_1_df = df_bat1[df_bat1['Cluster'] == 0]\n",
    "cluster_i = df_bat1[df_bat1['Cluster'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c114e197-849a-48d4-a548-323e0cde85e1",
   "metadata": {},
   "source": [
    "From the first clustering averages were computed and the one with best average scores if further clustered to find the clusters with top, good and average players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7409feca-4b88-4224-9bdd-4407ae06337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Sample data\n",
    "df_bat2 = cluster_1_df\n",
    "\n",
    "# Features to use for clustering\n",
    "features = ['runs', 'boundaries', 'dismissal', 'average', 'strike_rate', 'highest_score',\n",
    "            'balls_faced', 'innings', 'average_strike_rate', 'average_runs', \n",
    "            'average_balls_faced', 'average_boundaries']\n",
    "# Extract features\n",
    "X = df_bat2[features]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=4)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Plot the explained variance ratio as a bar graph\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(range(1, 5), pca.explained_variance_ratio_, alpha=0.7, align='center')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('Explained Variance Ratio by Principal Component')\n",
    "plt.xticks(range(1, 5))\n",
    "plt.show()\n",
    "\n",
    "# Plot the contribution of each feature to each principal component\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(pd.DataFrame(pca.components_, columns=features, index=['PC1', 'PC2', 'PC3', 'PC4']),\n",
    "            annot=True, cmap='coolwarm')\n",
    "plt.title('Feature Contribution to Principal Components')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Principal Component')\n",
    "plt.show()\n",
    "\n",
    "# Step 1: Determine the optimal number of clusters using the Elbow method\n",
    "inertia = []\n",
    "K_range = range(1, 11)  # Trying 1 to 10 clusters\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans.fit(X_pca)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the Elbow method result\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(K_range, inertia, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.xticks(K_range)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Step 2: Compute Silhouette Scores for a range of cluster numbers\n",
    "silhouette_scores = []\n",
    "K_range = range(2, 11)  # Silhouette score requires at least 2 clusters\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    clusters = kmeans.fit_predict(X_pca)\n",
    "    silhouette_avg = silhouette_score(X_pca, clusters)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "\n",
    "# Plot the Silhouette Scores\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(K_range, silhouette_scores, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Score for Different Numbers of Clusters')\n",
    "plt.xticks(K_range)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Choose the optimal number of clusters based on silhouette score\n",
    "optimal_k = 2  # Replace this with the optimal number of clusters from the Silhouette Score plot\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=0)\n",
    "clusters = kmeans.fit_predict(X_pca)\n",
    "\n",
    "# Add the cluster number to the DataFrame\n",
    "df_bat2['Cluster'] = clusters\n",
    "\n",
    "# Display the DataFrame with the cluster column\n",
    "print(df_bat2.head())\n",
    "\n",
    "# 3D Scatter Plot\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Define colors for the clusters\n",
    "colors = plt.cm.get_cmap('tab10', optimal_k)\n",
    "\n",
    "cluster_labels = {0: 'Excellent players cluster', 1: 'Good players cluster'}\n",
    "\n",
    "for i in range(optimal_k):\n",
    "    ax.scatter(X_pca[clusters == i, 0], X_pca[clusters == i, 1], X_pca[clusters == i, 2],\n",
    "               color=colors(i), label=cluster_labels[i], alpha=0.6)\n",
    "\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "ax.set_title('Final Clustering of Top Cluster Players')\n",
    "ax.legend()\n",
    "plt.savefig('final_clustering_of_top_cluster_players.png')  # Save the image\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Plot Silhouette Scores for Each Cluster\n",
    "silhouette_avg = silhouette_score(X_pca, clusters)\n",
    "print(f'Silhouette Score for {optimal_k} clusters: {silhouette_avg:.2f}')\n",
    "\n",
    "# Compute silhouette scores for each sample\n",
    "sample_silhouette_values = silhouette_samples(X_pca, clusters)\n",
    "\n",
    "# Create a silhouette plot\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "y_lower = 10\n",
    "for i in range(optimal_k):\n",
    "    # Aggregate the silhouette scores for samples belonging to cluster i\n",
    "    cluster_silhouette_values = sample_silhouette_values[clusters == i]\n",
    "    cluster_silhouette_values.sort()\n",
    "    \n",
    "    # Compute the size of the cluster\n",
    "    size_cluster_i = cluster_silhouette_values.shape[0]\n",
    "    \n",
    "    # Plot the silhouette scores for cluster i\n",
    "    ax.fill_betweenx(np.arange(y_lower, y_lower + size_cluster_i),\n",
    "                     0, cluster_silhouette_values,\n",
    "                     facecolor=colors(i), alpha=0.7)\n",
    "    \n",
    "    # Add the cluster label\n",
    "    ax.text(-0.05, y_lower + 0.5 * size_cluster_i, f'Cluster {i}',\n",
    "            color='black', va='center', ha='right', fontsize=12)\n",
    "    \n",
    "    # Update y_lower for the next cluster\n",
    "    y_lower += size_cluster_i\n",
    "\n",
    "ax.set_xlabel('Silhouette coefficient values')\n",
    "ax.set_ylabel('Cluster')\n",
    "ax.set_title('Silhouette Plot for the Clusters')\n",
    "plt.show()\n",
    "\n",
    "# Pie Chart of Total Number of Points in Each Cluster with Custom Labels\n",
    "cluster_counts = df_bat2['Cluster'].value_counts()\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Custom labels for the pie chart\n",
    "pie_labels = [cluster_labels[i] for i in cluster_counts.index]\n",
    "\n",
    "plt.pie(cluster_counts, labels=pie_labels, autopct='%1.1f%%', colors=plt.cm.tab10(range(optimal_k)))\n",
    "plt.title('Distribution of Players in Final Clustering(clustering of top players cluster)')\n",
    "plt.savefig('cluster_distribution_pie_chart.png')  # Save the pie chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797a4d70-81b5-407d-91e5-9c5f2592f327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'scores' column from the DataFrame\n",
    "#df_bat2 = df_bat2.drop(columns=['scores'])\n",
    "\n",
    "# Compute the mean of each feature by cluster\n",
    "cluster_means = df_bat2.groupby('Cluster').mean()\n",
    "\n",
    "# Display the cluster means\n",
    "print(cluster_means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b85be8-1ef6-45a1-9a4b-8951aeba66a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_ii = df_bat2[df_bat2['Cluster'] == 1]\n",
    "cluster_iii = df_bat2[df_bat2['Cluster'] == 0]\n",
    "cluster_ii['rating'] = 2\n",
    "cluster_iii['rating'] = 3\n",
    "cluster_i['rating'] = 1\n",
    "combined_df = pd.concat([cluster_ii, cluster_iii, cluster_i])\n",
    "\n",
    "# Reset index if needed (optiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5977a07d-ef90-4efb-96cf-bfc505b5eec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_lowb = df_bat1[df_bat1['Cluster'].isin([1])].index.tolist()\n",
    "cluster_low_mediumb = df_bat2[df_bat2['Cluster'].isin([1])].index.tolist()\n",
    "cluster_mediumb = df_bat2[df_bat2['Cluster'].isin([0])].index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683af419-0872-401f-9325-b31998179581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pdf0=pd.read_excel(\"finaldesertation.xlsx\")\n",
    "pdf0 = pdf0.drop_duplicates()\n",
    "pdf0['batter_rating'] = 0\n",
    "\n",
    "# Assign ratings based on cluster membership\n",
    "pdf0.loc[pdf0['batsman'].isin(cluster_mediumb), 'batter_rating'] = 3\n",
    "#pdf.loc[pdf['bowler'].isin(cluster_high), 'bowler_rating'] = 5\n",
    "pdf0.loc[pdf0['batsman'].isin(cluster_low_mediumb), 'batter_rating'] = 2\n",
    "pdf0.loc[pdf0['batsman'].isin(cluster_lowb), 'batter_rating'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8b4a4e-2627-48d1-9b89-447c2b45e0ce",
   "metadata": {},
   "source": [
    "The code provided performs hierarchical clustering on a dataset of batsman metrics, visualizing the results using a dendrogram. Here’s a step-by-step breakdown:\n",
    "\n",
    "First, the necessary libraries are imported: pandas for data manipulation, numpy for numerical operations, scipy for clustering and distance calculations, and matplotlib for plotting. Additionally, the MinMaxScaler from sklearn is used to normalize the data.\n",
    "\n",
    "The dataset, assumed to be a dictionary named batsman_metrics, is converted into a DataFrame. This DataFrame, df_bat_h, is structured with batsmen as rows and their metrics as columns. Any missing values in this DataFrame are filled with zeros to ensure completeness.\n",
    "\n",
    "Next, if there is a column named 'scores', it is removed. This step cleans the data by removing columns that are not relevant to the clustering analysis.\n",
    "\n",
    "The DataFrame is then normalized using Min-Max scaling. This process transforms the feature values so that they fall within the range of 0 to 1. Normalization is crucial in clustering because it ensures that all metrics contribute equally to the distance calculations, regardless of their original scales.\n",
    "\n",
    "Following normalization, the code computes the pairwise Euclidean distances between batsmen using the pdist function. This distance matrix serves as the foundation for hierarchical clustering.\n",
    "\n",
    "Hierarchical clustering is performed using the Ward method, which is implemented via the linkage function. This method aims to minimize the variance within each cluster as clusters are merged.\n",
    "\n",
    "Finally, the clustering results are visualized through a dendrogram. A dendrogram is a tree-like diagram that illustrates the arrangement of clusters at various levels of similarity. The plot is configured to display batsmen names on the x-axis and the distance on the y-axis, with labels rotated for better readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4c818f-b235-4407-9319-542e2d47ab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_bat_h = pd.DataFrame.from_dict(batsman_metrics, orient='index')\n",
    "\n",
    "# Fill missing values with 0\n",
    "df_bat_h = df_bat_h.fillna(0)\n",
    "\n",
    "# Drop the 'scores' column if it exists\n",
    "if 'scores' in df_bat_h.columns:\n",
    "    df_bat_h = df_bat_h.drop(columns=['scores'])\n",
    "\n",
    "\n",
    "# Step 2: Normalize the data if necessary (using Min-Max scaling here)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(df_bat_h), columns=df_bat_h.columns, index=df_bat_h.index)\n",
    "\n",
    "# Step 3: Calculate the distance matrix\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "distance_matrix = pdist(df_normalized, metric='euclidean')\n",
    "\n",
    "# Step 4: Perform hierarchical clustering\n",
    "Z = linkage(distance_matrix, method='ward')\n",
    "\n",
    "# Step 5: Visualize the results using a dendrogram\n",
    "plt.figure(figsize=(10, 7))\n",
    "dendrogram(Z, labels=df_bat_h.index, leaf_rotation=90)\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('Batsman')\n",
    "plt.ylabel('Distance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c79b2e-3db7-416d-8d4b-6329455565ac",
   "metadata": {},
   "source": [
    "Data Preparation:\n",
    "The code starts by converting the batsman_metrics dictionary into a DataFrame, df_bat_h, where each index represents a batsman and each column represents a specific metric. Any missing values in this DataFrame are replaced with zeros to ensure that the data is complete and usable.\n",
    "\n",
    "Data Cleaning:\n",
    "The code checks for a column named 'scores' in the DataFrame. If such a column exists, it is removed. This step is essential to exclude any irrelevant or redundant information from the clustering analysis.\n",
    "\n",
    "Data Normalization:\n",
    "To ensure that the clustering algorithm treats all metrics equally, the data is normalized using Min-Max scaling. This scaling transforms all feature values to a range between 0 and 1, thereby eliminating any biases that might arise from different scales of the metrics.\n",
    "\n",
    "Distance Calculation:\n",
    "The code calculates the pairwise Euclidean distances between all pairs of batsmen using the pdist function. This distance matrix is crucial for the clustering algorithm as it quantifies the similarity between different batsmen.\n",
    "\n",
    "Hierarchical Clustering:\n",
    "Hierarchical clustering is performed using the linkage function with the Ward method. This method minimizes the variance within each cluster and builds a hierarchy of clusters.\n",
    "\n",
    "Forming Clusters:\n",
    "The code sets a threshold for the maximum distance between clusters and assigns each batsman to a cluster based on this threshold. The threshold is defined as 2, but it can be adjusted depending on the specific requirements or insights from the dendrogram visualization.\n",
    "\n",
    "Grouping and Printing Results:\n",
    "After assigning cluster labels, the code groups batsmen by their respective clusters. It then prints out the batsmen in each cluster, showing which players are grouped together based on their similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa855bd8-dbc8-47ea-ad11-069cb81507c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "\n",
    "\n",
    "\n",
    "df_bat_h = pd.DataFrame.from_dict(batsman_metrics, orient='index')\n",
    "\n",
    "# Fill missing values with 0\n",
    "df_bat_h = df_bat_h.fillna(0)\n",
    "\n",
    "# Drop the 'scores' column if it exists\n",
    "if 'scores' in df_bat_h.columns:\n",
    "    df_bat_h = df_bat_h.drop(columns=['scores'])\n",
    "\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(df_bat_h), columns=df_bat_h.columns, index=df_bat_h.index)\n",
    "\n",
    "# Calculate the distance matrix\n",
    "distance_matrix = pdist(df_normalized, metric='euclidean')\n",
    "\n",
    "# Perform hierarchical clustering\n",
    "Z = linkage(distance_matrix, method='ward')\n",
    "\n",
    "# Define the threshold for forming clusters\n",
    "threshold = 2  # Adjust this threshold based on the dendrogram\n",
    "\n",
    "# Assign cluster labels to each player\n",
    "cluster_labels = fcluster(Z, threshold, criterion='distance')\n",
    "\n",
    "# Group and print the players by their cluster labels\n",
    "clusters = {}\n",
    "for player, cluster in zip(df_bat_h.index, cluster_labels):\n",
    "    if cluster not in clusters:\n",
    "        clusters[cluster] = []\n",
    "    clusters[cluster].append(player)\n",
    "\n",
    "for cluster, players in clusters.items():\n",
    "    print(f\"Cluster {cluster}: {', '.join(players)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c153973a-df19-48ee-8885-3dcdd87dc242",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster, players in clusters.items():\n",
    "    if 'N Workman' in players:\n",
    "        print(f\"Cluster {cluster}: {', '.join(players)}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6f4d5d-4282-4439-8164-60c33c4f3cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowler_metrics = {k: v for k, v in bowler_metrics.items() if pd.notna(k)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389f9692-8dee-45d9-9c5c-64b683b2922e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, metrics in bowler_metrics.items():\n",
    "    if metrics['runs_conceded'] != 0:  # Avoid division by zero\n",
    "        metrics['runs_conceded'] = 1 / metrics['runs_conceded']\n",
    "\n",
    "# Display the updated dictionary\n",
    "print(bowler_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6e2ec2-b7d4-4662-9b64-4be85bfab26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Sample Data (assuming bowler_metrics is a dictionary and defined)\n",
    "data = bowler_metrics\n",
    "df_bowl = pd.DataFrame.from_dict(data, orient='index')\n",
    "df_bowl = df_bowl.fillna(0)\n",
    "\n",
    "# Features to use for clustering\n",
    "features = ['runs_conceded', 'wickets', 'extras', 'balls_bowled', 'innings', 'average', 'strike_rate', 'economy_rate']\n",
    "\n",
    "# Extract features\n",
    "X = df_bowl[features]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=4)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Plot the explained variance ratio as a bar graph\n",
    "plt.figure(figsize=(8, 5))\n",
    "num_components = len(pca.explained_variance_ratio_)\n",
    "plt.bar(range(1, num_components + 1), pca.explained_variance_ratio_, alpha=0.7, align='center')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('Explained Variance Ratio by Principal Component')\n",
    "plt.xticks(range(1, num_components + 1))\n",
    "plt.show()\n",
    "\n",
    "# Plot the contribution of each feature to each principal component\n",
    "plt.figure(figsize=(10, 7))\n",
    "num_components = pca.components_.shape[0]  # Number of principal components\n",
    "num_features = pca.components_.shape[1]    # Number of features\n",
    "\n",
    "# Ensure the number of row indices matches the number of principal components\n",
    "pc_labels = [f'PC{i+1}' for i in range(num_components)]\n",
    "\n",
    "# Create DataFrame for heatmap\n",
    "heatmap_df = pd.DataFrame(pca.components_, columns=features, index=pc_labels)\n",
    "\n",
    "# Plot heatmap\n",
    "sns.heatmap(heatmap_df, annot=True, cmap='coolwarm')\n",
    "plt.title('Feature Contribution to Principal Components')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Principal Component')\n",
    "plt.show()\n",
    "\n",
    "# Step 1: Determine the optimal number of clusters using the Elbow method\n",
    "inertia = []\n",
    "K_range = range(1, 11)  # Trying 1 to 10 clusters\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans.fit(X_pca)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the Elbow method result\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(K_range, inertia, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.xticks(K_range)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Step 2: Compute Silhouette Scores for a range of cluster numbers\n",
    "silhouette_scores = []\n",
    "K_range = range(2, 11)  # Silhouette score requires at least 2 clusters\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    clusters = kmeans.fit_predict(X_pca)\n",
    "    silhouette_avg = silhouette_score(X_pca, clusters)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "\n",
    "# Plot the Silhouette Scores\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(K_range, silhouette_scores, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Score for Different Numbers of Clusters')\n",
    "plt.xticks(K_range)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Choose the optimal number of clusters based on silhouette score\n",
    "optimal_k = 3  # Replace this with the optimal number of clusters from the Silhouette Score plot\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=0)\n",
    "clusters = kmeans.fit_predict(X_pca)\n",
    "\n",
    "# Add the cluster number to the DataFrame\n",
    "df_bowl['Cluster'] = clusters\n",
    "\n",
    "# Display the DataFrame with the cluster column\n",
    "print(df_bowl.head())\n",
    "\n",
    "# 3D Scatter Plot\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Define colors for the clusters\n",
    "colors = plt.cm.get_cmap('tab10', optimal_k)\n",
    "\n",
    "# Define cluster names\n",
    "cluster_names = {0: 'Good Players', 1: 'Very Good Players', 2: 'Excellent Players'}\n",
    "\n",
    "for i in range(optimal_k):\n",
    "    ax.scatter(X_pca[clusters == i, 0], X_pca[clusters == i, 1], X_pca[clusters == i, 2],\n",
    "               color=colors(i), label=cluster_names[i], alpha=0.6)\n",
    "\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "ax.set_title('Clustering of the Players')\n",
    "ax.legend()\n",
    "\n",
    "# Save the 3D scatter plot\n",
    "plt.savefig('clustering_of_the_players.png', bbox_inches='tight')\n",
    "\n",
    "# Display the 3D scatter plot\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Plot Silhouette Scores for Each Cluster\n",
    "silhouette_avg = silhouette_score(X_pca, clusters)\n",
    "print(f'Silhouette Score for {optimal_k} clusters: {silhouette_avg:.2f}')\n",
    "\n",
    "# Compute silhouette scores for each sample\n",
    "sample_silhouette_values = silhouette_samples(X_pca, clusters)\n",
    "\n",
    "# Create a silhouette plot\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "y_lower = 10\n",
    "for i in range(optimal_k):\n",
    "    # Aggregate the silhouette scores for samples belonging to cluster i\n",
    "    cluster_silhouette_values = sample_silhouette_values[clusters == i]\n",
    "    cluster_silhouette_values.sort()\n",
    "    \n",
    "    # Compute the size of the cluster\n",
    "    size_cluster_i = cluster_silhouette_values.shape[0]\n",
    "    \n",
    "    # Plot the silhouette scores for cluster i\n",
    "    ax.fill_betweenx(np.arange(y_lower, y_lower + size_cluster_i),\n",
    "                     0, cluster_silhouette_values,\n",
    "                     facecolor=colors(i), alpha=0.7)\n",
    "    \n",
    "    # Add the cluster label\n",
    "    ax.text(-0.05, y_lower + 0.5 * size_cluster_i, f'Cluster {i}',\n",
    "            color='black', va='center', ha='right', fontsize=12)\n",
    "    \n",
    "    # Update y_lower for the next cluster\n",
    "    y_lower += size_cluster_i\n",
    "\n",
    "ax.set_xlabel('Silhouette coefficient values')\n",
    "ax.set_ylabel('Cluster')\n",
    "ax.set_title('Silhouette Plot for the Clusters')\n",
    "plt.show()\n",
    "\n",
    "# Pie Chart of Clusters\n",
    "cluster_counts = df_bowl['Cluster'].value_counts()\n",
    "cluster_labels = {0: 'Good Players', 1: 'Very Good Players', 2: 'Excellent Players'}\n",
    "labels = [cluster_labels[i] for i in cluster_counts.index]\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(cluster_counts, labels=labels, autopct='%1.1f%%', colors=plt.cm.Paired(range(optimal_k)))\n",
    "plt.title('Percentage of Players in Each Cluster')\n",
    "plt.savefig('percentage_of_players_in_each_cluster.png', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da719783-0164-4204-9980-8771f2beeb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(df_bowl[(df_bowl['Cluster'] == i) ].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3417870-5090-4e46-a37d-9dd0e564389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_low_medium = df_bowl[df_bowl['Cluster'].isin([2])].index.tolist()\n",
    "cluster_low = df_bowl[df_bowl['Cluster'].isin([0])].index.tolist()\n",
    "cluster_medium = df_bowl[df_bowl['Cluster'].isin([1])].index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b76e26-0377-4fc1-b8a3-33f37ecf9699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_bowler_h = pd.DataFrame.from_dict(bowler_metrics, orient='index')\n",
    "\n",
    "# Fill missing values with 0\n",
    "df_bowler_h = df_bowler_h.fillna(0)\n",
    "\n",
    "# Drop the 'scores' column if it exists\n",
    "if 'scores' in df_bowler_h.columns:\n",
    "    df_bowler_h = df_bowler_h.drop(columns=['scores'])\n",
    "\n",
    "\n",
    "# Step 2: Normalize the data if necessary (using Min-Max scaling here)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(df_bowler_h), columns=df_bowler_h.columns, index=df_bowler_h.index)\n",
    "\n",
    "# Step 3: Calculate the distance matrix\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "distance_matrix = pdist(df_normalized, metric='euclidean')\n",
    "\n",
    "# Step 4: Perform hierarchical clustering\n",
    "Z = linkage(distance_matrix, method='ward')\n",
    "\n",
    "# Step 5: Visualize the results using a dendrogram\n",
    "plt.figure(figsize=(10, 7))\n",
    "dendrogram(Z, labels=df_bowler_h.index, leaf_rotation=90)\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('Batsman')\n",
    "plt.ylabel('Distance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c69333-65ae-4107-890d-0e0399315899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "\n",
    "\n",
    "\n",
    "df_bowler_h = pd.DataFrame.from_dict(bowler_metrics, orient='index')\n",
    "\n",
    "# Fill missing values with 0\n",
    "df_bowler_h = df_bowler_h.fillna(0)\n",
    "\n",
    "# Drop the 'scores' column if it exists\n",
    "if 'scores' in df_bowler_h.columns:\n",
    "    df_bowler_h = df_bowler_h.drop(columns=['scores'])\n",
    "\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(df_bowler_h), columns=df_bowler_h.columns, index=df_bowler_h.index)\n",
    "\n",
    "# Calculate the distance matrix\n",
    "distance_matrix = pdist(df_normalized, metric='euclidean')\n",
    "\n",
    "# Perform hierarchical clustering\n",
    "Z = linkage(distance_matrix, method='ward')\n",
    "\n",
    "# Define the threshold for forming clusters\n",
    "threshold = 2  # Adjust this threshold based on the dendrogram\n",
    "\n",
    "# Assign cluster labels to each player\n",
    "cluster_labels = fcluster(Z, threshold, criterion='distance')\n",
    "\n",
    "# Group and print the players by their cluster labels\n",
    "clusters = {}\n",
    "for player, cluster in zip(df_bowler_h.index, cluster_labels):\n",
    "    if cluster not in clusters:\n",
    "        clusters[cluster] = []\n",
    "    clusters[cluster].append(player)\n",
    "\n",
    "for cluster, players in clusters.items():\n",
    "    print(f\"Cluster {cluster}: {', '.join(players)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff18a18e-a454-4ed7-849b-3693a04741c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pdf=pd.read_excel(\"finaldesertation.xlsx\")\n",
    "pdf = pdf.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fceefad-6ca1-4fb7-b6cd-26aad7b9aab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf['bowler_rating'] = 0\n",
    "\n",
    "# Assign ratings based on cluster membership\n",
    "pdf.loc[pdf['bowler'].isin(cluster_medium), 'bowler_rating'] = 3\n",
    "#pdf.loc[pdf['bowler'].isin(cluster_high), 'bowler_rating'] = 5\n",
    "pdf.loc[pdf['bowler'].isin(cluster_low_medium), 'bowler_rating'] = 2\n",
    "pdf.loc[pdf['bowler'].isin(cluster_low), 'bowler_rating'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c59e04-5916-45f4-9e60-35430956adca",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = pdf[pdf['bowler_rating'] == 0]\n",
    "\n",
    "filtered_df['bowler'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cee1c2-9a89-4677-bd5d-48ed82b6fac5",
   "metadata": {},
   "source": [
    "The code snippet focuses on calculating detailed cricket batting metrics based on a DataFrame that contains various events from cricket matches. The primary goal is to compute metrics for batsmen based on their performance in different matches and innings.\n",
    "\n",
    "Initial Data Preparation\n",
    "The code begins by segregating the data into four different DataFrames based on the bowler_rating and NaN values in the bowler column:\n",
    "\n",
    "bat_rating3: Contains records where the bowler_rating is 3.\n",
    "bat_rating2: Contains records where the bowler_rating is 2.\n",
    "bat_rating1: Contains records where the bowler_rating is 1.\n",
    "bat_rating0: Contains records where the bowler is NaN, indicating missing bowler information.\n",
    "Function for Calculating Metrics\n",
    "The calculate_metrics function processes events from a DataFrame to compute batting statistics. Here's a detailed look at how it works:\n",
    "\n",
    "Initialize Metrics Storage:\n",
    "Two dictionaries, batsman_metrics and bowler_metrics, are initialized to store metrics for each batsman and bowler. In this function, however, only batsman metrics are being computed.\n",
    "\n",
    "Define Scoring Rules:\n",
    "\n",
    "runs_scored: Maps event descriptions to the number of runs scored.\n",
    "dismissals: Lists various dismissal types.\n",
    "extras: Although defined, it’s not used in the provided code snippet.\n",
    "Process Each Event:\n",
    "\n",
    "Iterate Through DataFrame Rows: For each event, the code extracts relevant details like the event description, bowler, batsman, and bowling team.\n",
    "Initialize Batsmen: If a batsman is not yet in the batsman_metrics dictionary, they are added with default values.\n",
    "Handle Innings Changes: If there’s a change in the bowling team (indicating a new innings), the current scores for all batsmen are saved, and their runs are reset.\n",
    "Update Batsman Metrics:\n",
    "Scoring Events: Update runs, boundaries, and balls faced based on the event description.\n",
    "Dismissals: Record dismissals and reset runs for the next innings.\n",
    "Final Adjustments:\n",
    "\n",
    "Ensure that the last innings runs for each batsman are recorded if they haven't been added yet.\n",
    "Calculate Additional Metrics:\n",
    "\n",
    "Average: The batting average is calculated as total runs divided by the number of dismissals. If there are no dismissals, the average is set to the total runs.\n",
    "Strike Rate: This is calculated as (runs / balls faced) * 100. If no balls were faced, the strike rate is set to 0.\n",
    "Highest Score: The highest score from the list of scores is identified.\n",
    "Innings: The number of innings is determined by the length of the scores list.\n",
    "Applying the Function\n",
    "The calculate_metrics function is applied to each of the DataFrames (bat_rating3, bat_rating2, bat_rating1, bat_rating0, and pdf), calculating the batting metrics for each group.\n",
    "\n",
    "Printing Results\n",
    "Finally, the computed metrics for the bat_rating3 DataFrame are printed, showing the detailed performance statistics of batsmen who faced bowlers with a rating of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6975494e-d028-4019-8d1b-eda3ae37e5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bat_rating3=pdf[pdf['bowler_rating']==3]\n",
    "bat_rating2=pdf[pdf['bowler_rating']==2]\n",
    "bat_rating1=pdf[pdf['bowler_rating']==1]\n",
    "bat_rating0 = pdf[pdf['bowler'].isna()]\n",
    "import pandas as pd\n",
    "from decimal import Decimal\n",
    "\n",
    "# Function to process events and calculate metrics for batsmen and bowlers\n",
    "def calculate_metrics(df):\n",
    "    # Initialize dictionaries to hold metrics\n",
    "    batsman_metrics = {}\n",
    "    bowler_metrics = {}\n",
    "\n",
    "    # Define scoring rules\n",
    "    runs_scored = {\n",
    "        '0 runs': 0, '1 run': 1, '2 runs': 2, '3 runs': 3, '4 runs': 4, '6 runs': 6,\n",
    "        '1 run \\n 1 no ball': 1, '2 runs \\n 1 no ball': 2, '3 runs \\n 1 no ball': 3, \n",
    "        '4 runs \\n 1 no ball': 4, '6 runs \\n 1 no ball': 6, '5 runs': 5,\n",
    "        '1 run \\n 2 no balls': 1, '4 runs \\n 2 no balls': 4,\n",
    "    }\n",
    "    \n",
    "    dismissals = [\n",
    "        'Wicket!', 'Wicket! \\n 2 wides', 'Wicket! \\n 1 run \\n 1 no ball', \n",
    "        'Wicket! \\n 1 run', 'Wicket! \\n 2 runs', 'Wicket! \\n 1 bye', \n",
    "        'Wicket! \\n 1 no ball', 'Wicket! \\n 1 wide', 'Wicket! \\n 1 leg bye'\n",
    "    ]\n",
    "\n",
    "    extras = {\n",
    "        '1 wide': 1, '2 wides': 2, '3 wides': 3, '4 wides': 4, '5 wides': 5, '6 wides': 6,\n",
    "        '1 no ball': 1, '2 no balls': 2, '1 bye': 1, '2 byes': 2, '3 byes': 3, \n",
    "        '4 byes': 4, '5 byes': 5, '1 leg bye': 1, '2 leg byes': 2, '3 leg byes': 3, \n",
    "        '4 leg byes': 4, '2 1nb + byes': 2, '3 1nb + byes': 3, '6 1nb + byes': 6, \n",
    "        '5 1nb + byes': 5, '4 1nb + byes': 4, '2 1nb + leg byes': 2\n",
    "    }\n",
    "\n",
    "    previous_bowling_team = None\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        event = row['Event']\n",
    "        bowler = row['bowler']\n",
    "        batsman = row['batsman']\n",
    "        bowling_team = row['bowling team']\n",
    "        over = int(row['Over'][5:])\n",
    "\n",
    "        # Initialize batsman and bowler if not already in the dictionary\n",
    "        if batsman not in batsman_metrics:\n",
    "            batsman_metrics[batsman] = {'runs': 0, 'boundaries': 0, 'dismissal': 0, 'balls_faced': 0, 'innings': 0, 'scores': []}\n",
    "        \n",
    "\n",
    "        # Handle change in batting team (new match or new innings)\n",
    "        if previous_bowling_team is not None and previous_bowling_team != bowling_team:\n",
    "            # Save the scores for all batsmen\n",
    "            for b in batsman_metrics:\n",
    "                if batsman_metrics[b]['runs'] > 0:\n",
    "                    batsman_metrics[b]['scores'].append(batsman_metrics[b]['runs'])\n",
    "                    batsman_metrics[b]['runs'] = 0\n",
    "\n",
    "        # Calculate metrics for batsmen\n",
    "        if event in runs_scored:\n",
    "            runs = runs_scored[event]\n",
    "            batsman_metrics[batsman]['runs'] += runs\n",
    "            batsman_metrics[batsman]['balls_faced'] += 1\n",
    "            if runs >= 4:\n",
    "                batsman_metrics[batsman]['boundaries'] += 1\n",
    "\n",
    "        if event in dismissals:\n",
    "            batsman_metrics[batsman]['balls_faced'] += 1\n",
    "            batsman_metrics[batsman]['dismissal'] += 1\n",
    "            batsman_metrics[batsman]['scores'].append(batsman_metrics[batsman]['runs'])\n",
    "            batsman_metrics[batsman]['runs'] = 0  # Reset runs for the next innings\n",
    "\n",
    "        \n",
    "\n",
    "        previous_bowling_team = bowling_team\n",
    "\n",
    "    # Ensure last innings runs are recorded\n",
    "    for batsman in batsman_metrics:\n",
    "        if batsman_metrics[batsman]['runs'] > 0:\n",
    "            batsman_metrics[batsman]['scores'].append(batsman_metrics[batsman]['runs'])\n",
    "\n",
    "    # Calculate additional metrics for batsmen\n",
    "    for batsman in batsman_metrics:\n",
    "        runs = sum(batsman_metrics[batsman]['scores'])\n",
    "        dismissal = batsman_metrics[batsman]['dismissal']\n",
    "        balls_faced = batsman_metrics[batsman]['balls_faced']\n",
    "\n",
    "        average = runs / dismissal if dismissal > 0 else runs\n",
    "        strike_rate = (runs / balls_faced * 100) if balls_faced > 0 else Decimal('0')\n",
    "        highest_score = max(batsman_metrics[batsman]['scores']) if batsman_metrics[batsman]['scores'] else runs\n",
    "\n",
    "        batsman_metrics[batsman]['average'] = average\n",
    "        batsman_metrics[batsman]['strike_rate'] = strike_rate\n",
    "        batsman_metrics[batsman]['highest_score'] = highest_score\n",
    "        batsman_metrics[batsman]['runs'] = runs\n",
    "        batsman_metrics[batsman]['innings'] = len(batsman_metrics[batsman]['scores'])\n",
    "\n",
    "    \n",
    "\n",
    "    return batsman_metrics\n",
    "\n",
    "\n",
    "\n",
    "# Calculate metrics\n",
    "rat3 = calculate_metrics(bat_rating3)\n",
    "rat2 = calculate_metrics(bat_rating2)\n",
    "rat1 = calculate_metrics(bat_rating1)\n",
    "rat0 = calculate_metrics(bat_rating0)\n",
    "ran = calculate_metrics(pdf)\n",
    "# Print results\n",
    "print(\"Batsman Metrics:\", rat3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acefdb40-c018-45ba-9a29-7ba4979bd84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "players=[]\n",
    "for i in ran.keys():\n",
    "    players.append(i)\n",
    "key_final={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0039c2f7-7f63-42af-9b26-3b72f21a6ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in players:\n",
    "    key_final[i]={}\n",
    "    if i in rat0:\n",
    "        key_final[i][0]=rat0[i]\n",
    "    if i in rat1:\n",
    "        key_final[i][1]=rat1[i]\n",
    "    if i in rat2:\n",
    "        key_final[i][2]=rat2[i]\n",
    "    if i in rat3:\n",
    "        key_final[i][3]=rat3[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4129a7-65b1-4a53-88cf-640622f793ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in averages.iterrows():\n",
    "    player_name = row['batsman']\n",
    "    if player_name in key_final:\n",
    "        key_final[player_name]['average_runs'] = row['R']  # Set runs average\n",
    "        key_final[player_name]['average_balls_faced'] = row['B']  # Set balls faced average\n",
    "        key_final[player_name]['average_boundaries'] = row['4s'] + row['6s']  # Set total boundaries\n",
    "        key_final[player_name]['average_strike_rate'] = row['SR']  # Set strike rate\n",
    "\n",
    "# Print the updated dictionary\n",
    "print(key_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b69b2d7-ac25-4dc1-9168-b8e29831bb32",
   "metadata": {},
   "source": [
    "This code calculates a comprehensive rating for cricket batsmen by leveraging the Analytic Hierarchy Process (AHP), a structured technique for organizing and analyzing complex decisions. It integrates various performance metrics of batsmen and weighs them according to their relative importance to produce a final rating.\n",
    "\n",
    "Step-by-Step Explanation\n",
    "AHP Function (ahp):\n",
    "\n",
    "Purpose: This function calculates priority vectors and consistency ratios for a series of matrices that represent different aspects of batsman performance.\n",
    "Process:\n",
    "Normalization: Each matrix is normalized by dividing each element by the sum of its column.\n",
    "Priority Vector: The priority vector (or weight vector) is calculated as the average of the rows in the normalized matrix.\n",
    "Consistency Check:\n",
    "A weighted sum vector is calculated by multiplying the original matrix with the priority vector.\n",
    "Lambda Max is computed by averaging the ratio of the weighted sum vector and the priority vector.\n",
    "Consistency Index (CI) and Consistency Ratio (CR) are computed. CR helps in determining if the comparisons made in the matrix are consistent. A CR > 0.1 indicates inconsistency, prompting an error.\n",
    "Output: A dictionary containing the priority vector, CI, and CR for each matrix.\n",
    "Matrix Definitions:\n",
    "\n",
    "Various matrices representing different hierarchical levels of batsman performance are defined:\n",
    "Bowler Rating Matrix: Compares different bowler ratings.\n",
    "Level 2 Matrix: Weighs the importance of three primary metrics (Scoring Ability, Consistency, Efficiency).\n",
    "Scoring Ability Matrix: Compares sub-metrics within the scoring ability category.\n",
    "Consistency Matrix: Compares sub-metrics within consistency.\n",
    "Efficiency Matrix: Compares sub-metrics within efficiency.\n",
    "These matrices are fed into the ahp function to compute the respective priority vectors and consistency ratios.\n",
    "Calculate Weighted Score Function (calculate_weighted_score):\n",
    "\n",
    "Purpose: This function calculates a weighted score based on a given set of weights and corresponding metric values.\n",
    "Process: It multiplies each metric by its corresponding weight and sums the results.\n",
    "Calculate Batsman Rating Function (calculate_batsman_rating):\n",
    "\n",
    "Purpose: This function calculates the final rating for a batsman against bowlers with different ratings, based on the weighted scores from the different performance metrics.\n",
    "Process:\n",
    "Level 1 Scores: Compute scores for Scoring Ability, Consistency, and Efficiency using their respective priority vectors and metrics.\n",
    "Level 2 Score: Combine the Level 1 scores using the Level 2 priority vector.\n",
    "Final Rating: Multiply the Level 2 score by the priority vector value of the corresponding bowler rating.\n",
    "Final Ratings Calculation:\n",
    "\n",
    "The code iterates over each batsman and calculates their overall rating by combining their performance metrics against bowlers of different ratings.\n",
    "Metrics Handling: For each bowler rating, metrics such as runs, boundaries, highest_score, average, etc., are used to compute the corresponding rating.\n",
    "The calculated ratings are summed up to produce the final rating for each batsman.\n",
    "Output:\n",
    "\n",
    "For each batsman, the code prints the rating against each bowler rating, followed by the final cumulative rating.\n",
    "Finally, all batsmen’s ratings are displayed.\n",
    "Overall Objective\n",
    "The code assesses batsmen based on their performance against bowlers of varying quality, factoring in multiple performance aspects such as scoring ability, consistency, and efficiency. By assigning different weights to each metric and incorporating consistency checks, it ensures that the final ratings are both comprehensive and consistent. This approach allows for a structured evaluation of batsman performance across different scenarios and opponents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3787a45e-b50e-4885-abac-027733d2cfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import decimal\n",
    "\n",
    "def ahp(matrix_dict):\n",
    "    def calculate_priority_vector_and_consistency(matrix):\n",
    "        n = matrix.shape[0]\n",
    "        \n",
    "        # Normalize the matrix\n",
    "        column_sums = np.sum(matrix, axis=0)\n",
    "        normalized_matrix = matrix / column_sums\n",
    "        \n",
    "        # Calculate the Priority Vector\n",
    "        priority_vector = np.mean(normalized_matrix, axis=1)\n",
    "        \n",
    "        # Compute the Weighted Sum Vector using the original matrix\n",
    "        weighted_sum_vector = np.dot(matrix, priority_vector)\n",
    "        \n",
    "        # Compute Lambda Max\n",
    "        lambda_max = np.mean(weighted_sum_vector / priority_vector)\n",
    "        \n",
    "        # Calculate Consistency Index (CI)\n",
    "        CI = (lambda_max - n) / (n - 1)\n",
    "        \n",
    "        # Random Index (RI) for consistency ratio calculation\n",
    "        RI_dict = {1: 0, 2: 0, 3: 0.58, 4: 0.90, 5: 1.12, 6: 1.24, 7: 1.32, 8: 1.41, 9: 1.45, 10: 1.49}\n",
    "        RI = RI_dict.get(n, 1.49)\n",
    "        \n",
    "        # Calculate Consistency Ratio (CR)\n",
    "        CR = CI / RI if RI != 0 else 0\n",
    "        \n",
    "        return priority_vector, CI, CR\n",
    "\n",
    "    results = {}\n",
    "    for key, matrix in matrix_dict.items():\n",
    "        priority_vector, CI, CR = calculate_priority_vector_and_consistency(matrix)\n",
    "        if CR > 0.1:\n",
    "            raise ValueError(f\"The consistency ratio for {key} is too high: {CR:.2f}\")\n",
    "        results[key] = {'priority_vector': priority_vector, 'CI': CI, 'CR': CR}\n",
    "    \n",
    "    return results\n",
    "\n",
    "def calculate_weighted_score(weights, metrics):\n",
    "    # Convert metrics values to float if they are decimal.Decimal\n",
    "    metrics = {k: float(v) if isinstance(v, decimal.Decimal) else v for k, v in metrics.items()}\n",
    "    \n",
    "    return sum(weights.get(key, 0) * metrics.get(key, 0) for key in weights)\n",
    "\n",
    "def calculate_batsman_rating(bowler_rating, scoring_metrics, consistency_metrics, efficiency_metrics, results):\n",
    "    # Calculate weighted scores for each level\n",
    "    scoring_ability_score = calculate_weighted_score(\n",
    "        dict(zip(['runs', 'boundaries', 'highest_score'], results['Scoring Ability']['priority_vector'])),\n",
    "        scoring_metrics\n",
    "    )\n",
    "    \n",
    "    consistency_score = calculate_weighted_score(\n",
    "        dict(zip(['average', 'average_runs', 'dismissals', 'innings'], results['Consistency']['priority_vector'])),\n",
    "        consistency_metrics\n",
    "    )\n",
    "    \n",
    "    efficiency_score = calculate_weighted_score(\n",
    "        dict(zip(['strike_rate', 'average_strike_rate', 'balls_faced', 'average_balls_faced', 'average_balls', 'average_boundaries'], results['Efficiency']['priority_vector'])),\n",
    "        efficiency_metrics\n",
    "    )\n",
    "    \n",
    "    # Calculate Level 2 weighted score\n",
    "    level_2_weights = dict(zip(['scoring_ability', 'consistency', 'efficiency'], results['Level 2']['priority_vector']))\n",
    "    level_2_score = (\n",
    "        level_2_weights['scoring_ability'] * scoring_ability_score +\n",
    "        level_2_weights['consistency'] * consistency_score +\n",
    "        level_2_weights['efficiency'] * efficiency_score\n",
    "    )\n",
    "    \n",
    "    # Multiply level 2 score by bowler rating priority vector\n",
    "    bowler_rating_weight = results['Bowler Rating']['priority_vector'][bowler_rating - 1]  # Adjust index for 0-based array\n",
    "    overall_rating = bowler_rating_weight * level_2_score\n",
    "    \n",
    "    return overall_rating\n",
    "\n",
    "# Define matrices\n",
    "bowler_rating_matrix = np.array([\n",
    "    [1, 1.5, 1.75, 2],\n",
    "    [0.667, 1, 1.5, 1.75],\n",
    "    [0.571, 0.667, 1, 1.5],\n",
    "    [0.5, 0.571, 0.667, 1]\n",
    "])\n",
    "\n",
    "level_2_matrix = np.array([\n",
    "    [1, 1.25, 1.5],\n",
    "    [0.8, 1, 1.25],\n",
    "    [0.667, 0.8, 1]\n",
    "])\n",
    "\n",
    "scoring_ability_matrix = np.array([\n",
    "    [1, 3, 5],\n",
    "    [0.33, 1, 3],\n",
    "    [0.2, 0.33, 1]\n",
    "])\n",
    "\n",
    "consistency_matrix = np.array([\n",
    "    [1, 3, 5, 7],\n",
    "    [0.33, 1, 3, 5],\n",
    "    [0.2, 0.33, 1, 3],\n",
    "    [0.14, 0.2, 0.33, 1]\n",
    "])\n",
    "\n",
    "efficiency_matrix = np.array([\n",
    "    [1, 3, 5, 7, 9],\n",
    "    [0.33, 1, 3, 5, 7],\n",
    "    [0.2, 0.33, 1, 3, 5],\n",
    "    [0.14, 0.2, 0.33, 1, 3],\n",
    "    [0.11, 0.14, 0.2, 0.33, 1]\n",
    "])\n",
    "\n",
    "# Creating dictionary of matrices\n",
    "matrix_dict = {\n",
    "    'Bowler Rating': bowler_rating_matrix,\n",
    "    'Level 2': level_2_matrix,\n",
    "    'Scoring Ability': scoring_ability_matrix,\n",
    "    'Consistency': consistency_matrix,\n",
    "    'Efficiency': efficiency_matrix\n",
    "}\n",
    "\n",
    "# Calculate AHP results\n",
    "results = ahp(matrix_dict)\n",
    "\n",
    "\n",
    "# Calculate and print the batsman ratings\n",
    "final_ratings = {}\n",
    "for batsman, metrics_by_bowler in key_final.items():\n",
    "    final_rating = 0\n",
    "    print(f\"\\nBatsman: {batsman}\")\n",
    "    \n",
    "    # Default values for metrics\n",
    "    default_metrics = {\n",
    "        'average_runs': metrics_by_bowler.get('average_runs', 0),\n",
    "        'average_balls_faced': metrics_by_bowler.get('average_balls_faced', 0),\n",
    "        'average_boundaries': metrics_by_bowler.get('average_boundaries', 0),\n",
    "        'average_strike_rate': metrics_by_bowler.get('average_strike_rate', 0)\n",
    "    }\n",
    "    \n",
    "    for bowler_rating, metrics in metrics_by_bowler.items():\n",
    "        if isinstance(bowler_rating, int):  # Skip non-metric entries\n",
    "            scoring_metrics = {\n",
    "                'runs': metrics.get('runs', 0),\n",
    "                'boundaries': metrics.get('boundaries', 0),\n",
    "                'highest_score': metrics.get('highest_score', 0)\n",
    "            }\n",
    "            consistency_metrics = {\n",
    "                'average': metrics.get('average', default_metrics['average_runs']),\n",
    "                'average_runs': default_metrics['average_runs'],\n",
    "                'dismissals': metrics.get('dismissal', 0),\n",
    "                'innings': metrics.get('innings', 0)\n",
    "            }\n",
    "            efficiency_metrics = {\n",
    "                'strike_rate': metrics.get('strike_rate', 0),\n",
    "                'average_strike_rate': default_metrics['average_strike_rate'],\n",
    "                'balls_faced': metrics.get('balls_faced', 0),\n",
    "                'average_balls_faced': default_metrics['average_balls_faced'],\n",
    "                'average_balls': metrics.get('balls_faced', 0),\n",
    "                'average_boundaries': default_metrics['average_boundaries']\n",
    "            }\n",
    "            overall_rating = calculate_batsman_rating(bowler_rating, scoring_metrics, consistency_metrics, efficiency_metrics, results)\n",
    "            final_rating += overall_rating\n",
    "            print(f\"  Bowler Rating {bowler_rating}: Overall Batsman Rating = {overall_rating}\")\n",
    "    final_ratings[batsman] = final_rating\n",
    "    print(f\"  Final Rating: {final_rating}\")\n",
    "\n",
    "print(\"\\nFinal Batsman Ratings:\")\n",
    "for batsman, rating in final_ratings.items():\n",
    "    print(f\"{batsman}: {rating}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d32c04-0cd6-45e3-b870-db7969a5d0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ratings = sorted(final_ratings.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the sorted values\n",
    "for name, value in sorted_ratings:\n",
    "    print(f\"{name}: {value}\")\n",
    "nr_bats=sorted_ratings[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cb2c98-a43f-4e7e-9b8c-47e3eb454736",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [value for name, value in nr_bats]\n",
    "\n",
    "# Compute min and max values\n",
    "min_value = min(values)\n",
    "max_value = max(values)\n",
    "\n",
    "# Normalize values\n",
    "normalized_data = [(name, (value - min_value) / (max_value - min_value)) for name, value in nr_bats]\n",
    "\n",
    "# Output the normalized data\n",
    "for name, normalized_value in normalized_data:\n",
    "    print(f'{name}: {normalized_value:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d010034f-7474-4294-84dc-c423ebeab8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data for top players\n",
    "data = [\n",
    "    ('N Workman', 1.0),\n",
    " ('C McCarthy', 0.8607992283840062),\n",
    " ('F Wright', 0.7972612582868434),\n",
    " ('J Harker', 0.7471745117994111),\n",
    " ('C Bennett', 0.6910088854364737),\n",
    " ('R Curtis', 0.6240290240145733),\n",
    " ('J Mellons', 0.5970018706641969),\n",
    " ('L Robertson', 0.5638565516815752),\n",
    " ('J Errington', 0.5609308446190859),\n",
    " ('J Winlow', 0.5458630341381004),\n",
    " ('L Agnew', 0.5421388446774658),\n",
    " ('E Jackson', 0.5304836145716233),\n",
    " ('C Brook', 0.5304002152783249),\n",
    " ('J Soppitt', 0.5199968950583211),\n",
    " ('H Keegan', 0.5090877819365686),\n",
    "]\n",
    "\n",
    "# Sort data by rating and get top 10\n",
    "top_10 = sorted(data, key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "# Separate names and ratings for plotting\n",
    "names, ratings = zip(*top_10)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(names, ratings, color='skyblue')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Player Name')\n",
    "plt.title('Top 10 Players by Rating')\n",
    "plt.gca().invert_yaxis()  # Highest ratings at the top\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig('top_10_players_by_rating.png', bbox_inches='tight')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6689d6-80e5-443e-85fa-a83987defe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract float values\n",
    "values = [x[1] for x in normalized_data]\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(range(len(values)), values, color='blue', marker='o')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Scatter Plot of Values')\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the plot as an image file\n",
    "plt.savefig('scatter_plot.png')\n",
    "\n",
    "# Show the plot (optional, remove if not needed)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0257d9ab-ff4c-4033-9263-7fad693bcc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_dict = dict(normalized_data)\n",
    "player_stats=batsman_metrics\n",
    "def update_player_ratings(stats_dict, ratings_dict):\n",
    "    for player, stats in stats_dict.items():\n",
    "        if player in ratings_dict:\n",
    "            stats['rating'] = ratings_dict[player]\n",
    "        else:\n",
    "            stats['rating'] = None  # Handle missing ratings\n",
    "\n",
    "# Update player stats with ratings\n",
    "update_player_ratings(player_stats, rating_dict)\n",
    "\n",
    "# Print updated player stats\n",
    "for player, stats in player_stats.items():\n",
    "    print(f\"Player: {player}\")\n",
    "    print(f\"Stats: {stats}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22cc854-e13a-4582-bce6-39e4612d4885",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfB = pd.DataFrame(player_stats).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb3faf5-ab89-41c6-b3b7-69eb63c92d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfB['Rating Class'] = pd.cut(dfB['rating'], bins=np.linspace(0, 1, 11), labels=range(1, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1c180a-96f0-4517-a038-9521be4959e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfB=dfB.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30168a4-e726-4a7a-a60a-71906ad8416c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X = dfB.drop(columns=['rating', 'scores', 'Rating Class','balls_faced','highest_score'])\n",
    "y = dfB['Rating Class']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert predictions and actual values to integers for classification accuracy\n",
    "y_pred_rounded = np.round(y_pred).astype(int)\n",
    "y_test_rounded = y_test.astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(y_pred_rounded == y_test_rounded)\n",
    "accuracy_percentage = accuracy * 100\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = np.ceil(y_pred)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print coefficients\n",
    "coefficients = model.coef_\n",
    "feature_names = X.columns\n",
    "\n",
    "print(\"Model Coefficients:\")\n",
    "for feature, coef in zip(feature_names, coefficients):\n",
    "    print(f\"{feature}: {coef:.4f}\")\n",
    "\n",
    "print(f\"\\nMean Squared Error: {mse:.4f}\")\n",
    "print(f\"R^2 Score: {r2:.4f}\")\n",
    "print(f\"Prediction Accuracy: {accuracy_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f486c7-6eda-4792-bc98-8c8470c82c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfB.set_index('scores', inplace=True)\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = dfB.corr()\n",
    "\n",
    "# Plotting the heatmap for feature vs feature correlations\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", linewidths=.5)\n",
    "plt.title(\"Feature vs Feature Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e7c345-75ab-4bcf-982c-ee41f71be050",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow3=pdf0[pdf0['batter_rating']==3]\n",
    "bow2=pdf0[pdf0['batter_rating']==2]\n",
    "bow1=pdf0[pdf0['batter_rating']==1]\n",
    "bow0 = pdf0[pdf0['batter_rating'].isna()]\n",
    "import pandas as pd\n",
    "from decimal import Decimal\n",
    "\n",
    "# Function to process events and calculate metrics for bowlers\n",
    "def calculate_bowler_metrics(df):\n",
    "    # Initialize dictionary to hold metrics\n",
    "    bowler_metrics = {}\n",
    "\n",
    "    # Define scoring rules\n",
    "    runs_scored = {\n",
    "        '0 runs': 0, '1 run': 1, '2 runs': 2, '3 runs': 3, '4 runs': 4, '6 runs': 6,\n",
    "        '1 run \\n 1 no ball': 1, '2 runs \\n 1 no ball': 2, '3 runs \\n 1 no ball': 3, \n",
    "        '4 runs \\n 1 no ball': 4, '6 runs \\n 1 no ball': 6, '5 runs': 5,\n",
    "        '1 run \\n 2 no balls': 1, '4 runs \\n 2 no balls': 4,\n",
    "    }\n",
    "    \n",
    "    dismissals = [\n",
    "        'Wicket!', 'Wicket! \\n 2 wides', 'Wicket! \\n 1 run \\n 1 no ball', \n",
    "        'Wicket! \\n 1 run', 'Wicket! \\n 2 runs', 'Wicket! \\n 1 bye', \n",
    "        'Wicket! \\n 1 no ball', 'Wicket! \\n 1 wide', 'Wicket! \\n 1 leg bye'\n",
    "    ]\n",
    "\n",
    "    extras = {\n",
    "        '1 wide': 1, '2 wides': 2, '3 wides': 3, '4 wides': 4, '5 wides': 5, '6 wides': 6,\n",
    "        '1 no ball': 1, '2 no balls': 2, '1 bye': 1, '2 byes': 2, '3 byes': 3, \n",
    "        '4 byes': 4, '5 byes': 5, '1 leg bye': 1, '2 leg byes': 2, '3 leg byes': 3, \n",
    "        '4 leg byes': 4, '2 1nb + byes': 2, '3 1nb + byes': 3, '6 1nb + byes': 6, \n",
    "        '5 1nb + byes': 5, '4 1nb + byes': 4, '2 1nb + leg byes': 2\n",
    "    }\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        event = row['Event']\n",
    "        bowler = row['bowler']\n",
    "        bowling_team = row['bowling team']\n",
    "        over = int(row['Over'][5:])\n",
    "\n",
    "        # Initialize bowler if not already in the dictionary\n",
    "        if bowler not in bowler_metrics:\n",
    "            bowler_metrics[bowler] = {'runs_conceded': 0, 'wickets': 0, 'extras': 0, 'balls_bowled': 0, 'innings': 0}\n",
    "\n",
    "        # Calculate metrics for bowlers\n",
    "        if event in runs_scored:\n",
    "            bowler_metrics[bowler]['runs_conceded'] += runs_scored[event]\n",
    "            bowler_metrics[bowler]['balls_bowled'] += 1\n",
    "\n",
    "        if event in dismissals:\n",
    "            bowler_metrics[bowler]['wickets'] += 1\n",
    "\n",
    "        if event in extras:\n",
    "            bowler_metrics[bowler]['extras'] += extras[event]\n",
    "            bowler_metrics[bowler]['runs_conceded'] += extras[event]\n",
    "\n",
    "    # Calculate additional metrics for bowlers\n",
    "    for bowler in bowler_metrics:\n",
    "        runs_conceded = bowler_metrics[bowler]['runs_conceded']\n",
    "        wickets = bowler_metrics[bowler]['wickets']\n",
    "        balls_bowled = bowler_metrics[bowler]['balls_bowled']\n",
    "\n",
    "        bowler_metrics[bowler]['average'] = runs_conceded / wickets if wickets > 0 else runs_conceded\n",
    "        bowler_metrics[bowler]['strike_rate'] = balls_bowled / wickets if wickets > 0 else balls_bowled\n",
    "        bowler_metrics[bowler]['economy_rate'] = (runs_conceded / (balls_bowled / 6)) if balls_bowled > 0 else 0\n",
    "        reciprocal_runs_conceded = 1 / runs_conceded if runs_conceded > 0 else 0\n",
    "        bowler_metrics[bowler]['runs_conceded'] = reciprocal_runs_conceded\n",
    "    return bowler_metrics\n",
    "\n",
    "# Calculate metrics for each rating category\n",
    "rat3_bowler_metrics = calculate_bowler_metrics(bow3)\n",
    "rat2_bowler_metrics = calculate_bowler_metrics(bow2)\n",
    "rat1_bowler_metrics = calculate_bowler_metrics(bow1)\n",
    "rat0_bowler_metrics = calculate_bowler_metrics(bow0)\n",
    "cam=calculate_bowler_metrics(pdf0)\n",
    "# Print results\n",
    "print(\"Rating 3 Bowler Metrics:\", rat3_bowler_metrics)\n",
    "print(\"Rating 2 Bowler Metrics:\", rat2_bowler_metrics)\n",
    "print(\"Rating 1 Bowler Metrics:\", rat1_bowler_metrics)\n",
    "print(\"Rating 0 Bowler Metrics:\", rat0_bowler_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015337b7-5acd-4556-86d4-6f9cce40084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "playersb=[]\n",
    "for i in cam.keys():\n",
    "    playersb.append(i)\n",
    "key_fina={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84652fb3-e968-43b2-b98f-29d7185cceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in playersb:\n",
    "    key_fina[i]={}\n",
    "    if i in rat0_bowler_metrics:\n",
    "        key_fina[i][0]=rat0_bowler_metrics[i]\n",
    "    if i in rat1_bowler_metrics:\n",
    "        key_fina[i][1]=rat1_bowler_metrics[i]\n",
    "    if i in rat2_bowler_metrics:\n",
    "        key_fina[i][2]=rat2_bowler_metrics[i]\n",
    "    if i in rat3_bowler_metrics:\n",
    "        key_fina[i][3]=rat3_bowler_metrics[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315f54e2-3e2f-4c97-8497-220f2cdb74c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "performance_data = key_fina\n",
    "    \n",
    "\n",
    "# Pairwise Comparison Matrices\n",
    "batsman_comparison_matrix = np.array([\n",
    "    [1, 1.5, 1.75, 2],\n",
    "    [0.667, 1, 1.5, 1.75],\n",
    "    [0.571, 0.667, 1, 1.5],\n",
    "    [0.5, 0.571, 0.667, 1]\n",
    "])\n",
    "\n",
    "performance_comparison_matrix = np.array([\n",
    "    [1, 1/3, 1/5, 1/3, 1/3],\n",
    "    [3, 1, 1/3, 1/3, 1/2],\n",
    "    [5, 3, 1, 2, 2],\n",
    "    [3, 3, 1/2, 1, 1],\n",
    "    [3, 2, 1/2, 1, 1]\n",
    "])\n",
    "\n",
    "def normalize_matrix(matrix):\n",
    "    col_sum = matrix.sum(axis=0)\n",
    "    return matrix / col_sum\n",
    "\n",
    "def calculate_priority_vector(normalized_matrix):\n",
    "    return normalized_matrix.mean(axis=1)\n",
    "\n",
    "# Normalize matrices\n",
    "norm_batsman_matrix = normalize_matrix(batsman_comparison_matrix)\n",
    "norm_performance_matrix = normalize_matrix(performance_comparison_matrix)\n",
    "\n",
    "# Calculate priority vectors\n",
    "batsman_priority_vector = calculate_priority_vector(norm_batsman_matrix)\n",
    "performance_priority_vector = calculate_priority_vector(norm_performance_matrix)\n",
    "\n",
    "# Extracting performance data\n",
    "def extract_performance_data(data):\n",
    "    result = {}\n",
    "    for bowler, ratings in data.items():\n",
    "        result[bowler] = {}\n",
    "        for rating, metrics in ratings.items():\n",
    "            result[bowler][rating] = np.array([metrics[param] for param in ['runs_conceded', 'wickets', 'extras', 'balls_bowled', 'innings']])\n",
    "    return result\n",
    "\n",
    "performance_data_array = extract_performance_data(performance_data)\n",
    "\n",
    "# Calculate scores for each bowler and rating\n",
    "def calculate_bowler_scores(data, performance_vector, performance_priority_vector):\n",
    "    scores = {}\n",
    "    for bowler, ratings in data.items():\n",
    "        scores[bowler] = {}\n",
    "        for rating, metrics in ratings.items():\n",
    "            performance_score = np.dot(metrics, performance_priority_vector)\n",
    "            final_score = batsman_priority_vector[int(rating) - 1] * performance_score\n",
    "            scores[bowler][rating] = final_score\n",
    "    return scores\n",
    "\n",
    "# Perform calculation\n",
    "final_scores = calculate_bowler_scores(performance_data_array, performance_priority_vector, performance_priority_vector)\n",
    "\n",
    "# Print results\n",
    "for bowler, ratings in final_scores.items():\n",
    "    print(f\"Bowler: {bowler}\")\n",
    "    for rating, score in ratings.items():\n",
    "        print(f\"  Rating {rating}: Score {score:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dff7e4-5d91-44af-ba15-546f974107ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "performance_data = key_fina\n",
    "\n",
    "# Pairwise Comparison Matrices\n",
    "batsman_comparison_matrix = np.array([\n",
    "    [1, 1.5, 1.75, 2],\n",
    "    [0.667, 1, 1.5, 1.75],\n",
    "    [0.571, 0.667, 1, 1.5],\n",
    "    [0.5, 0.571, 0.667, 1]\n",
    "])\n",
    "\n",
    "performance_comparison_matrix = np.array([\n",
    "    [1, 1/3, 1/5, 1/3, 1/3],\n",
    "    [3, 1, 1/3, 1/3, 1/2],\n",
    "    [5, 3, 1, 2, 2],\n",
    "    [3, 3, 1/2, 1, 1],\n",
    "    [3, 2, 1/2, 1, 1]\n",
    "])\n",
    "\n",
    "def normalize_matrix(matrix):\n",
    "    col_sum = matrix.sum(axis=0)\n",
    "    return matrix / col_sum\n",
    "\n",
    "def calculate_priority_vector(normalized_matrix):\n",
    "    return normalized_matrix.mean(axis=1)\n",
    "\n",
    "# Normalize matrices\n",
    "norm_batsman_matrix = normalize_matrix(batsman_comparison_matrix)\n",
    "norm_performance_matrix = normalize_matrix(performance_comparison_matrix)\n",
    "\n",
    "# Calculate priority vectors\n",
    "batsman_priority_vector = calculate_priority_vector(norm_batsman_matrix)\n",
    "performance_priority_vector = calculate_priority_vector(norm_performance_matrix)\n",
    "\n",
    "# Extracting performance data\n",
    "def extract_performance_data(data):\n",
    "    result = {}\n",
    "    for bowler, ratings in data.items():\n",
    "        result[bowler] = {}\n",
    "        for rating, metrics in ratings.items():\n",
    "            result[bowler][rating] = np.array([metrics[param] for param in ['runs_conceded', 'wickets', 'extras', 'balls_bowled', 'innings']])\n",
    "    return result\n",
    "\n",
    "performance_data_array = extract_performance_data(performance_data)\n",
    "\n",
    "# Calculate final score for each bowler\n",
    "def calculate_final_score(ratings, performance_weights):\n",
    "    final_scores = {}\n",
    "    for bowler, ratings_data in ratings.items():\n",
    "        bowler_final_score = 0\n",
    "        for rating, metrics in ratings_data.items():\n",
    "            weighted_performance = np.dot(performance_weights, metrics)\n",
    "            final_score_for_rating = batsman_priority_vector[int(rating) - 1] * weighted_performance\n",
    "            bowler_final_score += final_score_for_rating\n",
    "        final_scores[bowler] = bowler_final_score\n",
    "    return final_scores\n",
    "\n",
    "# Calculate final scores\n",
    "final_scores = calculate_final_score(performance_data_array, performance_priority_vector)\n",
    "\n",
    "# Calculate final ratings as sum of final_scores weighted by bowler ratings\n",
    "def calculate_final_rating(final_scores, batsman_priority_vector):\n",
    "    final_ratings = {}\n",
    "    for bowler, score in final_scores.items():\n",
    "        # Calculate weighted final score\n",
    "        weighted_final_score = np.dot(batsman_priority_vector, np.array([final_scores[bowler]] * len(batsman_priority_vector)))\n",
    "        final_ratings[bowler] = weighted_final_score\n",
    "    return final_ratings\n",
    "\n",
    "# Perform final rating calculation\n",
    "final_ratings = calculate_final_rating(final_scores, batsman_priority_vector)\n",
    "# Print results\n",
    "sorted_ratings = sorted(final_ratings.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# Print sorted ratings\n",
    "for bowler, rating in sorted_ratings:\n",
    "    print(f\"Bowler: {bowler}, Final Rating: {rating:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea28b07-342e-49cc-9313-b5666010d2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_bow=sorted_ratings[1:]\n",
    "values = [value for name, value in nr_bow]\n",
    "\n",
    "# Compute min and max values\n",
    "min_value = min(values)\n",
    "max_value = max(values)\n",
    "\n",
    "# Normalize values\n",
    "normalized_data = [(name, (value - min_value) / (max_value - min_value)) for name, value in nr_bow]\n",
    "\n",
    "# Output the normalized data\n",
    "for name, normalized_value in normalized_data:\n",
    "    print(f'{name}: {normalized_value:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3956fdc1-bb84-4761-9bac-22353cf151d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data for top players\n",
    "data = [\n",
    "    ('J Errington', 1.0000),\n",
    "    ('F Wright', 0.9722),\n",
    "    ('S Lowther', 0.8786),\n",
    "    ('T Baker', 0.8047),\n",
    "    ('R Scott', 0.8014),\n",
    "    ('G Kilner', 0.8001),\n",
    "    ('H Higginson', 0.7894),\n",
    "    ('E Morris', 0.7635),\n",
    "    ('B Thompson', 0.7535),\n",
    "    ('A Carter', 0.7456),\n",
    "    ('H Keegan', 0.7348),\n",
    "    ('N Workman', 0.7319),\n",
    "    ('J Mellons', 0.6991)\n",
    "]\n",
    "\n",
    "# Sort data by rating and get top 10\n",
    "top_10 = sorted(data, key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "# Separate names and ratings for plotting\n",
    "names, ratings = zip(*top_10)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(names, ratings, color='skyblue')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Player Name')\n",
    "plt.title('Top 10 Players by Rating')\n",
    "plt.gca().invert_yaxis()  # Highest ratings at the top\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig('top_10_players_by_rating.png', bbox_inches='tight')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9070387b-e197-4f8e-aff7-03e40ee42df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract float values\n",
    "values = [x[1] for x in normalized_data]\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(range(len(values)), values, color='blue', marker='o')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Scatter Plot of Values')\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the plot as an image file\n",
    "plt.savefig('scatter_plot.png')\n",
    "\n",
    "# Show the plot (optional, remove if not needed)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6747fcf2-7ec5-4108-911e-86300a0c53a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_dict = dict(normalized_data)\n",
    "player_stats=bowler_metrics\n",
    "def update_player_ratings(stats_dict, ratings_dict):\n",
    "    for player, stats in stats_dict.items():\n",
    "        if player in ratings_dict:\n",
    "            stats['rating'] = ratings_dict[player]\n",
    "        else:\n",
    "            stats['rating'] = None  # Handle missing ratings\n",
    "\n",
    "# Update player stats with ratings\n",
    "update_player_ratings(player_stats, rating_dict)\n",
    "\n",
    "# Print updated player stats\n",
    "for player, stats in player_stats.items():\n",
    "    print(f\"Player: {player}\")\n",
    "    print(f\"Stats: {stats}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2a45e3-a3f6-4dba-bf01-6c9e0014e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(player_stats).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a231abe7-b463-4981-8725-a26de47f07bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Rating Class'] = pd.cut(df['rating'], bins=np.linspace(0, 1, 11), labels=range(1, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee25e7d-f4ed-4754-a967-17cb34e5936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3d44c8-e1ca-435e-a545-8b0381add770",
   "metadata": {},
   "source": [
    "Data Preparation\n",
    "Features and Target Selection:\n",
    "\n",
    "The code begins by defining the features (X) and the target variable (y).\n",
    "X is created by dropping the rating and Rating Class columns from the DataFrame df. The remaining columns are used as features.\n",
    "y is set to the Rating Class, which is the categorical variable that the model will try to predict.\n",
    "Train-Test Split:\n",
    "\n",
    "The dataset is split into training and testing sets using train_test_split.\n",
    "30% of the data is reserved for testing, while 70% is used to train the model.\n",
    "The random_state parameter is set to 42 to ensure reproducibility.\n",
    "2. Model Training\n",
    "A LinearRegression model is instantiated and trained on the training data (X_train, y_train).\n",
    "Linear regression is typically used for continuous outputs, but in this case, it's being used to predict a categorical variable. The model will output continuous predictions, which will be rounded to the nearest integer for classification.\n",
    "3. Making Predictions\n",
    "Predictions (y_pred) are made on the test set (X_test).\n",
    "The predictions are rounded to the nearest integer using np.round() to convert the continuous output of the linear regression model into discrete class labels.\n",
    "Similarly, the actual test labels (y_test) are converted to integers to ensure compatibility when comparing them with the predicted values.\n",
    "4. Model Evaluation\n",
    "Accuracy Calculation:\n",
    "\n",
    "Accuracy is calculated by comparing the rounded predictions (y_pred_rounded) with the actual labels (y_test_rounded).\n",
    "The proportion of correctly predicted labels is multiplied by 100 to express the accuracy as a percentage.\n",
    "Error and Fit Metrics:\n",
    "\n",
    "Mean Squared Error (MSE): The average squared difference between the actual and predicted values. This metric is calculated after applying np.ceil() to the predictions to handle potential underestimation by the linear model.\n",
    "R² Score: A statistical measure that represents the proportion of variance in the dependent variable that is predictable from the independent variables. An R² score close to 1 indicates a good fit.\n",
    "5. Model Coefficients\n",
    "The coefficients of the linear regression model are printed alongside their corresponding feature names. These coefficients represent the weight or importance of each feature in predicting the target variable.\n",
    "A positive coefficient indicates that an increase in the feature value leads to an increase in the predicted target value, while a negative coefficient suggests the opposite.\n",
    "6. Summary of Results\n",
    "Coefficients: The feature names and their corresponding coefficients give insights into which features have the most influence on the Rating Class.\n",
    "MSE and R²: These metrics provide information about the model's performance in terms of prediction error and goodness-of-fit.\n",
    "Accuracy: The percentage of correct predictions indicates how well the model classifies the Rating Class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865ce5a0-dd9d-4736-949d-4666ae3e36aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X = df.drop(columns=['rating',  'Rating Class'])\n",
    "y = df['Rating Class']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert predictions and actual values to integers for classification accuracy\n",
    "y_pred_rounded = np.round(y_pred).astype(int)\n",
    "y_test_rounded = y_test.astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(y_pred_rounded == y_test_rounded)\n",
    "accuracy_percentage = accuracy * 100\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = np.ceil(y_pred)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print coefficients\n",
    "coefficients = model.coef_\n",
    "feature_names = X.columns\n",
    "\n",
    "print(\"Model Coefficients:\")\n",
    "for feature, coef in zip(feature_names, coefficients):\n",
    "    print(f\"{feature}: {coef:.4f}\")\n",
    "\n",
    "print(f\"\\nMean Squared Error: {mse:.4f}\")\n",
    "print(f\"R^2 Score: {r2:.4f}\")\n",
    "print(f\"Prediction Accuracy: {accuracy_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa53c27-d5ef-429e-a061-ed7c84c1f5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea293992-66ed-4921-83a8-05eacf617e23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0df69a8-1b7d-4e74-8b4b-236704f8381c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f97577-c40c-4818-9f2b-06eaa710a434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51a4e62-5e4b-40af-acae-642d8f3a7d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa9fce6-017a-4468-a5c1-8fd45d1a5bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
