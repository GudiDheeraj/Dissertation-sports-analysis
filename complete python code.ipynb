{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aece11b4-edb4-4b27-8a56-738531b7801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input = input(\"Enter the year you want to rank players (between 2010 and 2024, default is 2024): \")\n",
    "    \n",
    "    if user_input == \"\":\n",
    "        year = 2024\n",
    "    else:\n",
    "        year = int(user_input)\n",
    "    \n",
    "    if 2010 <= year <= 2024:\n",
    "        break\n",
    "    else:\n",
    "        print(\"Please enter a number between 2010 and 2024.\")\n",
    "\n",
    "# Calculate the value based on the year\n",
    "value = str(257 - (2024 - year))\n",
    "\n",
    "# Now you can use the `value` variable as needed\n",
    "print(f\"The value for the year {year} is {value}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2ea9d8-8a32-442c-867f-a7c45505c752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "cookies = {\n",
    "    'fdp-fingerprint': '1889803a551ecbaea1a74b3111b91ec8',\n",
    "    'OptanonAlertBoxClosed': '2024-04-30T13:30:53.182Z',\n",
    "    'ai_user': 'CU74D3KILVFnI2v4blNfQP|2024-06-03T19:59:44.280Z',\n",
    "    '_gid': 'GA1.2.972306044.1717694055',\n",
    "    '_play_cricket_session': 'IKqmU7wVY5OKGzKIUjS1WEZ0KyUUgl3h%2FePq67zQyx9aXbD3SUe85zj4a9MprzB7lOinQzJUCm7xlGHuMnYnC4QW9D6PgDKtC9ItW4HW2x6Uti8TZT1uxEPzuApob8fGSvOQTkKVDNE5dwhEXaDlP1XDBVR0gIpEV8T7U5xBN28JutWjt3O7LT1bjk8s%2FkgTCVHotMI%2F7mzEkm6nSOUjJbVcnjx5OiAEROrzjtOwJy9iQJTP5IHBUvWttfd0ypJf9HsAseu2YdXjVRoaLr0vUCxvQLS%2B136KPsoAFWMj3w%2FKGB4aSuwou3RXIHn9UxP%2FpaOL%2F3uafHHg1%2F%2B6Xn%2BexxY2srq5OKNhs3FWIdd07wdR76xFW2SGa86sQqn6vFYzeg%3D%3D--md3L0ZgpqH4CmuTu--C9cpDGB9yOBsoNl4z3ivIQ%3D%3D',\n",
    "    'TSd091cc5a027': '08ac97c60eab2000ffbe1b9cf025675bb1526cd069f3d6c33c069bf3b00b6a0cc94c962a8ec9ff64084342fb361130002eaafe37980af451e70b0b4d170ac4da0ab37739a3781d7fbf668fbc5bf9c0edbc248ede0a4510fe2310b0695f8fdacc',\n",
    "    'OptanonConsent': 'isGpcEnabled=0&datestamp=Thu+Jun+06+2024+20%3A09%3A21+GMT%2B0100+(British+Summer+Time)&version=202401.2.0&browserGpcFlag=0&isIABGlobal=false&hosts=&consentId=d771d464-7a78-4757-91b3-39bade7bccaa&interactionCount=1&landingPath=NotLandingPage&groups=C0001%3A1%2CC0002%3A1%2CC0004%3A1&geolocation=GB%3BENG&AwaitingReconsent=false',\n",
    "    '_ga_ZP882GSBL8': 'GS1.2.1717700942.6.1.1717700961.0.0.0',\n",
    "    '_ga_HHWFVJSD1E': 'GS1.1.1717700944.9.1.1717700962.0.0.0',\n",
    "    '_ga': 'GA1.1.1376912539.1714483850',\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "    'Accept-Language': 'en-GB,en-US;q=0.9,en;q=0.8',\n",
    "    'Cache-Control': 'max-age=0',\n",
    "    'Connection': 'keep-alive',\n",
    "    # 'Cookie': 'fdp-fingerprint=1889803a551ecbaea1a74b3111b91ec8; OptanonAlertBoxClosed=2024-04-30T13:30:53.182Z; ai_user=CU74D3KILVFnI2v4blNfQP|2024-06-03T19:59:44.280Z; _gid=GA1.2.972306044.1717694055; _play_cricket_session=IKqmU7wVY5OKGzKIUjS1WEZ0KyUUgl3h%2FePq67zQyx9aXbD3SUe85zj4a9MprzB7lOinQzJUCm7xlGHuMnYnC4QW9D6PgDKtC9ItW4HW2x6Uti8TZT1uxEPzuApob8fGSvOQTkKVDNE5dwhEXaDlP1XDBVR0gIpEV8T7U5xBN28JutWjt3O7LT1bjk8s%2FkgTCVHotMI%2F7mzEkm6nSOUjJbVcnjx5OiAEROrzjtOwJy9iQJTP5IHBUvWttfd0ypJf9HsAseu2YdXjVRoaLr0vUCxvQLS%2B136KPsoAFWMj3w%2FKGB4aSuwou3RXIHn9UxP%2FpaOL%2F3uafHHg1%2F%2B6Xn%2BexxY2srq5OKNhs3FWIdd07wdR76xFW2SGa86sQqn6vFYzeg%3D%3D--md3L0ZgpqH4CmuTu--C9cpDGB9yOBsoNl4z3ivIQ%3D%3D; TSd091cc5a027=08ac97c60eab2000ffbe1b9cf025675bb1526cd069f3d6c33c069bf3b00b6a0cc94c962a8ec9ff64084342fb361130002eaafe37980af451e70b0b4d170ac4da0ab37739a3781d7fbf668fbc5bf9c0edbc248ede0a4510fe2310b0695f8fdacc; OptanonConsent=isGpcEnabled=0&datestamp=Thu+Jun+06+2024+20%3A09%3A21+GMT%2B0100+(British+Summer+Time)&version=202401.2.0&browserGpcFlag=0&isIABGlobal=false&hosts=&consentId=d771d464-7a78-4757-91b3-39bade7bccaa&interactionCount=1&landingPath=NotLandingPage&groups=C0001%3A1%2CC0002%3A1%2CC0004%3A1&geolocation=GB%3BENG&AwaitingReconsent=false; _ga_ZP882GSBL8=GS1.2.1717700942.6.1.1717700961.0.0.0; _ga_HHWFVJSD1E=GS1.1.1717700944.9.1.1717700962.0.0.0; _ga=GA1.1.1376912539.1714483850',\n",
    "    'DNT': '1',\n",
    "    'If-None-Match': 'W/\"e73977832b057e5923fc0354614ca18d\"',\n",
    "    'Referer': 'https://durhamcity.play-cricket.com/home',\n",
    "    'Sec-Fetch-Dest': 'document',\n",
    "    'Sec-Fetch-Mode': 'navigate',\n",
    "    'Sec-Fetch-Site': 'same-origin',\n",
    "    'Sec-Fetch-User': '?1',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36',\n",
    "    'sec-ch-ua': '\"Google Chrome\";v=\"125\", \"Chromium\";v=\"125\", \"Not.A/Brand\";v=\"24\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform': '\"Windows\"',\n",
    "}\n",
    "\n",
    "response = requests.get('https://dcbjuniorlge.play-cricket.com/home', cookies=cookies, headers=headers)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2041fb86-c9ce-490d-9194-a74ecafac4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import Select, WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Initialize the WebDriver with ChromeDriverManager\n",
    "driver_path = r'C:\\Users\\dheer\\chromedriver.exe'\n",
    "\n",
    "service = Service(driver_path)\n",
    "options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "\n",
    "\n",
    "# Define the cookies\n",
    "cookies1 = [\n",
    "    {'name': 'fdp-fingerprint', 'value': '1889803a551ecbaea1a74b3111b91ec8'},\n",
    "    {'name': 'OptanonAlertBoxClosed', 'value': '2024-04-30T13:30:53.182Z'},\n",
    "    {'name': 'ai_user', 'value': 'CU74D3KILVFnI2v4blNfQP|2024-06-03T19:59:44.280Z'},\n",
    "    {'name': '_gid', 'value': 'GA1.2.972306044.1717694055'},\n",
    "    {'name': '_play_cricket_session', 'value': 'IKqmU7wVY5OKGzKIUjS1WEZ0KyUUgl3h%2FePq67zQyx9aXbD3SUe85zj4a9MprzB7lOinQzJUCm7xlGHuMnYnC4QW9D6PgDKtC9ItW4HW2x6Uti8TZT1uxEPzuApob8fGSvOQTkKVDNE5dwhEXaDlP1XDBVR0gIpEV8T7U5xBN28JutWjt3O7LT1bjk8s%2FkgTCVHotMI%2F7mzEkm6nSOUjJbVcnjx5OiAEROrzjtOwJy9iQJTP5IHBUvWttfd0ypJf9HsAseu2YdXjVRoaLr0vUCxvQLS%2B136KPsoAFWMj3w%2FKGB4aSuwou3RXIHn9UxP%2FpaOL%2F3uafHHg1%2F%2B6Xn%2BexxY2srq5OKNhs3FWIdd07wdR76xFW2SGa86sQqn6vFYzeg%3D%3D--md3L0ZgpqH4CmuTu--C9cpDGB9yOBsoNl4z3ivIQ%3D%3D'},\n",
    "    {'name': 'TSd091cc5a027', 'value': '08ac97c60eab2000ffbe1b9cf025675bb1526cd069f3d6c33c069bf3b00b6a0cc94c962a8ec9ff64084342fb361130002eaafe37980af451e70b0b4d170ac4da0ab37739a3781d7fbf668fbc5bf9c0edbc248ede0a4510fe2310b0695f8fdacc'},\n",
    "    {'name': 'OptanonConsent', 'value': 'isGpcEnabled=0&datestamp=Thu+Jun+06+2024+20%3A09%3A21+GMT%2B0100+(British+Summer+Time)&version=202401.2.0&browserGpcFlag=0&isIABGlobal=false&hosts=&consentId=d771d464-7a78-4757-91b3-39bade7bccaa&interactionCount=1&landingPath=NotLandingPage&groups=C0001%3A1%2CC0002%3A1%2CC0004%3A1&geolocation=GB%3BENG&AwaitingReconsent=false'},\n",
    "    {'name': '_ga_ZP882GSBL8', 'value': 'GS1.2.1717700942.6.1.1717700961.0.0.0'},\n",
    "    {'name': '_ga_HHWFVJSD1E', 'value': 'GS1.1.1717700944.9.1.1717700962.0.0.0'},\n",
    "    {'name': '_ga', 'value': 'GA1.1.1376912539.1714483850'}\n",
    "]\n",
    "\n",
    "try:\n",
    "    # Open the web page\n",
    "    driver.get('https://dcbjuniorlge.play-cricket.com/home')\n",
    "\n",
    "    # Add cookies to the session\n",
    "    for cookie in cookies1:\n",
    "        driver.add_cookie(cookie)\n",
    "\n",
    "    # Refresh the page to apply the cookies\n",
    "    driver.refresh()\n",
    "\n",
    "    # Wait for the dropdown to be present and select the option with value '256'\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    dropdown = wait.until(EC.presence_of_element_located((By.ID, 'season')))\n",
    "    select = Select(dropdown)\n",
    "    select.select_by_value(value)\n",
    "\n",
    "    # Wait for the page to update after selecting the dropdown value\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Get the updated HTML content of the page\n",
    "    html_content = driver.page_source\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Print the parsed HTML content\n",
    "    print(soup.prettify())\n",
    "finally:\n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be11f7a-2d99-4fb3-b749-6fb059277fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "div = soup.find('div',class_=\"panel-body\")\n",
    "links = div.find_all('a')\n",
    "initial_dict={}\n",
    "for link in links:\n",
    "    href = link.get('href')\n",
    "    text = link.get_text(strip=True)\n",
    "    initial_dict[text]=href"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782f8acf-f59e-483c-b78a-60d4526a606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dict = {key: value for key, value in initial_dict.items() if '13' in key and 'Girls' not in key}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ac8783-ff74-499a-ac57-21f125b91ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_link=[]\n",
    "for i in filtered_dict:\n",
    "    final_link.append(\"https://dcbjuniorlge.play-cricket.com/\"+filtered_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e328c6-c5a5-433e-80ee-bcbf1135292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_link=[]\n",
    "for i in final_link:\n",
    "    response1 = requests.get(i, cookies=cookies, headers=headers)\n",
    "    soup = BeautifulSoup(response1.content, 'html.parser')\n",
    "    rows = soup.find_all('tr', class_='league_row')\n",
    "\n",
    "    # Create a dictionary to store the team names and their links\n",
    "    teams_dict = {}\n",
    "\n",
    "    for row in rows:\n",
    "        link = row.find('a')\n",
    "        if link:\n",
    "            team_name = link.get_text(strip=True)\n",
    "            href = link.get('href')\n",
    "            teams_dict[team_name] = href\n",
    "\n",
    "    # Print the dictionary to verify the contents\n",
    "    for team, link in teams_dict.items():\n",
    "        print(f\"'{team}': '{link}'\")\n",
    "        all_link.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053ffc62-e237-445c-a40e-c50c00ed92ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "l2023=[]\n",
    "for i in all_link:\n",
    "    match=[]\n",
    "    response1 = requests.get(i, cookies=cookies, headers=headers)\n",
    "    soup = BeautifulSoup(response1.content, 'html.parser')\n",
    "    div=soup.find('div',class_=\"tab-content brnone\")\n",
    "    tbody=div.find('tbody')\n",
    "    tr=tbody.find_all('tr')\n",
    "    for j in tr:\n",
    "        td=j.find('td', class_=\"tfont3\")\n",
    "        if td:  # Check if td is not None\n",
    "                match.append(td)\n",
    "\n",
    "    # Provided URL\n",
    "    url = i\n",
    "\n",
    "    # Parse the URL\n",
    "    parsed_url = urlparse(url)\n",
    "\n",
    "    # Split the path component by slashes\n",
    "    path_parts = parsed_url.path.split('/')\n",
    "\n",
    "    # Join the path components except for the last part\n",
    "    trimmed_path = '/'.join(path_parts[:-2])\n",
    "\n",
    "    # Reconstruct the URL up to the last second slash\n",
    "    trimmed_url = f\"{parsed_url.scheme}://{parsed_url.netloc}{trimmed_path}\"\n",
    "\n",
    "    # Print the result\n",
    "\n",
    "\n",
    "    matchs = [ str(k) for k in match]\n",
    "    # Initialize the link variable\n",
    "    link_2023 = None\n",
    "\n",
    "    # Iterate over the match list to find the one with the 2023 link\n",
    "    for html_str in matchs:\n",
    "        # Ensure the item is a string\n",
    "        if html_str:\n",
    "            # Parse the HTML string\n",
    "            td = BeautifulSoup(html_str, 'html.parser').td\n",
    "            # Find the 'a' tag within the td\n",
    "            a_tag = td.find('a')\n",
    "            # Check if the text of the 'a' tag is '2023'\n",
    "            if a_tag and a_tag.text == '2024':\n",
    "                link_2023 = a_tag['href']\n",
    "                break\n",
    "\n",
    "    if trimmed_url != None and link_2023 != None:\n",
    "        # Print the link for 2023\n",
    "        l2023.append(trimmed_url+link_2023)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4076ec5f-21bf-4db2-8791-045ebf70c594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse, urlunparse\n",
    "\n",
    "# Assuming l2023, cookies, and headers are already defined\n",
    "ball_link = []\n",
    "\n",
    "for i in l2023:\n",
    "    response1 = requests.get(i, cookies=cookies, headers=headers)\n",
    "    soup = BeautifulSoup(response1.content, 'html.parser')\n",
    "    divs = soup.find_all('div', class_='col-sm-1 col-md-1 d-none d-md-block')\n",
    "\n",
    "    # Filter links that have <i class=\"material-icons\">assignment</i>\n",
    "    filtered_links = []\n",
    "\n",
    "    for div in divs:\n",
    "        link = div.find('a', class_='link-scorecard d-none d-md-inline-block rounded-circle')\n",
    "        if link:\n",
    "            parsed_url = urlparse(i)\n",
    "            # Reconstruct the URL without the specific path and query\n",
    "            trimmed_url = urlunparse((parsed_url.scheme, parsed_url.netloc, '', '', '', ''))\n",
    "            filtered_links.append(trimmed_url + link.get('href'))        \n",
    "\n",
    "    ball_link.append(filtered_links)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2b94af-2c04-4a9f-ba0e-8bf29eb96802",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreball = []\n",
    "z=0\n",
    "for i in ball_link:\n",
    "    for j in i:\n",
    "        response1 = requests.get(j, cookies=cookies, headers=headers)\n",
    "        soup = BeautifulSoup(response1.content, 'html.parser')\n",
    "        li = soup.find('li', class_=\"li-iasBallbyballtab\")\n",
    "\n",
    "        # Check if 'li' is found\n",
    "        if li:\n",
    "\n",
    "            a = li.find('a')\n",
    "            href = a.get('href')\n",
    "            scoreball.append(j)\n",
    "        z=z+1 \n",
    "    print(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae980351-de70-4c2c-8d50-0f56aa266790",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreball = [url for url in scoreball if url not in urls_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b965ec-7ace-4efd-9794-da47c800d7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data for each over\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "z=0\n",
    "columns = ['Over', 'Ball', 'Event', 'Commentary', 'innings', 'teamname','teamscore', 'teamtossinfo','full_match_result', 'Player', 'Dismissal', 'R', 'B', '4s', '6s', 'SR']\n",
    "\n",
    "    # Create an empty DataFrame with specified columns\n",
    "df_data = pd.DataFrame(columns=columns)\n",
    "for i in scoreball:\n",
    "    print(i)\n",
    "    z=z+1\n",
    "    print(z)\n",
    "    # Initialize Chrome options\n",
    "    \n",
    "    # Initialize the WebDriver with ChromeDriverManager\n",
    "    driver_path = r'C:\\Users\\dheer\\chromedriver.exe'\n",
    "    \n",
    "    service = Service(driver_path)\n",
    "    options = webdriver.ChromeOptions()\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    # Define your cookies\n",
    "    cookies = [\n",
    "        {'name': 'fdp-fingerprint', 'value': '1889803a551ecbaea1a74b3111b91ec8'},\n",
    "        {'name': 'OptanonAlertBoxClosed', 'value': '2024-04-30T13:30:53.182Z'},\n",
    "        {'name': 'ai_user', 'value': 'CU74D3KILVFnI2v4blNfQP|2024-06-03T19:59:44.280Z'},\n",
    "        {'name': '_gid', 'value': 'GA1.2.972306044.1717694055'},\n",
    "        {'name': '_play_cricket_session', 'value': 'IKqmU7wVY5OKGzKIUjS1WEZ0KyUUgl3h%2FePq67zQyx9aXbD3SUe85zj4a9MprzB7lOinQzJUCm7xlGHuMnYnC4QW9D6PgDKtC9ItW4HW2x6Uti8TZT1uxEPzuApob8fGSvOQTkKVDNE5dwhEXaDlP1XDBVR0gIpEV8T7U5xBN28JutWjt3O7LT1bjk8s%2FkgTCVHotMI%2F7mzEkm6nSOUjJbVcnjx5OiAEROrzjtOwJy9iQJTP5IHBUvWttfd0ypJf9HsAseu2YdXjVRoaLr0vUCxvQLS%2B136KPsoAFWMj3w%2FKGB4aSuwou3RXIHn9UxP%2FpaOL%2F3uafHHg1%2F%2B6Xn%2BexxY2srq5OKNhs3FWIdd07wdR76xFW2SGa86sQqn6vFYzeg%3D%3D--md3L0ZgpqH4CmuTu--C9cpDGB9yOBsoNl4z3ivIQ%3D%3D'},\n",
    "        {'name': 'TSd091cc5a027', 'value': '08ac97c60eab2000ffbe1b9cf025675bb1526cd069f3d6c33c069bf3b00b6a0cc94c962a8ec9ff64084342fb361130002eaafe37980af451e70b0b4d170ac4da0ab37739a3781d7fbf668fbc5bf9c0edbc248ede0a4510fe2310b0695f8fdacc'},\n",
    "        {'name': 'OptanonConsent', 'value': 'isGpcEnabled=0&datestamp=Thu+Jun+06+2024+20%3A09%3A21+GMT%2B0100+(British+Summer+Time)&version=202401.2.0&browserGpcFlag=0&isIABGlobal=false&hosts=&consentId=d771d464-7a78-4757-91b3-39bade7bccaa&interactionCount=1&landingPath=NotLandingPage&groups=C0001%3A1%2CC0002%3A1%2CC0004%3A1&geolocation=GB%3BENG&AwaitingReconsent=false'},\n",
    "        {'name': '_ga_ZP882GSBL8', 'value': 'GS1.2.1717700942.6.1.1717700961.0.0.0'},\n",
    "        {'name': '_ga_HHWFVJSD1E', 'value': 'GS1.1.1717700944.9.1.1717700962.0.0.0'},\n",
    "        {'name': '_ga', 'value': 'GA1.1.1376912539.1714483850'}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        # Open the web page\n",
    "        driver.get(i)\n",
    "\n",
    "        # Add cookies to the session\n",
    "        for cookie in cookies:\n",
    "            driver.add_cookie(cookie)\n",
    "\n",
    "        # Refresh the page to apply the cookies\n",
    "        driver.refresh()\n",
    "\n",
    "        # Wait for the 'Ball by Ball' tab to be clickable and click it\n",
    "        wait = WebDriverWait(driver, 7)\n",
    "       \n",
    "        ball_by_ball_tab = wait.until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"iasBallbyballtab-tab\"]')))\n",
    "        ball_by_ball_tab.click()\n",
    "\n",
    "        # Wait for the data to load (you may need to adjust the wait time or the condition)\n",
    "        time.sleep(3)  # Adjust this sleep time if necessary\n",
    "\n",
    "        # Scrape the data you need\n",
    "        \n",
    "        data_elements = driver.find_elements(By.XPATH, '//*[@id=\"iasBallbyball\"]/div/div[2]/div[2]/div')\n",
    "        if data_elements == []:\n",
    "            continue\n",
    "        for element in data_elements:\n",
    "            element_html1 = element.get_attribute('outerHTML')\n",
    "        if (len(element_html1))< 1000:\n",
    "            continue\n",
    "        try:\n",
    "            ball_by_ball_tab = wait.until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"iasBallbyball\"]/div/div[1]/ul/li[2]')))\n",
    "\n",
    "            ball_by_ball_tab.click()\n",
    "\n",
    "            time.sleep(3)  # Adjust this sleep time if necessary\n",
    "\n",
    "            # Scrape the data you need\n",
    "            data_elements = driver.find_elements(By.XPATH, '//*[@id=\"iasBallbyball\"]/div/div[2]/div[2]/div')\n",
    "            for element in data_elements:\n",
    "                element_html2 = element.get_attribute('outerHTML')\n",
    "        except TimeoutException:\n",
    "            driver.quit()\n",
    "    finally:\n",
    "        # Close the WebDriver\n",
    "        driver.quit()\n",
    "\n",
    "    response1 = requests.get(i)\n",
    "    soup = BeautifulSoup(response1.content, 'html.parser')\n",
    "    td=soup.find_all('td',class_=\"col-md-4 text-center v-top\")\n",
    "    tdc=soup.find('td',class_=\"col-md-4 text-center bluebg-top\")\n",
    "    team1_name = team1_score = team1_toss_info = ''\n",
    "    team2_name = team2_score = team2_toss_info = ''\n",
    "\n",
    "    # Extract team data\n",
    "    team_data = []\n",
    "\n",
    "    for i, team in enumerate(td):\n",
    "        score1 = tdc\n",
    "        team_name = team.find('p', class_='team-name').text.strip()\n",
    "        team_info_2 = team.find('p', class_='team-info-2')\n",
    "        score = team.find('p', class_='team-info-2').get_text(separator=' ', strip=True)\n",
    "        score = ' '.join(score)\n",
    "        toss_info = team.find('p', class_='team-info-3 adma')\n",
    "        team_namex = ''\n",
    "        try:\n",
    "            team_namex = score1.find('p', class_='match-ttl win-cb-name').text.strip()\n",
    "        except AttributeError:\n",
    "            pass  # Handle the case where the element is not found, or do nothing\n",
    "        # Extract the match result\n",
    "        \n",
    "        if team_namex:\n",
    "            match_result_div = score1.find('div', class_='info mdont')\n",
    "            match_result = match_result_div.text.strip()\n",
    "            span_text = match_result_div.find('span').text.strip()\n",
    "        else:\n",
    "            match_result=\" \"\n",
    "            span_text=\" \"\n",
    "        # Combine the match result with the text inside the span tag\n",
    "        full_match_result = f\"{team_namex} {match_result} {span_text}\"\n",
    "        if not toss_info:\n",
    "            toss_info = team.find('p', class_='team-info-3')\n",
    "        toss_info = toss_info.text.strip() if toss_info else 'None'\n",
    "        if i == 0:\n",
    "            team1_name = team_name\n",
    "            team1_score = score\n",
    "            team1_toss_info = toss_info\n",
    "        elif i == 1:\n",
    "            team2_name = team_name\n",
    "            team2_score = score\n",
    "            team2_toss_info = toss_info\n",
    "\n",
    "    # Print the extracted data\n",
    "    team_data_dict = {\n",
    "        'team1name': team1_name,\n",
    "        'team1score': team1_score,\n",
    "        'team1tossinfo': team1_toss_info,\n",
    "        'team2name': team2_name,\n",
    "        'team2score': team2_score,\n",
    "        'team2tossinfo': team2_toss_info,\n",
    "        'full_match_result':full_match_result\n",
    "    }\n",
    "\n",
    "    innings=1\n",
    "    if team_data_dict['team1tossinfo']== 'Won the toss and elected to bat':\n",
    "        n=\"1\"\n",
    "    elif team_data_dict['team1tossinfo']== 'Won the toss and elected to field':\n",
    "        n=\"2\"\n",
    "    elif team_data_dict['team2tossinfo']== 'Won the toss and elected to bat':\n",
    "        n=\"2\"\n",
    "    elif team_data_dict['team2tossinfo']== 'Won the toss and elected to field':\n",
    "        n=\"1\"\n",
    "    \n",
    "    \n",
    "    columns = ['Over', 'Ball', 'Event', 'Commentary', 'innings', 'teamname',\n",
    "               'teamscore', 'teamtossinfo', 'full_match_result', 'Player', 'Dismissal', 'R', 'B', '4s', '6s', 'SR']\n",
    "\n",
    "    # Create an empty DataFrame with specified columns\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    for i in [element_html1,element_html2]:\n",
    "        soup = BeautifulSoup(i, 'html.parser')\n",
    "        over_containers = soup.find_all('div', class_='BallByBallStyle__OverContainer-sc-1u6d087-4')\n",
    "\n",
    "        # List to hold all ball data\n",
    "        all_ball_data = []\n",
    "\n",
    "        # Loop through each over container and extract ball data\n",
    "        for over_container in over_containers:\n",
    "            over_number = over_container.find('span', class_='BallByBallStyle__OverHeading-sc-1u6d087-5').text.strip()\n",
    "            ball_containers = over_container.find_all('div', class_='BallDetailViewStyle__BallContainerInner-sc-19vwj2-2')\n",
    "            teamname=\"team\"+n+\"name\"\n",
    "            teamscore=\"team\"+n+\"score\"\n",
    "            teamtossinfo=\"team\"+n+\"tossinfo\"\n",
    "            \n",
    "            for ball_container in ball_containers:\n",
    "                ball_data = {}\n",
    "                ball_data['Over'] = over_number\n",
    "                ball_data['Ball'] = ball_container.find('div', class_='BallDetailViewStyle__StandardContainer-sc-19vwj2-3').text.strip()\n",
    "                ball_data['Event'] = ball_container.find('div', class_='BallDetailViewStyle__CenterStandardContainer-sc-19vwj2-4').text.strip()\n",
    "                ball_data['Commentary'] = ball_container.find('div', class_='BallDetailViewStyle__CommentaryContainer-sc-19vwj2-5').text.strip()\n",
    "                ball_data['innings'] = innings\n",
    "                ball_data['teamname'] = team_data_dict[teamname]\n",
    "                ball_data['teamscore'] = team_data_dict[teamscore]\n",
    "                ball_data['teamtossinfo'] = team_data_dict[teamtossinfo]\n",
    "                ball_data['full_match_result']=team_data_dict[\"full_match_result\"]\n",
    "                # Additional player data if available\n",
    "                player_container = ball_container.find('div', class_='BallDetailViewStyle__WicketInformationContainer-sc-19vwj2-6')\n",
    "                if player_container:\n",
    "                    ball_data['Player'] = player_container.find('div', class_='BallDetailViewStyle__PersonName-sc-19vwj2-9').text.strip()\n",
    "                    ball_data['Dismissal'] = player_container.find('div', class_='BallDetailViewStyle__PersonDismissal-sc-19vwj2-10').text.strip()\n",
    "                    stats_containers = player_container.find_all('div', class_='BallDetailViewStyle__StatItem-sc-19vwj2-12')\n",
    "                    for stat_container in stats_containers:\n",
    "                        stat_heading = stat_container.find('div', class_='BallDetailViewStyle__StatHeading-sc-19vwj2-13').text.strip()\n",
    "                        stat_value = stat_container.find('div', class_='BallDetailViewStyle__StatValue-sc-19vwj2-14').text.strip()\n",
    "                        ball_data[stat_heading] = stat_value\n",
    "\n",
    "                all_ball_data.append(ball_data)\n",
    "        if team_data_dict['team1tossinfo']== 'Won the toss and elected to bat':\n",
    "            n=\"2\"\n",
    "        elif team_data_dict['team1tossinfo']== 'Won the toss and elected to field':\n",
    "            n=\"1\"\n",
    "        elif team_data_dict['team2tossinfo']== 'Won the toss and elected to bat':\n",
    "            n=\"1\"\n",
    "        elif team_data_dict['team2tossinfo']== 'Won the toss and elected to field':\n",
    "            n=\"2\"\n",
    "        # Create DataFrame\n",
    "        df1 = pd.DataFrame(all_ball_data)\n",
    "        df = pd.concat([df, df1], ignore_index=True)\n",
    "        innings=innings+1\n",
    "    df_data = pd.concat([df_data, df], ignore_index=True)\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9fafc0-3a26-44fd-a747-a587fb86c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['batting team'] = df_data['teamname']\n",
    "\n",
    "# Initialize the bowling team column with None\n",
    "df_data['bowling team'] = None\n",
    "\n",
    "# Iterate over the DataFrame to set the bowling team\n",
    "for i in range(len(df_data)):\n",
    "    if df_data.at[i, 'innings'] == 1:\n",
    "        # For innings 1, find the next row with innings 2\n",
    "        for j in range(i + 1, len(df_data)):\n",
    "            if df_data.at[j, 'innings'] == 2:\n",
    "                df_data.at[i, 'bowling team'] = df_data.at[j, 'teamname']\n",
    "                break\n",
    "    elif df_data.at[i, 'innings'] == 2:\n",
    "        # For innings 2, find the previous row with innings 1\n",
    "        for j in range(i - 1, -1, -1):\n",
    "            if df_data.at[j, 'innings'] == 1:\n",
    "                df_data.at[i, 'bowling team'] = df_data.at[j, 'teamname']\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38eeb08-fb40-4df7-991b-94626a537084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract bowler, batsman, and runs\n",
    "def extract_details(commentary):\n",
    "    # Split the commentary into parts\n",
    "    try:\n",
    "        bowler_part, batsman_part = commentary.split(\"to \")\n",
    "        batsman, runs = batsman_part.split(\":\")\n",
    "        bowler = bowler_part.strip()\n",
    "        batsman = batsman.strip() if batsman else None\n",
    "        runs = runs.strip()\n",
    "    except ValueError:\n",
    "        # In case of unexpected format\n",
    "        bowler, batsman, runs = None, None, None\n",
    "    \n",
    "    return bowler, batsman, runs\n",
    "\n",
    "# Apply the function to the Commentary column\n",
    "df_data[['bowler', 'batsman', 'runs']] = df_data['Commentary'].apply(lambda x: pd.Series(extract_details(x)))\n",
    "\n",
    "# Print the updated DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07ee726-6cfe-4bb1-9257-96ddcd9d1b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_rows = df_data.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b74e22-dd5e-4fa4-ba5e-e8d920ae91d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_path = 'finaldesertation.xlsx'\n",
    "unique_rows.to_excel(excel_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baca041-b1b1-4183-9713-3088b8f30218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_excel(\"finaldesertation.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2d9bef-1164-4f1f-afdb-3242b56aaccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c32b5b-9ab7-4c60-9364-3b7f6dc6106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[::-1].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc97b14-cf6b-40e2-932f-f1062f3eb00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from decimal import Decimal\n",
    "\n",
    "# Function to process events and calculate metrics for batsmen and bowlers\n",
    "def calculate_metrics(df):\n",
    "    # Initialize dictionaries to hold metrics\n",
    "    batsman_metrics = {}\n",
    "    bowler_metrics = {}\n",
    "\n",
    "    # Define scoring rules\n",
    "    runs_scored = {\n",
    "        '0 runs': 0, '1 run': 1, '2 runs': 2, '3 runs': 3, '4 runs': 4, '6 runs': 6,\n",
    "        '1 run \\n 1 no ball': 1, '2 runs \\n 1 no ball': 2, '3 runs \\n 1 no ball': 3, \n",
    "        '4 runs \\n 1 no ball': 4, '6 runs \\n 1 no ball': 6, '5 runs': 5,\n",
    "        '1 run \\n 2 no balls': 1, '4 runs \\n 2 no balls': 4,\n",
    "    }\n",
    "    \n",
    "    dismissals = [\n",
    "        'Wicket!', 'Wicket! \\n 2 wides', 'Wicket! \\n 1 run \\n 1 no ball', \n",
    "        'Wicket! \\n 1 run', 'Wicket! \\n 2 runs', 'Wicket! \\n 1 bye', \n",
    "        'Wicket! \\n 1 no ball', 'Wicket! \\n 1 wide', 'Wicket! \\n 1 leg bye'\n",
    "    ]\n",
    "\n",
    "    extras = {\n",
    "        '1 wide': 1, '2 wides': 2, '3 wides': 3, '4 wides': 4, '5 wides': 5, '6 wides': 6,\n",
    "        '1 no ball': 1, '2 no balls': 2, '1 bye': 1, '2 byes': 2, '3 byes': 3, \n",
    "        '4 byes': 4, '5 byes': 5, '1 leg bye': 1, '2 leg byes': 2, '3 leg byes': 3, \n",
    "        '4 leg byes': 4, '2 1nb + byes': 2, '3 1nb + byes': 3, '6 1nb + byes': 6, \n",
    "        '5 1nb + byes': 5, '4 1nb + byes': 4, '2 1nb + leg byes': 2\n",
    "    }\n",
    "\n",
    "    previous_bowling_team = None\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        event = row['Event']\n",
    "        bowler = row['bowler']\n",
    "        batsman = row['batsman']\n",
    "        bowling_team = row['bowling team']\n",
    "        over = int(row['Over'][5:])\n",
    "\n",
    "        # Initialize batsman and bowler if not already in the dictionary\n",
    "        if batsman not in batsman_metrics:\n",
    "            batsman_metrics[batsman] = {'runs': 0, 'boundaries': 0, 'dismissal': 0, 'balls_faced': 0, 'innings': 0, 'scores': []}\n",
    "        if bowler not in bowler_metrics:\n",
    "            bowler_metrics[bowler] = {'runs_conceded': 0, 'wickets': 0, 'extras': 0, 'balls_bowled': 0, 'innings': 0}\n",
    "\n",
    "        # Handle change in batting team (new match or new innings)\n",
    "        if previous_bowling_team is not None and previous_bowling_team != bowling_team:\n",
    "            # Save the scores for all batsmen\n",
    "            for b in batsman_metrics:\n",
    "                if batsman_metrics[b]['runs'] > 0:\n",
    "                    batsman_metrics[b]['scores'].append(batsman_metrics[b]['runs'])\n",
    "                    batsman_metrics[b]['runs'] = 0\n",
    "\n",
    "        # Calculate metrics for batsmen\n",
    "        if event in runs_scored:\n",
    "            runs = runs_scored[event]\n",
    "            batsman_metrics[batsman]['runs'] += runs\n",
    "            batsman_metrics[batsman]['balls_faced'] += 1\n",
    "            if runs >= 4:\n",
    "                batsman_metrics[batsman]['boundaries'] += 1\n",
    "\n",
    "        if event in dismissals:\n",
    "            batsman_metrics[batsman]['balls_faced'] += 1\n",
    "            batsman_metrics[batsman]['dismissal'] += 1\n",
    "            batsman_metrics[batsman]['scores'].append(batsman_metrics[batsman]['runs'])\n",
    "            batsman_metrics[batsman]['runs'] = 0  # Reset runs for the next innings\n",
    "\n",
    "        # Calculate metrics for bowlers\n",
    "        if event in runs_scored:\n",
    "            bowler_metrics[bowler]['runs_conceded'] += runs_scored[event]\n",
    "            bowler_metrics[bowler]['balls_bowled'] += 1\n",
    "\n",
    "        if event in dismissals:\n",
    "            bowler_metrics[bowler]['wickets'] += 1\n",
    "\n",
    "        if event in extras:\n",
    "            bowler_metrics[bowler]['extras'] += extras[event]\n",
    "            bowler_metrics[bowler]['runs_conceded'] += extras[event]\n",
    "\n",
    "        previous_bowling_team = bowling_team\n",
    "\n",
    "    # Ensure last innings runs are recorded\n",
    "    for batsman in batsman_metrics:\n",
    "        if batsman_metrics[batsman]['runs'] > 0:\n",
    "            batsman_metrics[batsman]['scores'].append(batsman_metrics[batsman]['runs'])\n",
    "\n",
    "    # Calculate additional metrics for batsmen\n",
    "    for batsman in batsman_metrics:\n",
    "        runs = sum(batsman_metrics[batsman]['scores'])\n",
    "        dismissal = batsman_metrics[batsman]['dismissal']\n",
    "        balls_faced = batsman_metrics[batsman]['balls_faced']\n",
    "\n",
    "        average = runs / dismissal if dismissal > 0 else runs\n",
    "        strike_rate = (runs / balls_faced * 100) if balls_faced > 0 else Decimal('0')\n",
    "        highest_score = max(batsman_metrics[batsman]['scores']) if batsman_metrics[batsman]['scores'] else runs\n",
    "\n",
    "        batsman_metrics[batsman]['average'] = average\n",
    "        batsman_metrics[batsman]['strike_rate'] = strike_rate\n",
    "        batsman_metrics[batsman]['highest_score'] = highest_score\n",
    "        batsman_metrics[batsman]['runs'] = runs\n",
    "        batsman_metrics[batsman]['innings'] = len(batsman_metrics[batsman]['scores'])\n",
    "\n",
    "    # Calculate additional metrics for bowlers\n",
    "    for bowler in bowler_metrics:\n",
    "        runs_conceded = bowler_metrics[bowler]['runs_conceded']\n",
    "        wickets = bowler_metrics[bowler]['wickets']\n",
    "        balls_bowled = bowler_metrics[bowler]['balls_bowled']\n",
    "\n",
    "        bowler_metrics[bowler]['average'] = runs_conceded / wickets if wickets > 0 else runs_conceded\n",
    "        bowler_metrics[bowler]['strike_rate'] = balls_bowled / wickets if wickets > 0 else balls_bowled\n",
    "        bowler_metrics[bowler]['economy_rate'] = (runs_conceded / (balls_bowled / 6)) if balls_bowled > 0 else 0\n",
    "\n",
    "    return batsman_metrics, bowler_metrics\n",
    "\n",
    "\n",
    "\n",
    "# Calculate metrics\n",
    "batsman_metrics, bowler_metrics = calculate_metrics(df)\n",
    "\n",
    "# Print results\n",
    "print(\"Batsman Metrics:\", batsman_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6723d35-821a-4fd5-9c17-19e76579d8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming the data is in a CSV file named 'cricket_data.csv'\n",
    "data = pd.read_excel(\"finaldesertation.xlsx\")\n",
    "\n",
    "# Initialize the list to store data frames\n",
    "matches_dataframes = []\n",
    "\n",
    "# Initialize variables to track the current match\n",
    "current_match = []\n",
    "current_inning = None\n",
    "\n",
    "# Iterate over the rows of the DataFrame\n",
    "for index, row in data.iterrows():\n",
    "    inning = row['innings']\n",
    "    \n",
    "    if current_inning is None:\n",
    "        # First row of the first match\n",
    "        current_inning = inning\n",
    "    \n",
    "    if inning == current_inning:\n",
    "        # Continue collecting data for the current inning\n",
    "        current_match.append(row)\n",
    "    else:\n",
    "        # Switch to the next inning\n",
    "        # Create a DataFrame for the completed match innings and store it\n",
    "        if current_match:\n",
    "            match_df = pd.DataFrame(current_match)\n",
    "            matches_dataframes.append(match_df)\n",
    "        \n",
    "        # Start a new match collection with the current row\n",
    "        current_match = [row]\n",
    "        current_inning = inning\n",
    "    \n",
    "# Add the last match data frame if there's any leftover data\n",
    "if current_match:\n",
    "    match_df = pd.DataFrame(current_match)\n",
    "    matches_dataframes.append(match_df)\n",
    "\n",
    "# Now matches_dataframes is a list of DataFrames, each containing data for one match\n",
    "\n",
    "\n",
    "# Updating innings count for each player in batsman_metrics\n",
    "for df in matches_dataframes:\n",
    "    for player in df['batsman'].unique():\n",
    "        if player in bowler_metrics:\n",
    "            bowler_metrics[player]['innings'] += 1\n",
    "\n",
    "# Output the updated batsman_metrics dictionary\n",
    "print(bowler_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648c02d1-e0c1-442a-ae5b-ebdc56a6d59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_excel(\"finaldesertation.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf6a1e9-d27c-4ba4-852a-98dd4ab75c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming the DataFrame is already loaded into df\n",
    "# Replace 'your_dataframe.csv' with the path to your actual data if needed\n",
    "# df = pd.read_csv('your_dataframe.csv')\n",
    "\n",
    "# Removing leading and trailing spaces from the 'teamscore' column\n",
    "df['teamscore'] = df['teamscore'].str.strip()\n",
    "\n",
    "# Creating a new DataFrame without null values in the specified columns\n",
    "columns_to_check = ['R', 'B', '4s', '6s', 'SR']\n",
    "df_non_null = df.dropna(subset=columns_to_check)\n",
    "\n",
    "# Displaying the new DataFrame\n",
    "print(df_non_null)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bcd0c7-b85f-4581-8625-76731ddd1670",
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = df_non_null.groupby('batsman').agg({\n",
    "    'R': 'mean',\n",
    "    'B': 'mean',\n",
    "    '4s': 'mean',\n",
    "    '6s': 'mean',\n",
    "    'SR': 'mean'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e5e2a8-5530-4acd-a894-acc8025d6567",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in averages.iterrows():\n",
    "    player_name = row['batsman']\n",
    "    if player_name in batsman_metrics:\n",
    "        batsman_metrics[player_name]['average_runs'] = row['R']  # Set runs average\n",
    "        batsman_metrics[player_name]['average_balls_faced'] = row['B']  # Set balls faced average\n",
    "        batsman_metrics[player_name]['average_boundaries'] = row['4s'] + row['6s']  # Set total boundaries\n",
    "        batsman_metrics[player_name]['average_strike_rate'] = row['SR']  # Set strike rate\n",
    "\n",
    "# Print the updated dictionary\n",
    "print(batsman_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a3ffb6-ef29-42a2-9411-c2d90c9c7e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = batsman_metrics\n",
    "df = pd.DataFrame.from_dict(data, orient='index')\n",
    "\n",
    "# Drop the 'scores' column and keep the rest\n",
    "df = df.drop(columns=['scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10973c90-09d0-4768-ba54-9baf31af9334",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Check for negative values or zeros and handle them (if necessary)\n",
    "# Here we replace zeros with NaNs before log transformation\n",
    "df = df.replace(0, np.nan)\n",
    "\n",
    "# Apply log transformation (use np.log1p to handle non-negative values)\n",
    "df_log_transformed = df.apply(lambda x: np.log1p(x))\n",
    "\n",
    "# Drop any rows with NaN values (resulting from the log transformation)\n",
    "df_log_transformed = df_log_transformed.dropna()\n",
    "\n",
    "# Standardize the log-transformed data\n",
    "scaler = StandardScaler()\n",
    "df_standardized = pd.DataFrame(scaler.fit_transform(df_log_transformed), columns=df_log_transformed.columns, index=df_log_transformed.index)\n",
    "\n",
    "# Plot histograms of standardized log-transformed data\n",
    "df_standardized.hist(figsize=(15, 10), bins=10, edgecolor='k')\n",
    "plt.suptitle('Histograms of Standardized Log-Transformed Features')\n",
    "plt.show()\n",
    "\n",
    "# Q-Q plots for standardized log-transformed data\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, column in enumerate(df_standardized.columns):\n",
    "    plt.subplot(3, 4, i + 1)\n",
    "    stats.probplot(df_standardized[column], dist=\"norm\", plot=plt)\n",
    "    plt.title(column)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4aa3ba-79e8-4a9b-95c8-793228d2b2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(batsman_metrics).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fe701d-2c83-4afd-9335-d784c098ab1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['innings','average'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d4d8cc-80b0-46a5-8d84-0da060408084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Sample Data (assuming batsman_metrics is a dictionary and defined)\n",
    "data = batsman_metrics\n",
    "df_bat1 = pd.DataFrame.from_dict(data, orient='index')\n",
    "df_bat1 = df_bat1.fillna(0)\n",
    "\n",
    "# Features to use for clustering\n",
    "features = ['runs', 'boundaries', 'dismissal', 'average', 'strike_rate', 'highest_score',\n",
    "            'balls_faced', 'innings', 'average_strike_rate', 'average_runs', \n",
    "            'average_balls_faced', 'average_boundaries']\n",
    "\n",
    "# Extract features\n",
    "X = df_bat1[features]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=4)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Plot the explained variance ratio as a bar graph\n",
    "plt.figure(figsize=(8, 5))\n",
    "num_components = len(pca.explained_variance_ratio_)\n",
    "plt.bar(range(1, num_components + 1), pca.explained_variance_ratio_, alpha=0.7, align='center')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('Explained Variance Ratio by Principal Component')\n",
    "plt.xticks(range(1, num_components + 1))\n",
    "plt.savefig('explained_variance_ratio.png')  # Save the image\n",
    "plt.show()\n",
    "\n",
    "# Plot the cumulative explained variance ratio\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, num_components + 1), cumulative_variance, marker='o', linestyle='--')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance Ratio')\n",
    "plt.title('Cumulative Explained Variance Ratio')\n",
    "plt.xticks(range(1, num_components + 1))\n",
    "plt.grid(True)\n",
    "plt.savefig('cumulative_explained_variance.png')  # Save the image\n",
    "plt.show()\n",
    "\n",
    "# Plot the contribution of each feature to each principal component\n",
    "plt.figure(figsize=(10, 7))\n",
    "num_components = pca.components_.shape[0]  # Number of principal components\n",
    "num_features = pca.components_.shape[1]    # Number of features\n",
    "\n",
    "# Ensure the number of row indices matches the number of principal components\n",
    "pc_labels = [f'PC{i+1}' for i in range(num_components)]\n",
    "\n",
    "# Create DataFrame for heatmap\n",
    "heatmap_df = pd.DataFrame(pca.components_, columns=features, index=pc_labels)\n",
    "\n",
    "# Plot heatmap\n",
    "sns.heatmap(heatmap_df, annot=True, cmap='coolwarm')\n",
    "plt.title('Feature Contribution to Principal Components')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Principal Component')\n",
    "plt.savefig('feature_contribution_heatmap.png')  # Save the image\n",
    "plt.show()\n",
    "\n",
    "# Step 1: Determine the optimal number of clusters using the Elbow method\n",
    "inertia = []\n",
    "K_range = range(1, 11)  # Trying 1 to 10 clusters\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans.fit(X_pca)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the Elbow method result\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(K_range, inertia, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.xticks(K_range)\n",
    "plt.grid(True)\n",
    "plt.savefig('elbow_method.png')  # Save the image\n",
    "plt.show()\n",
    "\n",
    "# Step 2: Compute Silhouette Scores for a range of cluster numbers\n",
    "silhouette_scores = []\n",
    "K_range = range(2, 11)  # Silhouette score requires at least 2 clusters\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    clusters = kmeans.fit_predict(X_pca)\n",
    "    silhouette_avg = silhouette_score(X_pca, clusters)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "\n",
    "# Plot the Silhouette Scores\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(K_range, silhouette_scores, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Score for Different Numbers of Clusters')\n",
    "plt.xticks(K_range)\n",
    "plt.grid(True)\n",
    "plt.savefig('silhouette_scores.png')  # Save the image\n",
    "plt.show()\n",
    "\n",
    "# Choose the optimal number of clusters based on silhouette score\n",
    "optimal_k = 2  # Replace this with the optimal number of clusters from the Silhouette Score plot\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=0)\n",
    "clusters = kmeans.fit_predict(X_pca)\n",
    "\n",
    "# Add the cluster number to the DataFrame\n",
    "df_bat1['Cluster'] = clusters\n",
    "\n",
    "# Display the DataFrame with the cluster column\n",
    "print(df_bat1.head())\n",
    "\n",
    "# 3D Scatter Plot with Renamed Clusters\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Define colors for the clusters\n",
    "colors = plt.cm.get_cmap('tab10', optimal_k)\n",
    "\n",
    "# Renaming the clusters\n",
    "cluster_labels = {0: 'Top Cluster Players', 1: 'Average Cluster Players'}\n",
    "\n",
    "for i in range(optimal_k):\n",
    "    ax.scatter(X_pca[clusters == i, 0], X_pca[clusters == i, 1], X_pca[clusters == i, 2],\n",
    "               color=colors(i), label=cluster_labels[i], alpha=0.6)\n",
    "\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "ax.set_title('Initial Clustering of Players')\n",
    "ax.legend()\n",
    "plt.savefig('initial_clustering_players.png')  # Save the image\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Plot Silhouette Scores for Each Cluster\n",
    "silhouette_avg = silhouette_score(X_pca, clusters)\n",
    "print(f'Silhouette Score for {optimal_k} clusters: {silhouette_avg:.2f}')\n",
    "\n",
    "# Compute silhouette scores for each sample\n",
    "sample_silhouette_values = silhouette_samples(X_pca, clusters)\n",
    "\n",
    "# Create a silhouette plot\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "y_lower = 10\n",
    "for i in range(optimal_k):\n",
    "    # Aggregate the silhouette scores for samples belonging to cluster i\n",
    "    cluster_silhouette_values = sample_silhouette_values[clusters == i]\n",
    "    cluster_silhouette_values.sort()\n",
    "    \n",
    "    # Compute the size of the cluster\n",
    "    size_cluster_i = cluster_silhouette_values.shape[0]\n",
    "    \n",
    "    # Plot the silhouette scores for cluster i\n",
    "    ax.fill_betweenx(np.arange(y_lower, y_lower + size_cluster_i),\n",
    "                     0, cluster_silhouette_values,\n",
    "                     facecolor=colors(i), alpha=0.7)\n",
    "    \n",
    "    # Add the cluster label\n",
    "    ax.text(-0.05, y_lower + 0.5 * size_cluster_i, cluster_labels[i],\n",
    "            color='black', va='center', ha='right', fontsize=12)\n",
    "    \n",
    "    # Update y_lower for the next cluster\n",
    "    y_lower += size_cluster_i\n",
    "\n",
    "ax.set_xlabel('Silhouette coefficient values')\n",
    "ax.set_ylabel('Cluster')\n",
    "ax.set_title('Silhouette Plot for the Clusters')\n",
    "plt.savefig('silhouette_plot.png')  # Save the image\n",
    "plt.show()\n",
    "\n",
    "# Pie Chart of Total Number of Points in Each Cluster with Custom Labels\n",
    "cluster_counts = df_bat1['Cluster'].value_counts()\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Custom labels for the pie chart\n",
    "pie_labels = [cluster_labels[i] for i in cluster_counts.index]\n",
    "\n",
    "plt.pie(cluster_counts, labels=pie_labels, autopct='%1.1f%%', colors=plt.cm.tab10(range(optimal_k)))\n",
    "plt.title('Distribution of Players in Initial Clustering')\n",
    "plt.savefig('cluster_distribution_pie_chart.png')  # Save the pie chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8494f614-b8a4-4c18-9c6d-75eb046b17a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'scores' column from the DataFrame\n",
    "df_bat1 = df_bat1.drop(columns=['scores'])\n",
    "\n",
    "# Ensure all columns are numeric\n",
    "df_bat1 = df_bat1.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Compute the mean of each feature by cluster\n",
    "cluster_means1 = df_bat1.groupby('Cluster').mean()\n",
    "\n",
    "# Display the cluster means\n",
    "print(cluster_means1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aa8543-0d0c-48e3-bd51-c571423267eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_1_df = df_bat1[df_bat1['Cluster'] == 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f406aa-855c-458b-85a8-706ef7d3feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_i = df_bat1[df_bat1['Cluster'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f09cda9-16d7-4c7a-b896-26dea41bd8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Sample data\n",
    "df_bat2 = cluster_1_df\n",
    "\n",
    "# Features to use for clustering\n",
    "features = ['runs', 'boundaries', 'dismissal', 'average', 'strike_rate', 'highest_score',\n",
    "            'balls_faced', 'innings', 'average_strike_rate', 'average_runs', \n",
    "            'average_balls_faced', 'average_boundaries']\n",
    "\n",
    "# Extract features\n",
    "X = df_bat2[features]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA with 2 components (for clustering)\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Plot the explained variance ratio and cumulative variance as a bar graph\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Explained variance for each component\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_explained_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "# Plotting\n",
    "plt.bar(range(1, 3), explained_variance_ratio, alpha=0.7, align='center', label='Individual explained variance')\n",
    "plt.step(range(1, 3), cumulative_explained_variance, where='mid', linestyle='--', color='red', label='Cumulative explained variance')\n",
    "\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('Explained and Cumulative Variance Ratio by Principal Component')\n",
    "plt.xticks(range(1, 3))\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.savefig('explained_variance_ratio_2_pca.png')  # Save the explained variance ratio graph\n",
    "plt.show()\n",
    "\n",
    "# Plot the contribution of each feature to each principal component\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(pd.DataFrame(pca.components_, columns=features, index=['PC1', 'PC2']),\n",
    "            annot=True, cmap='coolwarm')\n",
    "plt.title('Feature Contribution to Principal Components')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Principal Component')\n",
    "plt.savefig('feature_contribution_heatmap_2_pca.png')  # Save the heatmap\n",
    "plt.show()\n",
    "\n",
    "# Step 1: Determine the optimal number of clusters using the Elbow method\n",
    "inertia = []\n",
    "K_range = range(1, 11)  # Trying 1 to 10 clusters\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans.fit(X_pca)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the Elbow method result\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(K_range, inertia, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.xticks(K_range)\n",
    "plt.grid(True)\n",
    "plt.savefig('elbow_method_2_pca.png')  # Save the Elbow method plot\n",
    "plt.show()\n",
    "\n",
    "# Step 2: Compute Silhouette Scores for a range of cluster numbers\n",
    "silhouette_scores = []\n",
    "K_range = range(2, 11)  # Silhouette score requires at least 2 clusters\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    clusters = kmeans.fit_predict(X_pca)\n",
    "    silhouette_avg = silhouette_score(X_pca, clusters)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "\n",
    "# Plot the Silhouette Scores\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(K_range, silhouette_scores, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Score for Different Numbers of Clusters')\n",
    "plt.xticks(K_range)\n",
    "plt.grid(True)\n",
    "plt.savefig('silhouette_scores_2_pca.png')  # Save the Silhouette Score plot\n",
    "plt.show()\n",
    "\n",
    "# Choose the optimal number of clusters based on silhouette score\n",
    "optimal_k = 2  # Replace this with the optimal number of clusters from the Silhouette Score plot\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=0)\n",
    "clusters = kmeans.fit_predict(X_pca)\n",
    "\n",
    "# Add the cluster number to the DataFrame\n",
    "df_bat2['Cluster'] = clusters\n",
    "\n",
    "# Display the DataFrame with the cluster column\n",
    "print(df_bat2.head())\n",
    "\n",
    "# 2D Scatter Plot (for the two principal components)\n",
    "plt.figure(figsize=(10, 7))\n",
    "colors = plt.cm.get_cmap('tab10', optimal_k)\n",
    "\n",
    "cluster_labels = {0: 'Excellent players cluster', 1: 'Good players cluster'}\n",
    "\n",
    "for i in range(optimal_k):\n",
    "    plt.scatter(X_pca[clusters == i, 0], X_pca[clusters == i, 1],\n",
    "                color=colors(i), label=cluster_labels[i], alpha=0.6)\n",
    "\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('Final Clustering of Top Cluster Players')\n",
    "plt.legend()\n",
    "plt.savefig('final_clustering_of_top_cluster_players_2_pca.png')  # Save the image\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Plot Silhouette Scores for Each Cluster\n",
    "silhouette_avg = silhouette_score(X_pca, clusters)\n",
    "print(f'Silhouette Score for {optimal_k} clusters: {silhouette_avg:.2f}')\n",
    "\n",
    "# Compute silhouette scores for each sample\n",
    "sample_silhouette_values = silhouette_samples(X_pca, clusters)\n",
    "\n",
    "# Create a silhouette plot\n",
    "plt.figure(figsize=(10, 7))\n",
    "y_lower = 10\n",
    "for i in range(optimal_k):\n",
    "    # Aggregate the silhouette scores for samples belonging to cluster i\n",
    "    cluster_silhouette_values = sample_silhouette_values[clusters == i]\n",
    "    cluster_silhouette_values.sort()\n",
    "    \n",
    "    # Compute the size of the cluster\n",
    "    size_cluster_i = cluster_silhouette_values.shape[0]\n",
    "    \n",
    "    # Plot the silhouette scores for cluster i\n",
    "    plt.fill_betweenx(np.arange(y_lower, y_lower + size_cluster_i),\n",
    "                     0, cluster_silhouette_values,\n",
    "                     facecolor=colors(i), alpha=0.7)\n",
    "    \n",
    "    # Add the cluster label\n",
    "    plt.text(-0.05, y_lower + 0.5 * size_cluster_i, f'Cluster {i}',\n",
    "            color='black', va='center', ha='right', fontsize=12)\n",
    "    \n",
    "    # Update y_lower for the next cluster\n",
    "    y_lower += size_cluster_i\n",
    "\n",
    "plt.xlabel('Silhouette coefficient values')\n",
    "plt.ylabel('Cluster')\n",
    "plt.title('Silhouette Plot for the Clusters')\n",
    "plt.savefig('silhouette_plot_2_pca.png')  # Save the silhouette plot\n",
    "plt.show()\n",
    "\n",
    "# Pie Chart of Total Number of Points in Each Cluster with Custom Labels\n",
    "cluster_counts = df_bat2['Cluster'].value_counts()\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Custom labels for the pie chart\n",
    "pie_labels = [cluster_labels[i] for i in cluster_counts.index]\n",
    "\n",
    "plt.pie(cluster_counts, labels=pie_labels, autopct='%1.1f%%', colors=plt.cm.tab10(range(optimal_k)))\n",
    "plt.title('Distribution of Players in Final Clustering (Clustering of Top Players Cluster)')\n",
    "plt.savefig('cluster_distribution_pie_chart_2_pca.png')  # Save the pie chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cd88e4-3b3e-4660-b6ad-aa17ad2fb4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Load the image\n",
    "image_path = 'feature_contribution_heatmap_4_pca.png'  # or .jpg, .jpeg, etc.\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Display the image\n",
    "image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b0f0c2-0aff-457e-8e0d-2bdd3451f279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'scores' column from the DataFrame\n",
    "#df_bat2 = df_bat2.drop(columns=['scores'])\n",
    "\n",
    "# Compute the mean of each feature by cluster\n",
    "cluster_means = df_bat2.groupby('Cluster').mean()\n",
    "\n",
    "# Display the cluster means\n",
    "print(cluster_means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bf2eb6-4229-4f87-aad3-b6cca5d46966",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_ii = df_bat2[df_bat2['Cluster'] == 1]\n",
    "cluster_iii = df_bat2[df_bat2['Cluster'] == 0]\n",
    "cluster_ii['rating'] = 2\n",
    "cluster_iii['rating'] = 3\n",
    "cluster_i['rating'] = 1\n",
    "combined_df = pd.concat([cluster_ii, cluster_iii, cluster_i])\n",
    "\n",
    "# Reset index if needed (optiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bc74cb-a29e-4747-9add-9a5bfff63770",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming `combined_df` is your DataFrame\n",
    "\n",
    "# Identify numeric columns (excluding the target variable 'rating')\n",
    "numeric_columns = combined_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "numeric_columns = numeric_columns.drop('rating')  # Exclude the target variable if it's numeric\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the numeric columns and transform them\n",
    "combined_df[numeric_columns] = scaler.fit_transform(combined_df[numeric_columns])\n",
    "\n",
    "# Now `combined_df` has its numeric columns standardized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361ca7c4-8799-4deb-8b90-0221f730e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df=combined_df.dropna()\n",
    "# Assuming `combined_df` is your DataFrame\n",
    "y=combined_df[\"rating\"]\n",
    "x = combined_df[['runs', 'boundaries', 'dismissal', 'balls_faced', \n",
    "                 'innings', 'average', 'strike_rate', 'highest_score', \n",
    "                 'average_runs', 'average_balls_faced', \n",
    "                 'average_boundaries', 'average_strike_rate']]\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=500)\n",
    "model.fit(x, y)\n",
    "\n",
    "# Get feature importance\n",
    "importances = model.feature_importances_\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "x = combined_df[['runs', 'boundaries', 'dismissal', 'balls_faced', \n",
    "         'innings', 'average', 'strike_rate', 'highest_score', \n",
    "         'average_runs', 'average_balls_faced', \n",
    "         'average_boundaries', 'average_strike_rate']]\n",
    "y = combined_df[\"rating\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F-measure (F1 Score): {f1:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Coefficients\n",
    "features = [\n",
    "    'runs',\n",
    "    'boundaries',\n",
    "    'dismissal',\n",
    "    'balls_faced',\n",
    "    'innings',\n",
    "    'average',\n",
    "    'strike_rate',\n",
    "    'highest_score',\n",
    "    'average_runs',\n",
    "    'average_balls_faced',\n",
    "    'average_boundaries',\n",
    "    'average_strike_rate'\n",
    "]\n",
    "\n",
    "# Create a dictionary of features and their importances\n",
    "coefficients = dict(zip(features, importances))\n",
    "# Compute the weighted score\n",
    "combined_df['weighted_score'] = (\n",
    "    combined_df['runs'] * coefficients['runs'] +\n",
    "    combined_df['boundaries'] * coefficients['boundaries'] +\n",
    "    combined_df['dismissal'] * coefficients['dismissal'] +\n",
    "    combined_df['balls_faced'] * coefficients['balls_faced'] +\n",
    "    combined_df['innings'] * coefficients['innings'] +\n",
    "    combined_df['average'] * coefficients['average'] +\n",
    "    combined_df['strike_rate'] * coefficients['strike_rate'] +\n",
    "    combined_df['highest_score'] * coefficients['highest_score'] +\n",
    "    combined_df['average_runs'] * coefficients['average_runs'] +\n",
    "    combined_df['average_balls_faced'] * coefficients['average_balls_faced'] +\n",
    "    combined_df['average_boundaries'] * coefficients['average_boundaries'] +\n",
    "    combined_df['average_strike_rate'] * coefficients['average_strike_rate']\n",
    ")\n",
    "\n",
    "# Sort the DataFrame by 'weighted_score' from max to min\n",
    "sorted_df = combined_df.sort_values(by='weighted_score', ascending=False)\n",
    "\n",
    "# Print the sorted DataFrame\n",
    "print(sorted_df)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba25ec3d-0a83-4c8c-afbb-60d7e182ef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sorted_df\n",
    "\n",
    "min_score = df['weighted_score'].min()\n",
    "max_score = df['weighted_score'].max()\n",
    "\n",
    "df['normalized_score'] = (df['weighted_score'] - min_score) / (max_score - min_score)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Extract float values\n",
    "values = df['normalized_score']\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(range(1, len(values) + 1), values, color='blue', marker='o')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Scatter Plot of Batsman Ratings for Random Forest Model')\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the plot as an image file\n",
    "\n",
    "# Show the plot (optional, remove if not needed)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e8399b-633a-4ba8-8d94-2525c65d03e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming combined_df is your DataFrame\n",
    "\n",
    "# Define the feature matrix 'x' and target vector 'y'\n",
    "x = combined_df[['runs', 'boundaries', 'dismissal', 'balls_faced', \n",
    "                 'innings', 'average', 'strike_rate', 'highest_score', \n",
    "                 'average_runs', 'average_balls_faced', \n",
    "                 'average_boundaries', 'average_strike_rate']]\n",
    "y = combined_df[\"rating\"]\n",
    "\n",
    "# Apply Label Encoding to target labels to ensure they start from 0\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "model = xgb.XGBClassifier(n_estimators=500, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F-measure (F1 Score): {f1:.4f}\")\n",
    "\n",
    "# Get feature importances from the XGBoost model\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Create a dictionary of features and their importances\n",
    "coefficients = dict(zip(features, importances))\n",
    "\n",
    "# Compute the weighted score\n",
    "combined_df['weighted_score'] = (\n",
    "    combined_df['runs'] * coefficients['runs'] +\n",
    "    combined_df['boundaries'] * coefficients['boundaries'] +\n",
    "    combined_df['dismissal'] * coefficients['dismissal'] +\n",
    "    combined_df['balls_faced'] * coefficients['balls_faced'] +\n",
    "    combined_df['innings'] * coefficients['innings'] +\n",
    "    combined_df['average'] * coefficients['average'] +\n",
    "    combined_df['strike_rate'] * coefficients['strike_rate'] +\n",
    "    combined_df['highest_score'] * coefficients['highest_score'] +\n",
    "    combined_df['average_runs'] * coefficients['average_runs'] +\n",
    "    combined_df['average_balls_faced'] * coefficients['average_balls_faced'] +\n",
    "    combined_df['average_boundaries'] * coefficients['average_boundaries'] +\n",
    "    combined_df['average_strike_rate'] * coefficients['average_strike_rate']\n",
    ")\n",
    "\n",
    "# Sort the DataFrame by 'weighted_score' from max to min\n",
    "sorted_df = combined_df.sort_values(by='weighted_score', ascending=False)\n",
    "\n",
    "# Print the sorted DataFrame\n",
    "print(sorted_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d210d35-57f2-443a-9fc9-db80999bcf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "brf = sorted_df.index.tolist()\n",
    "\n",
    "# Print the list of player names\n",
    "print(brf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d9e226-881f-4564-a5d0-a4ce9bd3e727",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_lowb = df_bat1[df_bat1['Cluster'].isin([1])].index.tolist()\n",
    "cluster_low_mediumb = df_bat2[df_bat2['Cluster'].isin([1])].index.tolist()\n",
    "cluster_mediumb = df_bat2[df_bat2['Cluster'].isin([0])].index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93382f06-6de4-44ff-9b4f-a16a5963b7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pdf0=pd.read_excel(\"finaldesertation.xlsx\")\n",
    "pdf0 = pdf0.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d867995b-941b-4964-87ca-be8a8769a71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf0['batter_rating'] = 0\n",
    "\n",
    "# Assign ratings based on cluster membership\n",
    "pdf0.loc[pdf0['batsman'].isin(cluster_mediumb), 'batter_rating'] = 3\n",
    "#pdf.loc[pdf['bowler'].isin(cluster_high), 'bowler_rating'] = 5\n",
    "pdf0.loc[pdf0['batsman'].isin(cluster_low_mediumb), 'batter_rating'] = 2\n",
    "pdf0.loc[pdf0['batsman'].isin(cluster_lowb), 'batter_rating'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de70bde-c449-4a22-a39a-85281f7110f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_bat_h = pd.DataFrame.from_dict(batsman_metrics, orient='index')\n",
    "\n",
    "# Fill missing values with 0\n",
    "df_bat_h = df_bat_h.fillna(0)\n",
    "\n",
    "# Drop the 'scores' column if it exists\n",
    "if 'scores' in df_bat_h.columns:\n",
    "    df_bat_h = df_bat_h.drop(columns=['scores'])\n",
    "\n",
    "\n",
    "# Step 2: Normalize the data if necessary (using Min-Max scaling here)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(df_bat_h), columns=df_bat_h.columns, index=df_bat_h.index)\n",
    "\n",
    "# Step 3: Calculate the distance matrix\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "distance_matrix = pdist(df_normalized, metric='euclidean')\n",
    "\n",
    "# Step 4: Perform hierarchical clustering\n",
    "Z = linkage(distance_matrix, method='ward')\n",
    "\n",
    "# Step 5: Visualize the results using a dendrogram\n",
    "plt.figure(figsize=(10, 7))\n",
    "dendrogram(Z, labels=df_bat_h.index, leaf_rotation=90)\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('Batsman')\n",
    "plt.ylabel('Distance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f21f79-d943-4a34-9ca5-75a9a57d3ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "\n",
    "\n",
    "\n",
    "df_bat_h = pd.DataFrame.from_dict(batsman_metrics, orient='index')\n",
    "\n",
    "# Fill missing values with 0\n",
    "df_bat_h = df_bat_h.fillna(0)\n",
    "\n",
    "# Drop the 'scores' column if it exists\n",
    "if 'scores' in df_bat_h.columns:\n",
    "    df_bat_h = df_bat_h.drop(columns=['scores'])\n",
    "\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(df_bat_h), columns=df_bat_h.columns, index=df_bat_h.index)\n",
    "\n",
    "# Calculate the distance matrix\n",
    "distance_matrix = pdist(df_normalized, metric='euclidean')\n",
    "\n",
    "# Perform hierarchical clustering\n",
    "Z = linkage(distance_matrix, method='ward')\n",
    "\n",
    "# Define the threshold for forming clusters\n",
    "threshold = 2  # Adjust this threshold based on the dendrogram\n",
    "\n",
    "# Assign cluster labels to each player\n",
    "cluster_labels = fcluster(Z, threshold, criterion='distance')\n",
    "\n",
    "# Group and print the players by their cluster labels\n",
    "clusters = {}\n",
    "for player, cluster in zip(df_bat_h.index, cluster_labels):\n",
    "    if cluster not in clusters:\n",
    "        clusters[cluster] = []\n",
    "    clusters[cluster].append(player)\n",
    "\n",
    "for cluster, players in clusters.items():\n",
    "    print(f\"Cluster {cluster}: {', '.join(players)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ebf6db-39e5-4ed8-bcdc-572045d50f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster, players in clusters.items():\n",
    "    if 'N Workman' in players:\n",
    "        print(f\"Cluster {cluster}: {', '.join(players)}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dea0ecb-6452-4e48-bfbb-066357ee9ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowler_metrics = {k: v for k, v in bowler_metrics.items() if pd.notna(k)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc96c0a-d913-4094-b576-c01d0861d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, metrics in bowler_metrics.items():\n",
    "    if metrics['runs_conceded'] != 0:  # Avoid division by zero\n",
    "        metrics['runs_conceded'] = (1 / metrics['runs_conceded'])*100\n",
    "    else:\n",
    "        metrics['runs_conceded'] = 100\n",
    "\n",
    "# Display the updated dictionary\n",
    "print(bowler_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db157c02-74af-4fb1-9de1-d3cdaee68915",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(bowler_metrics).T\n",
    "\n",
    "# Convert all columns to numeric\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Replace zeros with NaNs to avoid issues with log transformation\n",
    "df = df.replace(0, np.nan)\n",
    "\n",
    "# Apply log transformation using np.log1p (log(1 + x))\n",
    "df_log_transformed = df.apply(lambda x: np.log1p(x))\n",
    "\n",
    "# Drop any rows with NaN values resulting from the log transformation\n",
    "df_log_transformed = df_log_transformed.dropna()\n",
    "\n",
    "# Standardize the log-transformed data\n",
    "scaler = StandardScaler()\n",
    "df_standardized = pd.DataFrame(scaler.fit_transform(df_log_transformed), columns=df_log_transformed.columns, index=df_log_transformed.index)\n",
    "\n",
    "# Plot histograms of standardized log-transformed data\n",
    "df_standardized.hist(figsize=(15, 10), bins=10, edgecolor='k')\n",
    "plt.suptitle('Histograms of Standardized Log-Transformed Features')\n",
    "plt.show()\n",
    "\n",
    "# Q-Q plots for standardized log-transformed data\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, column in enumerate(df_standardized.columns):\n",
    "    plt.subplot(3, 4, i + 1)\n",
    "    stats.probplot(df_standardized[column], dist=\"norm\", plot=plt)\n",
    "    plt.title(column)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f85184-9164-4c0d-88dd-f27d58846789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Sample Data (assuming bowler_metrics is a dictionary and defined)\n",
    "data = bowler_metrics\n",
    "df_bowl = pd.DataFrame.from_dict(data, orient='index')\n",
    "df_bowl = df_bowl.fillna(0)\n",
    "\n",
    "# Features to use for clustering\n",
    "features = ['runs_conceded', 'wickets', 'extras', 'balls_bowled', 'innings', 'average', 'strike_rate', 'economy_rate']\n",
    "\n",
    "# Extract features\n",
    "X = df_bowl[features]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=4)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Plot the explained variance ratio as a bar graph\n",
    "plt.figure(figsize=(8, 5))\n",
    "num_components = len(pca.explained_variance_ratio_)\n",
    "plt.bar(range(1, num_components + 1), pca.explained_variance_ratio_, alpha=0.7, align='center')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('Explained Variance Ratio by Principal Component')\n",
    "plt.xticks(range(1, num_components + 1))\n",
    "plt.show()\n",
    "\n",
    "# Plot the contribution of each feature to each principal component\n",
    "plt.figure(figsize=(10, 7))\n",
    "num_components = pca.components_.shape[0]  # Number of principal components\n",
    "num_features = pca.components_.shape[1]    # Number of features\n",
    "\n",
    "# Ensure the number of row indices matches the number of principal components\n",
    "pc_labels = [f'PC{i+1}' for i in range(num_components)]\n",
    "\n",
    "# Create DataFrame for heatmap\n",
    "heatmap_df = pd.DataFrame(pca.components_, columns=features, index=pc_labels)\n",
    "\n",
    "# Plot heatmap\n",
    "sns.heatmap(heatmap_df, annot=True, cmap='coolwarm')\n",
    "plt.title('Feature Contribution to Principal Components')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Principal Component')\n",
    "plt.show()\n",
    "\n",
    "# Step 1: Determine the optimal number of clusters using the Elbow method\n",
    "inertia = []\n",
    "K_range = range(1, 11)  # Trying 1 to 10 clusters\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans.fit(X_pca)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the Elbow method result\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(K_range, inertia, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.xticks(K_range)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Step 2: Compute Silhouette Scores for a range of cluster numbers\n",
    "silhouette_scores = []\n",
    "K_range = range(2, 11)  # Silhouette score requires at least 2 clusters\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    clusters = kmeans.fit_predict(X_pca)\n",
    "    silhouette_avg = silhouette_score(X_pca, clusters)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "\n",
    "# Plot the Silhouette Scores\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(K_range, silhouette_scores, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Score for Different Numbers of Clusters')\n",
    "plt.xticks(K_range)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Choose the optimal number of clusters based on silhouette score\n",
    "optimal_k = 3  # Replace this with the optimal number of clusters from the Silhouette Score plot\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=0)\n",
    "clusters = kmeans.fit_predict(X_pca)\n",
    "\n",
    "# Add the cluster number to the DataFrame\n",
    "df_bowl['Cluster'] = clusters\n",
    "\n",
    "# Display the DataFrame with the cluster column\n",
    "print(df_bowl.head())\n",
    "\n",
    "# 3D Scatter Plot\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Define colors for the clusters\n",
    "colors = plt.cm.get_cmap('tab10', optimal_k)\n",
    "\n",
    "# Define cluster names\n",
    "cluster_names = {0: 'Good Players', 1: 'Very Good Players', 2: 'Excellent Players'}\n",
    "\n",
    "for i in range(optimal_k):\n",
    "    ax.scatter(X_pca[clusters == i, 0], X_pca[clusters == i, 1], X_pca[clusters == i, 2],\n",
    "               color=colors(i), label=cluster_names[i], alpha=0.6)\n",
    "\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "ax.set_title('Clustering of the Players')\n",
    "ax.legend()\n",
    "\n",
    "# Save the 3D scatter plot\n",
    "plt.savefig('clustering_of_the_players.png', bbox_inches='tight')\n",
    "\n",
    "# Display the 3D scatter plot\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Plot Silhouette Scores for Each Cluster\n",
    "silhouette_avg = silhouette_score(X_pca, clusters)\n",
    "print(f'Silhouette Score for {optimal_k} clusters: {silhouette_avg:.2f}')\n",
    "\n",
    "# Compute silhouette scores for each sample\n",
    "sample_silhouette_values = silhouette_samples(X_pca, clusters)\n",
    "\n",
    "# Create a silhouette plot\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "y_lower = 10\n",
    "for i in range(optimal_k):\n",
    "    # Aggregate the silhouette scores for samples belonging to cluster i\n",
    "    cluster_silhouette_values = sample_silhouette_values[clusters == i]\n",
    "    cluster_silhouette_values.sort()\n",
    "    \n",
    "    # Compute the size of the cluster\n",
    "    size_cluster_i = cluster_silhouette_values.shape[0]\n",
    "    \n",
    "    # Plot the silhouette scores for cluster i\n",
    "    ax.fill_betweenx(np.arange(y_lower, y_lower + size_cluster_i),\n",
    "                     0, cluster_silhouette_values,\n",
    "                     facecolor=colors(i), alpha=0.7)\n",
    "    \n",
    "    # Add the cluster label\n",
    "    ax.text(-0.05, y_lower + 0.5 * size_cluster_i, f'Cluster {i}',\n",
    "            color='black', va='center', ha='right', fontsize=12)\n",
    "    \n",
    "    # Update y_lower for the next cluster\n",
    "    y_lower += size_cluster_i\n",
    "\n",
    "ax.set_xlabel('Silhouette coefficient values')\n",
    "ax.set_ylabel('Cluster')\n",
    "ax.set_title('Silhouette Plot for the Clusters')\n",
    "plt.show()\n",
    "\n",
    "# Pie Chart of Clusters\n",
    "cluster_counts = df_bowl['Cluster'].value_counts()\n",
    "cluster_labels = {0: 'Good Players', 1: 'Very Good Players', 2: 'Excellent Players'}\n",
    "labels = [cluster_labels[i] for i in cluster_counts.index]\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(cluster_counts, labels=labels, autopct='%1.1f%%', colors=plt.cm.Paired(range(optimal_k)))\n",
    "plt.title('Percentage of Players in Each Cluster')\n",
    "plt.savefig('percentage_of_players_in_each_cluster.png', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543fb807-07cf-4916-b407-11ffc7ba28ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(df_bowl[(df_bowl['Cluster'] == i) ].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd61c95-d4b2-4d20-8469-f280d31ffa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_low_medium = df_bowl[df_bowl['Cluster'].isin([2])].index.tolist()\n",
    "cluster_low = df_bowl[df_bowl['Cluster'].isin([0])].index.tolist()\n",
    "cluster_medium = df_bowl[df_bowl['Cluster'].isin([1])].index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3f4b9b-e861-4ab7-bbb8-12303edb38e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bowl.loc[df_bowl['Cluster'] == 1, 'rating'] = 3\n",
    "df_bowl.loc[df_bowl['Cluster'] == 0, 'rating'] = 2\n",
    "df_bowl.loc[df_bowl['Cluster'] == 2, 'rating'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409cadb1-18eb-4096-bc40-258e5aab6e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_bowl is your DataFrame and you want to classify based on the 'Cluster' column\n",
    "df_bowl = df_bowl.dropna()\n",
    "numeric_columns = df_bowl.select_dtypes(include=['float64', 'int64']).columns\n",
    "numeric_columns = numeric_columns.drop('rating')  # Exclude the target variable if it's numeric\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the numeric columns and transform them\n",
    "df_bowl[numeric_columns] = scaler.fit_transform(df_bowl[numeric_columns])\n",
    "# Define the feature matrix 'x' and target vector 'y'\n",
    "y = df_bowl[\"rating\"]\n",
    "x = df_bowl[['runs_conceded', 'wickets', 'extras', 'balls_bowled', \n",
    "             'innings', 'average', 'strike_rate', 'economy_rate']]\n",
    "\n",
    "# Initialize and train the RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F-measure (F1 Score): {f1:.4f}\")\n",
    "\n",
    "# Get feature importance\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Coefficients\n",
    "features = [\n",
    "    'runs_conceded',\n",
    "    'wickets',\n",
    "    'extras',\n",
    "    'balls_bowled',\n",
    "    'innings',\n",
    "    'average',\n",
    "    'strike_rate',\n",
    "    'economy_rate'\n",
    "]\n",
    "\n",
    "# Create a dictionary of features and their importances\n",
    "coefficients = dict(zip(features, importances))\n",
    "\n",
    "# Compute the weighted score\n",
    "df_bowl['weighted_score'] = (\n",
    "    df_bowl['runs_conceded'] * coefficients['runs_conceded'] +\n",
    "    df_bowl['wickets'] * coefficients['wickets'] +\n",
    "    df_bowl['extras'] * coefficients['extras'] +\n",
    "    df_bowl['balls_bowled'] * coefficients['balls_bowled'] +\n",
    "    df_bowl['innings'] * coefficients['innings'] +\n",
    "    df_bowl['average'] * coefficients['average'] +\n",
    "    df_bowl['strike_rate'] * coefficients['strike_rate'] +\n",
    "    df_bowl['economy_rate'] * coefficients['economy_rate']\n",
    ")\n",
    "\n",
    "# Sort the DataFrame by 'weighted_score' from max to min\n",
    "sorted_df = df_bowl.sort_values(by='weighted_score', ascending=False)\n",
    "\n",
    "# Print the sorted DataFrame\n",
    "print(sorted_df)\n",
    "\n",
    "# Display the top 10 records\n",
    "print(sorted_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7103687-4a82-4a0f-8b25-08e061495311",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sorted_df\n",
    "\n",
    "min_score = df['weighted_score'].min()\n",
    "max_score = df['weighted_score'].max()\n",
    "\n",
    "df['normalized_score'] = (df['weighted_score'] - min_score) / (max_score - min_score)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Extract float values\n",
    "values = df['normalized_score']\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(range(1, len(values) + 1), values, color='blue', marker='o')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Scatter Plot of Bowler Ratings for Random Forest Model')\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the plot as an image file\n",
    "\n",
    "# Show the plot (optional, remove if not needed)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0810428-27be-42d0-9a75-7bd446f8bfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_bowl is your DataFrame and you want to classify based on the 'Cluster' column\n",
    "df_bowl = df_bowl.dropna()\n",
    "\n",
    "# Define the feature matrix 'x' and target vector 'y'\n",
    "y = df_bowl[\"rating\"]\n",
    "x = df_bowl[['runs_conceded', 'wickets', 'extras', 'balls_bowled', \n",
    "             'innings', 'average', 'strike_rate', 'economy_rate']]\n",
    "\n",
    "# Initialize and train the RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F-measure (F1 Score): {f1:.4f}\")\n",
    "\n",
    "# Get feature importance\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Coefficients\n",
    "features = [\n",
    "    'runs_conceded',\n",
    "    'wickets',\n",
    "    'extras',\n",
    "    'balls_bowled',\n",
    "    'innings',\n",
    "    'average',\n",
    "    'strike_rate',\n",
    "    'economy_rate'\n",
    "]\n",
    "\n",
    "# Create a dictionary of features and their importances\n",
    "coefficients = dict(zip(features, importances))\n",
    "\n",
    "# Compute the weighted score\n",
    "df_bowl['weighted_score'] = (\n",
    "    df_bowl['runs_conceded'] * coefficients['runs_conceded'] +\n",
    "    df_bowl['wickets'] * coefficients['wickets'] +\n",
    "    df_bowl['extras'] * coefficients['extras'] +\n",
    "    df_bowl['balls_bowled'] * coefficients['balls_bowled'] +\n",
    "    df_bowl['innings'] * coefficients['innings'] +\n",
    "    df_bowl['average'] * coefficients['average'] +\n",
    "    df_bowl['strike_rate'] * coefficients['strike_rate'] +\n",
    "    df_bowl['economy_rate'] * coefficients['economy_rate']\n",
    ")\n",
    "\n",
    "# Sort the DataFrame by 'weighted_score' from max to min\n",
    "sorted_df = df_bowl.sort_values(by='weighted_score', ascending=False)\n",
    "\n",
    "# Print the sorted DataFrame\n",
    "print(sorted_df)\n",
    "\n",
    "# Display the top 10 records\n",
    "print(sorted_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1606d53c-490b-47cf-a0dc-96a53d5c1876",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sorted_df\n",
    "\n",
    "min_score = df['weighted_score'].min()\n",
    "max_score = df['weighted_score'].max()\n",
    "\n",
    "df['normalized_score'] = (df['weighted_score'] - min_score) / (max_score - min_score)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Extract float values\n",
    "values = df['normalized_score']\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(range(len(values)), values, color='blue', marker='o')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Scatter Plot of Values')\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the plot as an image file\n",
    "plt.savefig('scatter_plot.png')\n",
    "\n",
    "# Show the plot (optional, remove if not needed)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c3ab65-dd2e-4204-8807-376fff0a2571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_bowler_h = pd.DataFrame.from_dict(bowler_metrics, orient='index')\n",
    "\n",
    "# Fill missing values with 0\n",
    "df_bowler_h = df_bowler_h.fillna(0)\n",
    "\n",
    "# Drop the 'scores' column if it exists\n",
    "if 'scores' in df_bowler_h.columns:\n",
    "    df_bowler_h = df_bowler_h.drop(columns=['scores'])\n",
    "\n",
    "\n",
    "# Step 2: Normalize the data if necessary (using Min-Max scaling here)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(df_bowler_h), columns=df_bowler_h.columns, index=df_bowler_h.index)\n",
    "\n",
    "# Step 3: Calculate the distance matrix\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "distance_matrix = pdist(df_normalized, metric='euclidean')\n",
    "\n",
    "# Step 4: Perform hierarchical clustering\n",
    "Z = linkage(distance_matrix, method='ward')\n",
    "\n",
    "# Step 5: Visualize the results using a dendrogram\n",
    "plt.figure(figsize=(10, 7))\n",
    "dendrogram(Z, labels=df_bowler_h.index, leaf_rotation=90)\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('Batsman')\n",
    "plt.ylabel('Distance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903e499f-c5e8-4a2a-9877-91645f27f6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "\n",
    "\n",
    "\n",
    "df_bowler_h = pd.DataFrame.from_dict(bowler_metrics, orient='index')\n",
    "\n",
    "# Fill missing values with 0\n",
    "df_bowler_h = df_bowler_h.fillna(0)\n",
    "\n",
    "# Drop the 'scores' column if it exists\n",
    "if 'scores' in df_bowler_h.columns:\n",
    "    df_bowler_h = df_bowler_h.drop(columns=['scores'])\n",
    "\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(df_bowler_h), columns=df_bowler_h.columns, index=df_bowler_h.index)\n",
    "\n",
    "# Calculate the distance matrix\n",
    "distance_matrix = pdist(df_normalized, metric='euclidean')\n",
    "\n",
    "# Perform hierarchical clustering\n",
    "Z = linkage(distance_matrix, method='ward')\n",
    "\n",
    "# Define the threshold for forming clusters\n",
    "threshold = 2  # Adjust this threshold based on the dendrogram\n",
    "\n",
    "# Assign cluster labels to each player\n",
    "cluster_labels = fcluster(Z, threshold, criterion='distance')\n",
    "\n",
    "# Group and print the players by their cluster labels\n",
    "clusters = {}\n",
    "for player, cluster in zip(df_bowler_h.index, cluster_labels):\n",
    "    if cluster not in clusters:\n",
    "        clusters[cluster] = []\n",
    "    clusters[cluster].append(player)\n",
    "\n",
    "for cluster, players in clusters.items():\n",
    "    print(f\"Cluster {cluster}: {', '.join(players)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd07781a-8bd6-4b20-b893-af4e74078791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pdf=pd.read_excel(\"finaldesertation.xlsx\")\n",
    "pdf = pdf.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66847735-3bae-4fde-851f-20855d943e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf['bowler_rating'] = 0\n",
    "\n",
    "# Assign ratings based on cluster membership\n",
    "pdf.loc[pdf['bowler'].isin(cluster_medium), 'bowler_rating'] = 3\n",
    "#pdf.loc[pdf['bowler'].isin(cluster_high), 'bowler_rating'] = 5\n",
    "pdf.loc[pdf['bowler'].isin(cluster_low_medium), 'bowler_rating'] = 2\n",
    "pdf.loc[pdf['bowler'].isin(cluster_low), 'bowler_rating'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915f27fa-426d-46a9-b3c3-1d1d0a5c9473",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = pdf[pdf['bowler_rating'] == 0]\n",
    "\n",
    "filtered_df['bowler'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8470c9a-fba2-41a4-bef1-782bc639a0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bat_rating3=pdf[pdf['bowler_rating']==3]\n",
    "bat_rating2=pdf[pdf['bowler_rating']==2]\n",
    "bat_rating1=pdf[pdf['bowler_rating']==1]\n",
    "bat_rating0 = pdf[pdf['bowler'].isna()]\n",
    "import pandas as pd\n",
    "from decimal import Decimal\n",
    "\n",
    "# Function to process events and calculate metrics for batsmen and bowlers\n",
    "def calculate_metrics(df):\n",
    "    # Initialize dictionaries to hold metrics\n",
    "    batsman_metrics = {}\n",
    "    bowler_metrics = {}\n",
    "\n",
    "    # Define scoring rules\n",
    "    runs_scored = {\n",
    "        '0 runs': 0, '1 run': 1, '2 runs': 2, '3 runs': 3, '4 runs': 4, '6 runs': 6,\n",
    "        '1 run \\n 1 no ball': 1, '2 runs \\n 1 no ball': 2, '3 runs \\n 1 no ball': 3, \n",
    "        '4 runs \\n 1 no ball': 4, '6 runs \\n 1 no ball': 6, '5 runs': 5,\n",
    "        '1 run \\n 2 no balls': 1, '4 runs \\n 2 no balls': 4,\n",
    "    }\n",
    "    \n",
    "    dismissals = [\n",
    "        'Wicket!', 'Wicket! \\n 2 wides', 'Wicket! \\n 1 run \\n 1 no ball', \n",
    "        'Wicket! \\n 1 run', 'Wicket! \\n 2 runs', 'Wicket! \\n 1 bye', \n",
    "        'Wicket! \\n 1 no ball', 'Wicket! \\n 1 wide', 'Wicket! \\n 1 leg bye'\n",
    "    ]\n",
    "\n",
    "    extras = {\n",
    "        '1 wide': 1, '2 wides': 2, '3 wides': 3, '4 wides': 4, '5 wides': 5, '6 wides': 6,\n",
    "        '1 no ball': 1, '2 no balls': 2, '1 bye': 1, '2 byes': 2, '3 byes': 3, \n",
    "        '4 byes': 4, '5 byes': 5, '1 leg bye': 1, '2 leg byes': 2, '3 leg byes': 3, \n",
    "        '4 leg byes': 4, '2 1nb + byes': 2, '3 1nb + byes': 3, '6 1nb + byes': 6, \n",
    "        '5 1nb + byes': 5, '4 1nb + byes': 4, '2 1nb + leg byes': 2\n",
    "    }\n",
    "\n",
    "    previous_bowling_team = None\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        event = row['Event']\n",
    "        bowler = row['bowler']\n",
    "        batsman = row['batsman']\n",
    "        bowling_team = row['bowling team']\n",
    "        over = int(row['Over'][5:])\n",
    "\n",
    "        # Initialize batsman and bowler if not already in the dictionary\n",
    "        if batsman not in batsman_metrics:\n",
    "            batsman_metrics[batsman] = {'runs': 0, 'boundaries': 0, 'dismissal': 0, 'balls_faced': 0, 'innings': 0, 'scores': []}\n",
    "        \n",
    "\n",
    "        # Handle change in batting team (new match or new innings)\n",
    "        if previous_bowling_team is not None and previous_bowling_team != bowling_team:\n",
    "            # Save the scores for all batsmen\n",
    "            for b in batsman_metrics:\n",
    "                if batsman_metrics[b]['runs'] > 0:\n",
    "                    batsman_metrics[b]['scores'].append(batsman_metrics[b]['runs'])\n",
    "                    batsman_metrics[b]['runs'] = 0\n",
    "\n",
    "        # Calculate metrics for batsmen\n",
    "        if event in runs_scored:\n",
    "            runs = runs_scored[event]\n",
    "            batsman_metrics[batsman]['runs'] += runs\n",
    "            batsman_metrics[batsman]['balls_faced'] += 1\n",
    "            if runs >= 4:\n",
    "                batsman_metrics[batsman]['boundaries'] += 1\n",
    "\n",
    "        if event in dismissals:\n",
    "            batsman_metrics[batsman]['balls_faced'] += 1\n",
    "            batsman_metrics[batsman]['dismissal'] += 1\n",
    "            batsman_metrics[batsman]['scores'].append(batsman_metrics[batsman]['runs'])\n",
    "            batsman_metrics[batsman]['runs'] = 0  # Reset runs for the next innings\n",
    "\n",
    "        \n",
    "\n",
    "        previous_bowling_team = bowling_team\n",
    "\n",
    "    # Ensure last innings runs are recorded\n",
    "    for batsman in batsman_metrics:\n",
    "        if batsman_metrics[batsman]['runs'] > 0:\n",
    "            batsman_metrics[batsman]['scores'].append(batsman_metrics[batsman]['runs'])\n",
    "\n",
    "    # Calculate additional metrics for batsmen\n",
    "    for batsman in batsman_metrics:\n",
    "        runs = sum(batsman_metrics[batsman]['scores'])\n",
    "        dismissal = batsman_metrics[batsman]['dismissal']\n",
    "        balls_faced = batsman_metrics[batsman]['balls_faced']\n",
    "\n",
    "        average = runs / dismissal if dismissal > 0 else runs\n",
    "        strike_rate = (runs / balls_faced * 100) if balls_faced > 0 else Decimal('0')\n",
    "        highest_score = max(batsman_metrics[batsman]['scores']) if batsman_metrics[batsman]['scores'] else runs\n",
    "\n",
    "        batsman_metrics[batsman]['average'] = average\n",
    "        batsman_metrics[batsman]['strike_rate'] = strike_rate\n",
    "        batsman_metrics[batsman]['highest_score'] = highest_score\n",
    "        batsman_metrics[batsman]['runs'] = runs\n",
    "        batsman_metrics[batsman]['innings'] = len(batsman_metrics[batsman]['scores'])\n",
    "\n",
    "    \n",
    "\n",
    "    return batsman_metrics\n",
    "\n",
    "\n",
    "\n",
    "# Calculate metrics\n",
    "rat3 = calculate_metrics(bat_rating3)\n",
    "rat2 = calculate_metrics(bat_rating2)\n",
    "rat1 = calculate_metrics(bat_rating1)\n",
    "rat0 = calculate_metrics(bat_rating0)\n",
    "ran = calculate_metrics(pdf)\n",
    "# Print results\n",
    "print(\"Batsman Metrics:\", rat3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc7127e-ec90-4b9c-9c23-ec9561754a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "rat3 = {k: v for k, v in rat3.items() if not (isinstance(k, float) and math.isnan(k))}\n",
    "rat2 = {k: v for k, v in rat2.items() if not (isinstance(k, float) and math.isnan(k))}\n",
    "rat1 = {k: v for k, v in rat1.items() if not (isinstance(k, float) and math.isnan(k))}\n",
    "rat0 = {k: v for k, v in rat0.items() if not (isinstance(k, float) and math.isnan(k))}\n",
    "ran = {k: v for k, v in ran.items() if not (isinstance(k, float) and math.isnan(k))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cf18dd-f390-442a-a37e-cc22569bf190",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "\n",
    "# Example data (assuming decimal.Decimal values might be present)\n",
    "data = rat3\n",
    "\n",
    "# Convert Decimal to float for normalization\n",
    "def convert_to_float(value):\n",
    "    if isinstance(value, Decimal):\n",
    "        return float(value)\n",
    "    return value\n",
    "\n",
    "# Prepare for normalization\n",
    "metrics = ['runs', 'boundaries', 'dismissal', 'balls_faced', 'innings', 'average', 'strike_rate', 'highest_score']\n",
    "values = {metric: [] for metric in metrics}\n",
    "\n",
    "# Collect values for each metric\n",
    "for player, stats in data.items():\n",
    "    for metric in metrics:\n",
    "        values[metric].append(convert_to_float(stats.get(metric, Decimal('0'))))\n",
    "\n",
    "# Normalize values using Min-Max Scaling\n",
    "normalized_data3 = {}\n",
    "\n",
    "for player, stats in data.items():\n",
    "    normalized_data3[player] = {}\n",
    "    for metric in metrics:\n",
    "        min_val = min(values[metric])\n",
    "        max_val = max(values[metric])\n",
    "        value = convert_to_float(stats.get(metric, Decimal('0')))\n",
    "        \n",
    "        if max_val > min_val:  # Avoid division by zero\n",
    "            normalized_data3[player][metric] = (value - min_val) / (max_val - min_val)\n",
    "        else:\n",
    "            normalized_data3[player][metric] = 0  # In case all values are the same\n",
    "\n",
    "# Optionally include scores separately (if normalization needed, apply similarly)\n",
    "for player in normalized_data3:\n",
    "    normalized_data3[player]['scores'] = data[player]['scores']\n",
    "\n",
    "print(normalized_data3)\n",
    "from decimal import Decimal\n",
    "\n",
    "# Example data (assuming decimal.Decimal values might be present)\n",
    "data = rat2\n",
    "\n",
    "# Convert Decimal to float for normalization\n",
    "def convert_to_float(value):\n",
    "    if isinstance(value, Decimal):\n",
    "        return float(value)\n",
    "    return value\n",
    "\n",
    "# Prepare for normalization\n",
    "metrics = ['runs', 'boundaries', 'dismissal', 'balls_faced', 'innings', 'average', 'strike_rate', 'highest_score']\n",
    "values = {metric: [] for metric in metrics}\n",
    "\n",
    "# Collect values for each metric\n",
    "for player, stats in data.items():\n",
    "    for metric in metrics:\n",
    "        values[metric].append(convert_to_float(stats.get(metric, Decimal('0'))))\n",
    "\n",
    "# Normalize values using Min-Max Scaling\n",
    "normalized_data2 = {}\n",
    "\n",
    "for player, stats in data.items():\n",
    "    normalized_data2[player] = {}\n",
    "    for metric in metrics:\n",
    "        min_val = min(values[metric])\n",
    "        max_val = max(values[metric])\n",
    "        value = convert_to_float(stats.get(metric, Decimal('0')))\n",
    "        \n",
    "        if max_val > min_val:  # Avoid division by zero\n",
    "            normalized_data2[player][metric] = (value - min_val) / (max_val - min_val)\n",
    "        else:\n",
    "            normalized_data2[player][metric] = 0  # In case all values are the same\n",
    "\n",
    "# Optionally include scores separately (if normalization needed, apply similarly)\n",
    "for player in normalized_data2:\n",
    "    normalized_data2[player]['scores'] = data[player]['scores']\n",
    "\n",
    "print(normalized_data2)\n",
    "from decimal import Decimal\n",
    "\n",
    "# Example data (assuming decimal.Decimal values might be present)\n",
    "data = rat1\n",
    "\n",
    "# Convert Decimal to float for normalization\n",
    "def convert_to_float(value):\n",
    "    if isinstance(value, Decimal):\n",
    "        return float(value)\n",
    "    return value\n",
    "\n",
    "# Prepare for normalization\n",
    "metrics = ['runs', 'boundaries', 'dismissal', 'balls_faced', 'innings', 'average', 'strike_rate', 'highest_score']\n",
    "values = {metric: [] for metric in metrics}\n",
    "\n",
    "# Collect values for each metric\n",
    "for player, stats in data.items():\n",
    "    for metric in metrics:\n",
    "        values[metric].append(convert_to_float(stats.get(metric, Decimal('0'))))\n",
    "\n",
    "# Normalize values using Min-Max Scaling\n",
    "normalized_data1 = {}\n",
    "\n",
    "for player, stats in data.items():\n",
    "    normalized_data1[player] = {}\n",
    "    for metric in metrics:\n",
    "        min_val = min(values[metric])\n",
    "        max_val = max(values[metric])\n",
    "        value = convert_to_float(stats.get(metric, Decimal('0')))\n",
    "        \n",
    "        if max_val > min_val:  # Avoid division by zero\n",
    "            normalized_data1[player][metric] = (value - min_val) / (max_val - min_val)\n",
    "        else:\n",
    "            normalized_data1[player][metric] = 0  # In case all values are the same\n",
    "\n",
    "# Optionally include scores separately (if normalization needed, apply similarly)\n",
    "for player in normalized_data1:\n",
    "    normalized_data1[player]['scores'] = data[player]['scores']\n",
    "\n",
    "print(normalized_data1)\n",
    "from decimal import Decimal\n",
    "\n",
    "# Example data (assuming decimal.Decimal values might be present)\n",
    "data = rat0\n",
    "\n",
    "# Convert Decimal to float for normalization\n",
    "def convert_to_float(value):\n",
    "    if isinstance(value, Decimal):\n",
    "        return float(value)\n",
    "    return value\n",
    "\n",
    "# Prepare for normalization\n",
    "metrics = ['runs', 'boundaries', 'dismissal', 'balls_faced', 'innings', 'average', 'strike_rate', 'highest_score']\n",
    "values = {metric: [] for metric in metrics}\n",
    "\n",
    "# Collect values for each metric\n",
    "for player, stats in data.items():\n",
    "    for metric in metrics:\n",
    "        values[metric].append(convert_to_float(stats.get(metric, Decimal('0'))))\n",
    "\n",
    "# Normalize values using Min-Max Scaling\n",
    "normalized_data0 = {}\n",
    "\n",
    "for player, stats in data.items():\n",
    "    normalized_data0[player] = {}\n",
    "    for metric in metrics:\n",
    "        min_val = min(values[metric])\n",
    "        max_val = max(values[metric])\n",
    "        value = convert_to_float(stats.get(metric, Decimal('0')))\n",
    "        \n",
    "        if max_val > min_val:  # Avoid division by zero\n",
    "            normalized_data0[player][metric] = (value - min_val) / (max_val - min_val)\n",
    "        else:\n",
    "            normalized_data0[player][metric] = 0  # In case all values are the same\n",
    "\n",
    "# Optionally include scores separately (if normalization needed, apply similarly)\n",
    "for player in normalized_data0:\n",
    "    normalized_data0[player]['scores'] = data[player]['scores']\n",
    "\n",
    "print(normalized_data0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490e7f0e-48cd-47f8-ac41-67cf4a6a7ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "players=[]\n",
    "for i in ran.keys():\n",
    "    players.append(i)\n",
    "key_final={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb71d68-dae9-43c9-94bc-c8955676ceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in players:\n",
    "    key_final[i]={}\n",
    "    if i in rat0:\n",
    "        key_final[i][0]=normalized_data0[i]\n",
    "    if i in rat1:\n",
    "        key_final[i][1]=normalized_data1[i]\n",
    "    if i in rat2:\n",
    "        key_final[i][2]=normalized_data2[i]\n",
    "    if i in rat3:\n",
    "        key_final[i][3]=normalized_data3[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0ed1fd-b26c-492a-99f7-45e2c983e1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for player_name in key_final.keys():\n",
    "    key_final[player_name]['average_runs'] = 0# Initialize runs average to 0\n",
    "    key_final[player_name]['average_balls_faced'] = 0# Initialize balls faced average to 0\n",
    "    key_final[player_name]['average_boundaries'] = 0# Initialize total boundaries to 0\n",
    "    key_final[player_name]['average_strike_rate'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f9c908-d9a7-4269-b220-db08b7223862",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_normalize = ['R', 'B', '4s', '6s', 'SR']\n",
    "df = averages\n",
    "\n",
    "# Apply Min-Max Scaling\n",
    "for column in columns_to_normalize:\n",
    "    min_val = df[column].min()\n",
    "    max_val = df[column].max()\n",
    "    df[column + '_norm'] = (df[column] - min_val) / (max_val - min_val)\n",
    "\n",
    "# Drop the original columns if you only need the normalized data\n",
    "df_normalized_a = df.drop(columns=columns_to_normalize)\n",
    "\n",
    "print(df_normalized_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc88f57-7d40-4735-840d-9ce717598fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_normalized_a.iterrows():\n",
    "    player_name = row['batsman']\n",
    "    if player_name in key_final:\n",
    "        key_final[player_name]['average_runs'] = row['R_norm']  # Set runs average\n",
    "        key_final[player_name]['average_balls_faced'] = row['B_norm']  # Set balls faced average\n",
    "        key_final[player_name]['average_boundaries'] = row['4s_norm'] + row['6s_norm']  # Set total boundaries\n",
    "        key_final[player_name]['average_strike_rate'] = row['SR_norm']  # Set strike rate\n",
    "\n",
    "# Print the updated dictionary\n",
    "print(key_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655fca73-79ad-4ace-8571-88c8894828cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_stats = {\n",
    "    'runs': 0.0,\n",
    "    'boundaries': 0.0,\n",
    "    'dismissal': 0.0,\n",
    "    'balls_faced': 0.0,\n",
    "    'innings': 0,\n",
    "    'average': 0.0,\n",
    "    'strike_rate': 0.0,\n",
    "    'highest_score': 0.0,\n",
    "    'scores':0.0\n",
    "}\n",
    "\n",
    "# Extract statistics with default values\n",
    "stats = []\n",
    "for player, details in key_final.items():\n",
    "    for key in [0, 1, 2, 3]:\n",
    "        stats_dict = details.get(key, default_stats.copy())\n",
    "        stats_dict['player'] = player\n",
    "        stats_dict['key'] = key\n",
    "        stats.append(stats_dict)\n",
    "\n",
    "# Sorting by the highest value among the numeric statistics\n",
    "sorted_stats = sorted(stats, key=lambda x: max(v for v in x.values() if isinstance(v, (int, float))), reverse=True)\n",
    "\n",
    "# Preparing the ordered dictionary\n",
    "ordered_data = {}\n",
    "for stat in sorted_stats:\n",
    "    player = stat.pop('player')\n",
    "    key = stat.pop('key')\n",
    "    if player not in ordered_data:\n",
    "        ordered_data[player] = {}\n",
    "    ordered_data[player][key] = stat\n",
    "\n",
    "ordered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dd845e-994f-42a3-b07e-c7ea50e9bf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import decimal\n",
    "\n",
    "def ahp(matrix_dict):\n",
    "    def calculate_priority_vector_and_consistency(matrix):\n",
    "        n = matrix.shape[0]\n",
    "        \n",
    "        # Normalize the matrix\n",
    "        column_sums = np.sum(matrix, axis=0)\n",
    "        normalized_matrix = matrix / column_sums\n",
    "        \n",
    "        # Calculate the Priority Vector\n",
    "        priority_vector = np.mean(normalized_matrix, axis=1)\n",
    "        \n",
    "        # Compute the Weighted Sum Vector using the original matrix\n",
    "        weighted_sum_vector = np.dot(matrix, priority_vector)\n",
    "        \n",
    "        # Compute Lambda Max\n",
    "        lambda_max = np.mean(weighted_sum_vector / priority_vector)\n",
    "        \n",
    "        # Calculate Consistency Index (CI)\n",
    "        CI = (lambda_max - n) / (n - 1)\n",
    "        \n",
    "        # Random Index (RI) for consistency ratio calculation\n",
    "        RI_dict = {1: 0, 2: 0, 3: 0.58, 4: 0.90, 5: 1.12, 6: 1.24, 7: 1.32, 8: 1.41, 9: 1.45, 10: 1.49}\n",
    "        RI = RI_dict.get(n, 1.49)\n",
    "        \n",
    "        # Calculate Consistency Ratio (CR)\n",
    "        CR = CI / RI if RI != 0 else 0\n",
    "        \n",
    "        return priority_vector, CI, CR\n",
    "\n",
    "    results = {}\n",
    "    for key, matrix in matrix_dict.items():\n",
    "        priority_vector, CI, CR = calculate_priority_vector_and_consistency(matrix)\n",
    "        if CR > 0.1:\n",
    "            raise ValueError(f\"The consistency ratio for {key} is too high: {CR:.2f}\")\n",
    "        results[key] = {'priority_vector': priority_vector, 'CI': CI, 'CR': CR}\n",
    "    \n",
    "    return results\n",
    "\n",
    "def calculate_weighted_score(weights, metrics):\n",
    "    # Convert metrics values to float if they are decimal.Decimal\n",
    "    metrics = {k: float(v) if isinstance(v, decimal.Decimal) else v for k, v in metrics.items()}\n",
    "    \n",
    "    return sum(weights.get(key, 0) * metrics.get(key, 0) for key in weights)\n",
    "\n",
    "def calculate_batsman_rating(bowler_rating, scoring_metrics, consistency_metrics, efficiency_metrics, results):\n",
    "    # Calculate weighted scores for each level\n",
    "    scoring_ability_score = calculate_weighted_score(\n",
    "        dict(zip(['runs', 'boundaries', 'highest_score'], results['Scoring Ability']['priority_vector'])),\n",
    "        scoring_metrics\n",
    "    )\n",
    "    \n",
    "    consistency_score = calculate_weighted_score(\n",
    "        dict(zip(['average', 'average_runs', 'dismissals', 'innings'], results['Consistency']['priority_vector'])),\n",
    "        consistency_metrics\n",
    "    )\n",
    "    \n",
    "    efficiency_score = calculate_weighted_score(\n",
    "        dict(zip(['strike_rate', 'average_strike_rate', 'balls_faced', 'average_balls_faced', 'average_boundaries'], results['Efficiency']['priority_vector'])),\n",
    "        efficiency_metrics\n",
    "    )\n",
    "    \n",
    "    # Calculate Level 2 weighted score\n",
    "    level_2_weights = dict(zip(['scoring_ability', 'consistency', 'efficiency'], results['Level 2']['priority_vector']))\n",
    "    level_2_score = (\n",
    "        level_2_weights['scoring_ability'] * scoring_ability_score +\n",
    "        level_2_weights['consistency'] * consistency_score +\n",
    "        level_2_weights['efficiency'] * efficiency_score\n",
    "    )\n",
    "    \n",
    "    # Multiply level 2 score by bowler rating priority vector\n",
    "    bowler_rating_weight = results['Bowler Rating']['priority_vector'][bowler_rating - 1]  # Adjust index for 0-based array\n",
    "    overall_rating = bowler_rating_weight * level_2_score\n",
    "    \n",
    "    return overall_rating\n",
    "\n",
    "# Define matrices\n",
    "bowler_rating_matrix = np.array([\n",
    "    [1, 1.5, 1.75, 2],\n",
    "    [0.667, 1, 1.5, 1.75],\n",
    "    [0.571, 0.667, 1, 1.5],\n",
    "    [0.5, 0.571, 0.667, 1]\n",
    "])\n",
    "\n",
    "level_2_matrix = np.array([\n",
    "    [1, 1.25, 1.5],\n",
    "    [0.8, 1, 1.25],\n",
    "    [0.667, 0.8, 1]\n",
    "])\n",
    "\n",
    "scoring_ability_matrix = np.array([\n",
    "    [1, 3, 5],\n",
    "    [0.33, 1, 3],\n",
    "    [0.2, 0.33, 1]\n",
    "])\n",
    "\n",
    "consistency_matrix = np.array([\n",
    "    [1, 3, 5, 7],\n",
    "    [0.33, 1, 3, 5],\n",
    "    [0.2, 0.33, 1, 3],\n",
    "    [0.14, 0.2, 0.33, 1]\n",
    "])\n",
    "\n",
    "efficiency_matrix = np.array([\n",
    "    [1, 3, 5, 7, 9],\n",
    "    [0.33, 1, 3, 5, 7],\n",
    "    [0.2, 0.33, 1, 3, 5],\n",
    "    [0.14, 0.2, 0.33, 1, 3],\n",
    "    [0.11, 0.14, 0.2, 0.33, 1]\n",
    "])\n",
    "\n",
    "# Creating dictionary of matrices\n",
    "matrix_dict = {\n",
    "    'Bowler Rating': bowler_rating_matrix,\n",
    "    'Level 2': level_2_matrix,\n",
    "    'Scoring Ability': scoring_ability_matrix,\n",
    "    'Consistency': consistency_matrix,\n",
    "    'Efficiency': efficiency_matrix\n",
    "}\n",
    "\n",
    "# Calculate AHP results\n",
    "results = ahp(matrix_dict)\n",
    "\n",
    "\n",
    "# Calculate and print the batsman ratings\n",
    "final_ratings = {}\n",
    "for batsman, metrics_by_bowler in key_final.items():\n",
    "    final_rating = 0\n",
    "    print(f\"\\nBatsman: {batsman}\")\n",
    "    \n",
    "    # Default values for metrics\n",
    "    default_metrics = {\n",
    "        'average_runs': metrics_by_bowler.get('average_runs', 0),\n",
    "        'average_balls_faced': metrics_by_bowler.get('average_balls_faced', 0),\n",
    "        'average_boundaries': metrics_by_bowler.get('average_boundaries', 0),\n",
    "        'average_strike_rate': metrics_by_bowler.get('average_strike_rate', 0)\n",
    "    }\n",
    "    \n",
    "    for bowler_rating, metrics in metrics_by_bowler.items():\n",
    "        if isinstance(bowler_rating, int):  # Skip non-metric entries\n",
    "            scoring_metrics = {\n",
    "                'runs': metrics.get('runs', 0),\n",
    "                'boundaries': metrics.get('boundaries', 0),\n",
    "                'highest_score': metrics.get('highest_score', 0)\n",
    "            }\n",
    "            consistency_metrics = {\n",
    "                'average': metrics.get('average', default_metrics['average_runs']),\n",
    "                'average_runs': default_metrics['average_runs'],\n",
    "                'dismissals': metrics.get('dismissal', 0),\n",
    "                'innings': metrics.get('innings', 0)\n",
    "            }\n",
    "            efficiency_metrics = {\n",
    "                'strike_rate': metrics.get('strike_rate', 0),\n",
    "                'average_strike_rate': default_metrics['average_strike_rate'],\n",
    "                'balls_faced': metrics.get('balls_faced', 0),\n",
    "                'average_balls_faced': default_metrics['average_balls_faced'],\n",
    "                'average_boundaries': default_metrics['average_boundaries']\n",
    "            }\n",
    "            overall_rating = calculate_batsman_rating(bowler_rating, scoring_metrics, consistency_metrics, efficiency_metrics, results)\n",
    "            final_rating += overall_rating\n",
    "            print(f\"  Bowler Rating {bowler_rating}: Overall Batsman Rating = {overall_rating}\")\n",
    "    final_ratings[batsman] = final_rating\n",
    "    print(f\"  Final Rating: {final_rating}\")\n",
    "\n",
    "print(\"\\nFinal Batsman Ratings:\")\n",
    "for batsman, rating in final_ratings.items():\n",
    "    print(f\"{batsman}: {rating}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e70493-8a06-4be8-819a-20364483ec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ratings = sorted(final_ratings.items(), key=lambda x: x[1], reverse=True)\n",
    "ahpb  =[]\n",
    "# Print the sorted values\n",
    "for name, value in sorted_ratings:\n",
    "    print(f\"{name}: {value}\")\n",
    "    ahpb.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3293ef-20fe-4ac6-9647-0487aafb683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_bats=sorted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e7ca02-ed03-4dd0-99ae-7946cf54fdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [value for name, value in nr_bats]\n",
    "\n",
    "# Compute min and max values\n",
    "min_value = min(values)\n",
    "max_value = max(values)\n",
    "\n",
    "# Normalize values\n",
    "normalized_data = [(name, (value - min_value) / (max_value - min_value)) for name, value in nr_bats]\n",
    "\n",
    "# Output the normalized data\n",
    "for name, normalized_value in normalized_data:\n",
    "    print(f'{name}: {normalized_value:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314671c8-8f5d-4e40-a1dd-d5e3eb60e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract float values\n",
    "values = [x[1] for x in normalized_data]\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(range(len(values)), values, color='blue', marker='o')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Scatter Plot of Batsman Ratings for AHP Model ')\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the plot as an image file\n",
    "plt.savefig('scatter_plot.png')\n",
    "\n",
    "# Show the plot (optional, remove if not needed)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b54b2e-b909-467a-8c7b-17552e8d45a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_dict = dict(normalized_data)\n",
    "player_stats=batsman_metrics\n",
    "def update_player_ratings(stats_dict, ratings_dict):\n",
    "    for player, stats in stats_dict.items():\n",
    "        if player in ratings_dict:\n",
    "            stats['rating'] = ratings_dict[player]\n",
    "        else:\n",
    "            stats['rating'] = None  # Handle missing ratings\n",
    "\n",
    "# Update player stats with ratings\n",
    "update_player_ratings(player_stats, rating_dict)\n",
    "\n",
    "# Print updated player stats\n",
    "for player, stats in player_stats.items():\n",
    "    print(f\"Player: {player}\")\n",
    "    print(f\"Stats: {stats}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bf9d07-862e-4bf7-8f88-4d058c7ee07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfB = pd.DataFrame(player_stats).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1501a14-0587-4c5a-98c9-0e5e110710c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfB['Rating Class'] = pd.cut(dfB['rating'], bins=np.linspace(0, 1, 9), labels=range(1, 9))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6109e3-3f75-4d92-aee0-3068763509f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfB=dfB.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dda5c15-9ca5-4730-aab1-00fd34986812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `combined_df` is your DataFrame\n",
    "y=dfB[\"Rating Class\"]\n",
    "x = dfB[['runs', 'boundaries', 'dismissal', 'balls_faced', \n",
    "                 'innings', 'average', 'strike_rate', 'highest_score', \n",
    "                 'average_runs', 'average_balls_faced', \n",
    "                 'average_boundaries', 'average_strike_rate']]\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=500)\n",
    "model.fit(x, y)\n",
    "\n",
    "# Get feature importance\n",
    "importances = model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7721fa-a587-4952-983f-4f7ebb3a81d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "x = dfB[['runs', 'boundaries', 'dismissal', 'balls_faced', \n",
    "         'innings', 'average', 'strike_rate', 'highest_score', \n",
    "         'average_runs', 'average_balls_faced', \n",
    "         'average_boundaries', 'average_strike_rate']]\n",
    "y = dfB[\"Rating Class\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F-measure (F1 Score): {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3adc46c-11ad-4570-99ba-15d5f28f973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients\n",
    "features = [\n",
    "    'runs',\n",
    "    'boundaries',\n",
    "    'dismissal',\n",
    "    'balls_faced',\n",
    "    'innings',\n",
    "    'average',\n",
    "    'strike_rate',\n",
    "    'highest_score',\n",
    "    'average_runs',\n",
    "    'average_balls_faced',\n",
    "    'average_boundaries',\n",
    "    'average_strike_rate'\n",
    "]\n",
    "\n",
    "# Create a dictionary of features and their importances\n",
    "coefficients = dict(zip(features, importances))\n",
    "# Compute the weighted score\n",
    "dfB['weighted_score'] = (\n",
    "    dfB['runs'] * coefficients['runs'] +\n",
    "    dfB['boundaries'] * coefficients['boundaries'] +\n",
    "    dfB['dismissal'] * coefficients['dismissal'] +\n",
    "    dfB['balls_faced'] * coefficients['balls_faced'] +\n",
    "    dfB['innings'] * coefficients['innings'] +\n",
    "    dfB['average'] * coefficients['average'] +\n",
    "    dfB['strike_rate'] * coefficients['strike_rate'] +\n",
    "    dfB['highest_score'] * coefficients['highest_score'] +\n",
    "    dfB['average_runs'] * coefficients['average_runs'] +\n",
    "    dfB['average_balls_faced'] * coefficients['average_balls_faced'] +\n",
    "    dfB['average_boundaries'] * coefficients['average_boundaries'] +\n",
    "    dfB['average_strike_rate'] * coefficients['average_strike_rate']\n",
    ")\n",
    "\n",
    "# Sort the DataFrame by 'weighted_score' from max to min\n",
    "sorted_df = dfB.sort_values(by='weighted_score', ascending=False)\n",
    "\n",
    "# Print the sorted DataFrame\n",
    "print(sorted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faef633c-3770-4157-b8f4-a7d23fd02fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_names = df.index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1070e6d0-83fd-401e-8182-eff15cc99671",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sorted_df\n",
    "\n",
    "min_score = df['weighted_score'].min()\n",
    "max_score = df['weighted_score'].max()\n",
    "\n",
    "df['normalized_score'] = (df['weighted_score'] - min_score) / (max_score - min_score)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Extract float values\n",
    "values = df['normalized_score']\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(range(len(values)), values, color='blue', marker='o')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Scatter Plot of Batsman Ratings from AHP and Random Forest Models')\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the plot as an image file\n",
    "plt.savefig('scatter_plot.png')\n",
    "\n",
    "# Show the plot (optional, remove if not needed)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380e612f-edda-4888-98db-95de1d897801",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow3=pdf0[pdf0['batter_rating']==3]\n",
    "bow2=pdf0[pdf0['batter_rating']==2]\n",
    "bow1=pdf0[pdf0['batter_rating']==1]\n",
    "bow0 = pdf0[pdf0['batter_rating'].isna()]\n",
    "import pandas as pd\n",
    "from decimal import Decimal\n",
    "\n",
    "# Function to process events and calculate metrics for bowlers\n",
    "def calculate_bowler_metrics(df):\n",
    "    # Initialize dictionary to hold metrics\n",
    "    bowler_metrics = {}\n",
    "\n",
    "    # Define scoring rules\n",
    "    runs_scored = {\n",
    "        '0 runs': 0, '1 run': 1, '2 runs': 2, '3 runs': 3, '4 runs': 4, '6 runs': 6,\n",
    "        '1 run \\n 1 no ball': 1, '2 runs \\n 1 no ball': 2, '3 runs \\n 1 no ball': 3, \n",
    "        '4 runs \\n 1 no ball': 4, '6 runs \\n 1 no ball': 6, '5 runs': 5,\n",
    "        '1 run \\n 2 no balls': 1, '4 runs \\n 2 no balls': 4,\n",
    "    }\n",
    "    \n",
    "    dismissals = [\n",
    "        'Wicket!', 'Wicket! \\n 2 wides', 'Wicket! \\n 1 run \\n 1 no ball', \n",
    "        'Wicket! \\n 1 run', 'Wicket! \\n 2 runs', 'Wicket! \\n 1 bye', \n",
    "        'Wicket! \\n 1 no ball', 'Wicket! \\n 1 wide', 'Wicket! \\n 1 leg bye'\n",
    "    ]\n",
    "\n",
    "    extras = {\n",
    "        '1 wide': 1, '2 wides': 2, '3 wides': 3, '4 wides': 4, '5 wides': 5, '6 wides': 6,\n",
    "        '1 no ball': 1, '2 no balls': 2, '1 bye': 1, '2 byes': 2, '3 byes': 3, \n",
    "        '4 byes': 4, '5 byes': 5, '1 leg bye': 1, '2 leg byes': 2, '3 leg byes': 3, \n",
    "        '4 leg byes': 4, '2 1nb + byes': 2, '3 1nb + byes': 3, '6 1nb + byes': 6, \n",
    "        '5 1nb + byes': 5, '4 1nb + byes': 4, '2 1nb + leg byes': 2\n",
    "    }\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        event = row['Event']\n",
    "        bowler = row['bowler']\n",
    "        bowling_team = row['bowling team']\n",
    "        over = int(row['Over'][5:])\n",
    "\n",
    "        # Initialize bowler if not already in the dictionary\n",
    "        if bowler not in bowler_metrics:\n",
    "            bowler_metrics[bowler] = {'runs_conceded': 0, 'wickets': 0, 'extras': 0, 'balls_bowled': 0, 'innings': 0}\n",
    "\n",
    "        # Calculate metrics for bowlers\n",
    "        if event in runs_scored:\n",
    "            bowler_metrics[bowler]['runs_conceded'] += runs_scored[event]\n",
    "            bowler_metrics[bowler]['balls_bowled'] += 1\n",
    "\n",
    "        if event in dismissals:\n",
    "            bowler_metrics[bowler]['wickets'] += 1\n",
    "\n",
    "        if event in extras:\n",
    "            bowler_metrics[bowler]['extras'] += extras[event]\n",
    "            bowler_metrics[bowler]['runs_conceded'] += extras[event]\n",
    "\n",
    "    # Calculate additional metrics for bowlers\n",
    "    for bowler in bowler_metrics:\n",
    "        runs_conceded = bowler_metrics[bowler]['runs_conceded']\n",
    "        wickets = bowler_metrics[bowler]['wickets']\n",
    "        balls_bowled = bowler_metrics[bowler]['balls_bowled']\n",
    "\n",
    "        bowler_metrics[bowler]['average'] = runs_conceded / wickets if wickets > 0 else runs_conceded\n",
    "        bowler_metrics[bowler]['strike_rate'] = balls_bowled / wickets if wickets > 0 else balls_bowled\n",
    "        bowler_metrics[bowler]['economy_rate'] = (runs_conceded / (balls_bowled / 6)) if balls_bowled > 0 else 0\n",
    "        reciprocal_runs_conceded = 1 / runs_conceded if runs_conceded > 0 else 1\n",
    "        bowler_metrics[bowler]['runs_conceded'] = reciprocal_runs_conceded*100\n",
    "    return bowler_metrics\n",
    "\n",
    "# Calculate metrics for each rating category\n",
    "rat3_bowler_metrics = calculate_bowler_metrics(bow3)\n",
    "rat2_bowler_metrics = calculate_bowler_metrics(bow2)\n",
    "rat1_bowler_metrics = calculate_bowler_metrics(bow1)\n",
    "rat0_bowler_metrics = calculate_bowler_metrics(bow0)\n",
    "cam=calculate_bowler_metrics(pdf0)\n",
    "# Print results\n",
    "print(\"Rating 3 Bowler Metrics:\", rat3_bowler_metrics)\n",
    "print(\"Rating 2 Bowler Metrics:\", rat2_bowler_metrics)\n",
    "print(\"Rating 1 Bowler Metrics:\", rat1_bowler_metrics)\n",
    "print(\"Rating 0 Bowler Metrics:\", rat0_bowler_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b59e6b-6676-4f98-ae4f-51ed943a8894",
   "metadata": {},
   "outputs": [],
   "source": [
    "playersb=[]\n",
    "for i in cam.keys():\n",
    "    playersb.append(i)\n",
    "key_fina={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48588efd-a1fe-4017-9166-89b7b02b886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in playersb:\n",
    "    key_fina[i]={}\n",
    "    if i in rat0_bowler_metrics:\n",
    "        key_fina[i][0]=rat0_bowler_metrics[i]\n",
    "    if i in rat1_bowler_metrics:\n",
    "        key_fina[i][1]=rat1_bowler_metrics[i]\n",
    "    if i in rat2_bowler_metrics:\n",
    "        key_fina[i][2]=rat2_bowler_metrics[i]\n",
    "    if i in rat3_bowler_metrics:\n",
    "        key_fina[i][3]=rat3_bowler_metrics[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2155f29-69e8-4fe9-b023-a11873a91560",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_key_final = {key: value for key, value in key_fina.items() if not (isinstance(key, float) and math.isnan(key))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e910375f-f9a1-48a2-bb12-8b1eb9a163b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_fina=cleaned_key_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd22d339-b529-4fe2-8090-21b09a60ad01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "# Sample data\n",
    "data = key_fina\n",
    "\n",
    "# Extract metrics\n",
    "metrics = ['runs_conceded', 'wickets', 'extras', 'balls_bowled', 'innings', 'average', 'strike_rate', 'economy_rate']\n",
    "\n",
    "# Flatten all metric values to find min and max\n",
    "all_values = {metric: [] for metric in metrics}\n",
    "\n",
    "for player, ratings in data.items():\n",
    "    for rating, values in ratings.items():\n",
    "        for metric in metrics:\n",
    "            if metric in values:\n",
    "                all_values[metric].append(values[metric])\n",
    "\n",
    "# Calculate min and max for each metric\n",
    "min_max_values = {metric: (min(all_values[metric]), max(all_values[metric])) for metric in metrics}\n",
    "\n",
    "# Normalize function\n",
    "def normalize(value, metric, min_max_values):\n",
    "    min_val, max_val = min_max_values[metric]\n",
    "    if max_val == min_val:\n",
    "        return 0  # Avoid division by zero if all values are the same\n",
    "    return (value - min_val) / (max_val - min_val)\n",
    "\n",
    "# Normalize the data\n",
    "standardized_data = {}\n",
    "for player, ratings in data.items():\n",
    "    standardized_data[player] = {}\n",
    "    for rating, values in ratings.items():\n",
    "        standardized_data[player][rating] = {\n",
    "            metric: normalize(values[metric], metric, min_max_values) for metric in metrics if metric in values\n",
    "        }\n",
    "\n",
    "# Print the normalized data\n",
    "pprint.pprint(standardized_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1821c488-437b-420d-aaf7-abb1083efb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_fina=standardized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e561a29c-50a3-407a-9046-c5e448c3a116",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_stats = {\n",
    "    'runs_conceded': 0.0,\n",
    "    'wickets': 0.0,\n",
    "    'extras': 0.0,\n",
    "    'balls_bowled': 0.0,\n",
    "    'innings': 0,\n",
    "    'average': 0.0,\n",
    "    'strike_rate': 0.0,\n",
    "    'economy_rate': 0.0\n",
    "}\n",
    "\n",
    "# Extract statistics with default values\n",
    "stats = []\n",
    "for player, details in key_fina.items():\n",
    "    for key in [0, 1, 2, 3]:\n",
    "        stats_dict = details.get(key, default_stats.copy())\n",
    "        stats_dict['player'] = player\n",
    "        stats_dict['key'] = key\n",
    "        stats.append(stats_dict)\n",
    "\n",
    "# Sorting by the highest value among the numeric statistics\n",
    "sorted_stats = sorted(stats, key=lambda x: max(v for v in x.values() if isinstance(v, (int, float))), reverse=True)\n",
    "\n",
    "# Preparing the ordered dictionary\n",
    "ordered_data = {}\n",
    "for stat in sorted_stats:\n",
    "    player = stat.pop('player')\n",
    "    key = stat.pop('key')\n",
    "    if player not in ordered_data:\n",
    "        ordered_data[player] = {}\n",
    "    ordered_data[player][key] = stat\n",
    "\n",
    "ordered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e602f1-a4f7-4bf6-b7cc-68ea5cf83144",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_fina=ordered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30824126-7ee5-470a-99b8-d2b8e0e1fdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import decimal\n",
    "\n",
    "def ahp(matrix_dict):\n",
    "    def calculate_priority_vector_and_consistency(matrix):\n",
    "        n = matrix.shape[0]\n",
    "        \n",
    "        # Normalize the matrix\n",
    "        column_sums = np.sum(matrix, axis=0)\n",
    "        normalized_matrix = matrix / column_sums\n",
    "        \n",
    "        # Calculate the Priority Vector\n",
    "        priority_vector = np.mean(normalized_matrix, axis=1)\n",
    "        \n",
    "        # Compute the Weighted Sum Vector using the original matrix\n",
    "        weighted_sum_vector = np.dot(matrix, priority_vector)\n",
    "        \n",
    "        # Compute Lambda Max\n",
    "        lambda_max = np.mean(weighted_sum_vector / priority_vector)\n",
    "        \n",
    "        # Calculate Consistency Index (CI)\n",
    "        CI = (lambda_max - n) / (n - 1)\n",
    "        \n",
    "        # Random Index (RI) for consistency ratio calculation\n",
    "        RI_dict = {1: 0, 2: 0, 3: 0.58, 4: 0.90, 5: 1.12, 6: 1.24, 7: 1.32, 8: 1.41, 9: 1.45, 10: 1.49}\n",
    "        RI = RI_dict.get(n, 1.49)\n",
    "        \n",
    "        # Calculate Consistency Ratio (CR)\n",
    "        CR = CI / RI if RI != 0 else 0\n",
    "        \n",
    "        return priority_vector, CI, CR\n",
    "\n",
    "    results = {}\n",
    "    for key, matrix in matrix_dict.items():\n",
    "        priority_vector, CI, CR = calculate_priority_vector_and_consistency(matrix)\n",
    "        if CR > 0.1:\n",
    "            raise ValueError(f\"The consistency ratio for {key} is too high: {CR:.2f}\")\n",
    "        results[key] = {'priority_vector': priority_vector, 'CI': CI, 'CR': CR}\n",
    "    \n",
    "    return results\n",
    "\n",
    "def calculate_weighted_score(weights, metrics):\n",
    "    # Convert metrics values to float if they are decimal.Decimal\n",
    "    metrics = {k: float(v) if isinstance(v, decimal.Decimal) else v for k, v in metrics.items()}\n",
    "    \n",
    "    return sum(weights.get(key, 0) * metrics.get(key, 0) for key in weights)\n",
    "\n",
    "def calculate_batsman_rating(bowler_rating, scoring_metrics, efficiency_metrics, results):\n",
    "    # Calculate weighted scores for each level\n",
    "    scoring_ability_score = calculate_weighted_score(\n",
    "        dict(zip(['wickets','average', 'innings'], results['Scoring Ability']['priority_vector'])),\n",
    "        scoring_metrics\n",
    "    )\n",
    "    \n",
    "    efficiency_score = calculate_weighted_score(\n",
    "        dict(zip(['economy_rate','balls_bowled','runs_conceded','strike_rate',  'extras' ], results['Efficiency']['priority_vector'])),\n",
    "        efficiency_metrics\n",
    "    )\n",
    "    \n",
    "    # Calculate Level 2 weighted score\n",
    "    level_2_weights = dict(zip(['scoring_ability', 'efficiency'], results['Level 2']['priority_vector']))\n",
    "    level_2_score = (\n",
    "        level_2_weights['scoring_ability'] * scoring_ability_score +\n",
    "        level_2_weights['efficiency'] * efficiency_score\n",
    "    )\n",
    "    \n",
    "    # Multiply level 2 score by bowler rating priority vector\n",
    "    bowler_rating_weight = results['Bowler Rating']['priority_vector'][bowler_rating - 1]  # Adjust index for 0-based array\n",
    "    overall_rating = bowler_rating_weight * level_2_score\n",
    "    \n",
    "    return overall_rating\n",
    "\n",
    "# Define matrices\n",
    "bowler_rating_matrix = np.array([\n",
    "    [1, 1.5, 1.75, 2],\n",
    "    [0.667, 1, 1.5, 1.75],\n",
    "    [0.571, 0.667, 1, 1.5],\n",
    "    [0.5, 0.571, 0.667, 1]\n",
    "])\n",
    "\n",
    "level_2_matrix = np.array([\n",
    "    [1, 1.25],\n",
    "    [0.8, 1]\n",
    "])\n",
    "\n",
    "efficiency_matrix = np.array([\n",
    "    [1, 3, 5, 7, 9],\n",
    "    [0.33, 1, 3, 5, 7],\n",
    "    [0.2, 0.33, 1, 3, 5],\n",
    "    [0.14, 0.2, 0.33, 1, 3],\n",
    "    [0.11, 0.14, 0.2, 0.33, 1]\n",
    "])\n",
    "\n",
    "scoring_ability_matrix = np.array([\n",
    "    [1, 3, 5],\n",
    "    [0.33, 1, 3],\n",
    "    [0.2, 0.33, 1]\n",
    "])\n",
    "\n",
    "# Creating dictionary of matrices\n",
    "matrix_dict = {\n",
    "    'Bowler Rating': bowler_rating_matrix,\n",
    "    'Level 2': level_2_matrix,\n",
    "    'Scoring Ability': scoring_ability_matrix,\n",
    "    'Efficiency': efficiency_matrix\n",
    "}\n",
    "\n",
    "# Calculate AHP results\n",
    "results = ahp(matrix_dict)\n",
    "\n",
    "# Example metrics data for batsmen (replace with actual data)\n",
    "key_final = key_fina\n",
    "\n",
    "# Calculate and print the batsman ratings\n",
    "final_ratings = {}\n",
    "for batsman, metrics_by_bowler in key_final.items():\n",
    "    final_rating = 0\n",
    "    print(f\"\\nbowler: {batsman}\")\n",
    "    \n",
    "    for bowler_rating, metrics in metrics_by_bowler.items():\n",
    "        scoring_metrics = {\n",
    "            'average': metrics.get('average', 0),\n",
    "            'wickets': metrics.get('wickets', 0),\n",
    "            'innings': metrics.get('innings', 0)\n",
    "        }\n",
    "        efficiency_metrics = {\n",
    "            'strike_rate': metrics.get('strike_rate', 0),\n",
    "            'balls_bowled': metrics.get('balls_bowled', 0),\n",
    "            'economy_rate': metrics.get('economy_rate', 0),\n",
    "            'extras': metrics.get('extras', 0),\n",
    "            'runs_conceded': metrics.get('runs_conceded', 0)\n",
    "        }\n",
    "        \n",
    "        overall_rating = calculate_batsman_rating(bowler_rating, scoring_metrics, efficiency_metrics, results)\n",
    "        final_rating += overall_rating\n",
    "        print(f\"  batsman Rating {bowler_rating}: Overall bowler Rating = {overall_rating:.2f}\")\n",
    "    \n",
    "    final_ratings[batsman] = final_rating\n",
    "    print(f\"  Final Rating: {final_rating:.2f}\")\n",
    "\n",
    "print(\"\\nFinal Batsman Ratings:\")\n",
    "for batsman, rating in final_ratings.items():\n",
    "    print(f\"{batsman}: {rating:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514953ef-2ce8-4e9b-8f85-2648f274586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_bow=final_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007fa55e-c1e1-4a14-911e-f14cea0eeec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ratings = sorted(final_ratings.items(), key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7ca0f7-09ee-4a48-bfd9-07812feb63ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming sorted_ratings is a list of tuples in the form (name, value)\n",
    "nr_bats = sorted_ratings\n",
    "\n",
    "# Extract values from the list of tuples\n",
    "values = [value for name, value in nr_bats]\n",
    "\n",
    "# Compute min and max values\n",
    "min_value = min(values)\n",
    "max_value = max(values)\n",
    "\n",
    "# Normalize values\n",
    "normalized_data = [(name, (value - min_value) / (max_value - min_value)) for name, value in nr_bats]\n",
    "\n",
    "# Output the normalized data\n",
    "for name, normalized_value in normalized_data:\n",
    "    print(f'{name}: {normalized_value:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc58d17f-b53f-4fc6-8b03-1882c8ff3e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract float values\n",
    "values = [x[1] for x in normalized_data]\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(range(len(values)), values, color='blue', marker='o')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Scatter Plot of Bowler Ratings for AHP Model')\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the plot as an image file\n",
    "plt.savefig('scatter_plot.png')\n",
    "\n",
    "# Show the plot (optional, remove if not needed)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfebb17-5902-4345-ae14-0d189bc14dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_dict = dict(normalized_data)\n",
    "player_stats=bowler_metrics\n",
    "def update_player_ratings(stats_dict, ratings_dict):\n",
    "    for player, stats in stats_dict.items():\n",
    "        if player in ratings_dict:\n",
    "            stats['rating'] = ratings_dict[player]\n",
    "        else:\n",
    "            stats['rating'] = None  # Handle missing ratings\n",
    "\n",
    "# Update player stats with ratings\n",
    "update_player_ratings(player_stats, rating_dict)\n",
    "\n",
    "# Print updated player stats\n",
    "for player, stats in player_stats.items():\n",
    "    print(f\"Player: {player}\")\n",
    "    print(f\"Stats: {stats}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cd1a49-bd07-47aa-91d7-ba34b83c6728",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(player_stats).T\n",
    "\n",
    "# Display the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0617955-8e26-4753-acf8-4f343136060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Rating Class'] = pd.cut(df['rating'], bins=np.linspace(0, 1, 11), labels=range(1, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0fff20-d9b4-4ec0-9ab8-3cfcbeb64bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming `df` is your DataFrame with the new data\n",
    "y = df[\"Rating Class\"]\n",
    "x = df[['runs_conceded', 'wickets', 'extras', 'balls_bowled', \n",
    "        'innings', 'average', 'strike_rate', 'economy_rate', 'rating']]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F-measure (F1 Score): {f1:.4f}\")\n",
    "\n",
    "# Get feature importance\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# List of features\n",
    "features = ['runs_conceded', 'wickets', 'extras', 'balls_bowled', \n",
    "            'innings', 'average', 'strike_rate', 'economy_rate', 'rating']\n",
    "\n",
    "# Create a dictionary of features and their importances\n",
    "coefficients = dict(zip(features, importances))\n",
    "\n",
    "# Compute the weighted score\n",
    "df['weighted_score'] = (\n",
    "    df['runs_conceded'] * coefficients['runs_conceded'] +\n",
    "    df['wickets'] * coefficients['wickets'] +\n",
    "    df['extras'] * coefficients['extras'] +\n",
    "    df['balls_bowled'] * coefficients['balls_bowled'] +\n",
    "    df['innings'] * coefficients['innings'] +\n",
    "    df['average'] * coefficients['average'] +\n",
    "    df['strike_rate'] * coefficients['strike_rate'] +\n",
    "    df['economy_rate'] * coefficients['economy_rate'] +\n",
    "    df['rating'] * coefficients['rating']\n",
    ")\n",
    "\n",
    "# Sort the DataFrame by 'weighted_score' from max to min\n",
    "sorted_df = df.sort_values(by='weighted_score', ascending=False)\n",
    "\n",
    "# Print the sorted DataFrame\n",
    "print(sorted_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96b33b3-35f0-4fc8-bca3-186e7aad156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sorted_df\n",
    "\n",
    "min_score = df['weighted_score'].min()\n",
    "max_score = df['weighted_score'].max()\n",
    "\n",
    "df['normalized_score'] = (df['weighted_score'] - min_score) / (max_score - min_score)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Extract float values\n",
    "values = df['normalized_score']\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(range(len(values)), values, color='blue', marker='o')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Scatter Plot of Bowlers Ratings from AHP and Random Forests Model')\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the plot as an image file\n",
    "plt.savefig('scatter_plot.png')\n",
    "\n",
    "# Show the plot (optional, remove if not needed)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d7d6b6-4d15-4239-8775-d73be1095824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74456883-2075-4a23-b451-432a41aa1851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7436a0e-bfd9-46a8-b061-ec5f17c9822e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b0e3c6-e41f-4fa4-a5f5-23295d3e7802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc929de2-0450-4c73-8724-3da43aed24ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e325c5b-7df7-4bd7-8a60-e3e4a6a21ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a6b961-7ef4-483f-bd1e-3fabba4847c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f53a567-c85d-44eb-b0e0-a1fb0f171d85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2a455e-a393-42c4-a8ee-18559960f291",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
